{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T06:31:39.282018Z",
     "start_time": "2025-01-11T06:30:39.957115Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T07:17:46.537499Z",
     "start_time": "2025-01-11T06:32:25.733922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_path, y_path, indices, batch_size):\n",
    "        assert os.path.exists(X_path), f\"X_path {X_path} does not exist.\"\n",
    "        assert os.path.exists(y_path), f\"y_path {y_path} does not exist.\"\n",
    "        \n",
    "        self.X = np.memmap(X_path, dtype='float32', mode='r', shape=(1612, 15, 224, 224, 3))\n",
    "        self.y = np.memmap(y_path, dtype='int32', mode='r', shape=(1612,))\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X_batch = self.X[batch_indices]\n",
    "        X_batch = preprocess_input(X_batch)  # Use appropriate preprocessing\n",
    "        y_batch = np.eye(2)[self.y[batch_indices]]  # Ensure correct one-hot encoding\n",
    "        return X_batch, y_batch\n",
    "\n",
    "# Updated Callbacks\n",
    "class StepTimerCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\n--- Starting Epoch {epoch + 1} ---\")\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        print(f\"--- Epoch {epoch + 1} completed in {epoch_time:.2f} seconds ---\\n\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.step_start_time = time.time()\n",
    "        print(f\"Step {batch + 1}/{self.params['steps']} - \", end=\"\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        step_time = time.time() - self.step_start_time\n",
    "        print(f\"Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}, Time: {step_time:.2f} seconds\")\n",
    "\n",
    "class BatchEarlyStopping(Callback):\n",
    "    def __init__(self, monitor='loss', threshold=0.1, patience=5):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        current_value = logs.get(self.monitor)\n",
    "        if current_value is not None:\n",
    "            if current_value < self.threshold:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    print(f\"\\nEarly stopping triggered at batch {batch + 1}: {self.monitor} = {current_value:.4f}\")\n",
    "                    self.model.stop_training = True\n",
    "            else:\n",
    "                self.wait = 0\n",
    "\n",
    "# Updated Model Building Function\n",
    "def build_cnn_lstm_model(seq_length, height, width, channels, num_classes):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(height, width, channels))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    sequence_input = Input(shape=(seq_length, height, width, channels))\n",
    "    cnn_features = TimeDistributed(base_model)(sequence_input)\n",
    "    flattened_features = TimeDistributed(Flatten())(cnn_features)\n",
    "\n",
    "    lstm_out = LSTM(128, return_sequences=True)(flattened_features)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "    lstm_out = Dropout(0.4)(lstm_out)\n",
    "    lstm_out = LSTM(128)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "    lstm_out = Dropout(0.3)(lstm_out)\n",
    "\n",
    "    dense_out = Dense(64, activation='relu')(lstm_out)\n",
    "    dense_out = Dropout(0.3)(dense_out)\n",
    "    output = Dense(num_classes, activation='softmax')(dense_out)\n",
    "\n",
    "    model = Model(inputs=sequence_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training Preparation\n",
    "cnn_lstm_model = build_cnn_lstm_model(seq_length=15, height=224, width=224, channels=3, num_classes=2)\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "indices = np.arange(1612)\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "\n",
    "train_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_final_1612.dat', \n",
    "                          r'E:\\PosePerfect\\Dataset Creation\\y_final_1612.dat', \n",
    "                          train_indices, batch_size=12)\n",
    "val_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_final_1612.dat', \n",
    "                        r'E:\\PosePerfect\\Dataset Creation\\y_final_1612.dat', \n",
    "                        val_indices, batch_size=12)\n",
    "\n",
    "checkpoint_dir = './mobilenetV2_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}.keras')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return lr * 0.9 if epoch >= 2 else lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "step_timer_callback = StepTimerCallback()\n",
    "batch_early_stopping_callback = BatchEarlyStopping(monitor='loss', threshold=0.1, patience=2)\n",
    "\n",
    "# Model Training\n",
    "cnn_lstm_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=[checkpoint_callback, lr_callback, step_timer_callback, batch_early_stopping_callback],\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "22fce1d8525b4ed0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001B[1m9406464/9406464\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m,   │             \u001B[38;5;34m0\u001B[0m │\n",
       "│                                 │ \u001B[38;5;34m3\u001B[0m)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m1280\u001B[0m) │     \u001B[38;5;34m2,257,984\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m62720\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │    \u001B[38;5;34m32,178,688\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │           \u001B[38;5;34m130\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62720</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">32,178,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m34,577,666\u001B[0m (131.90 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,577,666</span> (131.90 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m32,319,170\u001B[0m (123.29 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,319,170</span> (123.29 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m2,258,496\u001B[0m (8.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,258,496</span> (8.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PosePerfect\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Epoch 1 ---\n",
      "Epoch 1/10\n",
      "Step 1/94 - Loss: 1.3009, Accuracy: 0.5000, Time: 147.57 seconds\n",
      "\u001B[1m 1/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:53:01\u001B[0m 150s/step - accuracy: 0.5000 - loss: 1.3009Step 2/94 - Loss: 1.1387, Accuracy: 0.4583, Time: 5.11 seconds\n",
      "\u001B[1m 2/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:59\u001B[0m 5s/step - accuracy: 0.4792 - loss: 1.2198     Step 3/94 - Loss: 1.0540, Accuracy: 0.4444, Time: 3.83 seconds\n",
      "\u001B[1m 3/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:51\u001B[0m 5s/step - accuracy: 0.4676 - loss: 1.1645Step 4/94 - Loss: 1.0759, Accuracy: 0.4792, Time: 3.93 seconds\n",
      "\u001B[1m 4/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:29\u001B[0m 4s/step - accuracy: 0.4705 - loss: 1.1424Step 5/94 - Loss: 1.1272, Accuracy: 0.5000, Time: 3.92 seconds\n",
      "\u001B[1m 5/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:16\u001B[0m 4s/step - accuracy: 0.4764 - loss: 1.1393Step 6/94 - Loss: 1.0385, Accuracy: 0.5417, Time: 3.89 seconds\n",
      "\u001B[1m 6/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:06\u001B[0m 4s/step - accuracy: 0.4873 - loss: 1.1225Step 7/94 - Loss: 1.0174, Accuracy: 0.5357, Time: 3.92 seconds\n",
      "\u001B[1m 7/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:58\u001B[0m 4s/step - accuracy: 0.4942 - loss: 1.1075Step 8/94 - Loss: 0.9693, Accuracy: 0.5625, Time: 3.91 seconds\n",
      "\u001B[1m 8/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:51\u001B[0m 4s/step - accuracy: 0.5027 - loss: 1.0902Step 9/94 - Loss: 0.9889, Accuracy: 0.5463, Time: 5.20 seconds\n",
      "\u001B[1m 9/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:59\u001B[0m 4s/step - accuracy: 0.5076 - loss: 1.0790Step 10/94 - Loss: 0.9784, Accuracy: 0.5500, Time: 5.66 seconds\n",
      "\u001B[1m10/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:08\u001B[0m 4s/step - accuracy: 0.5118 - loss: 1.0689Step 11/94 - Loss: 0.9691, Accuracy: 0.5606, Time: 4.96 seconds\n",
      "\u001B[1m11/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:09\u001B[0m 4s/step - accuracy: 0.5162 - loss: 1.0598Step 12/94 - Loss: 0.9788, Accuracy: 0.5625, Time: 3.95 seconds\n",
      "\u001B[1m12/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:01\u001B[0m 4s/step - accuracy: 0.5201 - loss: 1.0531Step 13/94 - Loss: 0.9698, Accuracy: 0.5641, Time: 4.49 seconds\n",
      "\u001B[1m13/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:57\u001B[0m 4s/step - accuracy: 0.5235 - loss: 1.0467Step 14/94 - Loss: 0.9459, Accuracy: 0.5714, Time: 3.89 seconds\n",
      "\u001B[1m14/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:49\u001B[0m 4s/step - accuracy: 0.5269 - loss: 1.0395Step 15/94 - Loss: 0.9631, Accuracy: 0.5556, Time: 3.97 seconds\n",
      "\u001B[1m15/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:43\u001B[0m 4s/step - accuracy: 0.5288 - loss: 1.0344Step 16/94 - Loss: 0.9538, Accuracy: 0.5573, Time: 3.85 seconds\n",
      "\u001B[1m16/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:36\u001B[0m 4s/step - accuracy: 0.5306 - loss: 1.0293Step 17/94 - Loss: 0.9302, Accuracy: 0.5686, Time: 3.78 seconds\n",
      "\u001B[1m17/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:29\u001B[0m 4s/step - accuracy: 0.5328 - loss: 1.0235Step 18/94 - Loss: 0.9069, Accuracy: 0.5741, Time: 3.93 seconds\n",
      "\u001B[1m18/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:23\u001B[0m 4s/step - accuracy: 0.5351 - loss: 1.0170Step 19/94 - Loss: 0.9100, Accuracy: 0.5789, Time: 3.89 seconds\n",
      "\u001B[1m19/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:17\u001B[0m 4s/step - accuracy: 0.5374 - loss: 1.0114Step 20/94 - Loss: 0.8996, Accuracy: 0.5833, Time: 3.89 seconds\n",
      "\u001B[1m20/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:12\u001B[0m 4s/step - accuracy: 0.5397 - loss: 1.0058Step 21/94 - Loss: 0.9087, Accuracy: 0.5794, Time: 3.92 seconds\n",
      "\u001B[1m21/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:07\u001B[0m 4s/step - accuracy: 0.5416 - loss: 1.0012Step 22/94 - Loss: 0.8877, Accuracy: 0.5909, Time: 3.98 seconds\n",
      "\u001B[1m22/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:02\u001B[0m 4s/step - accuracy: 0.5439 - loss: 0.9960Step 23/94 - Loss: 0.8843, Accuracy: 0.5870, Time: 3.86 seconds\n",
      "\u001B[1m23/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:56\u001B[0m 4s/step - accuracy: 0.5457 - loss: 0.9912Step 24/94 - Loss: 0.8854, Accuracy: 0.5799, Time: 3.85 seconds\n",
      "\u001B[1m24/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:51\u001B[0m 4s/step - accuracy: 0.5472 - loss: 0.9868Step 25/94 - Loss: 0.8890, Accuracy: 0.5833, Time: 4.00 seconds\n",
      "\u001B[1m25/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:47\u001B[0m 4s/step - accuracy: 0.5486 - loss: 0.9829Step 26/94 - Loss: 0.8759, Accuracy: 0.5833, Time: 4.24 seconds\n",
      "\u001B[1m26/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:43\u001B[0m 4s/step - accuracy: 0.5499 - loss: 0.9787Step 27/94 - Loss: 0.8699, Accuracy: 0.5833, Time: 3.88 seconds\n",
      "\u001B[1m27/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:38\u001B[0m 4s/step - accuracy: 0.5512 - loss: 0.9747Step 28/94 - Loss: 0.8616, Accuracy: 0.5804, Time: 3.91 seconds\n",
      "\u001B[1m28/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:33\u001B[0m 4s/step - accuracy: 0.5522 - loss: 0.9707Step 29/94 - Loss: 0.8470, Accuracy: 0.5891, Time: 3.85 seconds\n",
      "\u001B[1m29/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:28\u001B[0m 4s/step - accuracy: 0.5535 - loss: 0.9664Step 30/94 - Loss: 0.8335, Accuracy: 0.5944, Time: 3.79 seconds\n",
      "\u001B[1m30/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:23\u001B[0m 4s/step - accuracy: 0.5549 - loss: 0.9620Step 31/94 - Loss: 0.8385, Accuracy: 0.5941, Time: 3.76 seconds\n",
      "\u001B[1m31/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:18\u001B[0m 4s/step - accuracy: 0.5561 - loss: 0.9580Step 32/94 - Loss: 0.8382, Accuracy: 0.5938, Time: 3.90 seconds\n",
      "\u001B[1m32/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:14\u001B[0m 4s/step - accuracy: 0.5573 - loss: 0.9542Step 33/94 - Loss: 0.8379, Accuracy: 0.5960, Time: 3.87 seconds\n",
      "\u001B[1m33/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:09\u001B[0m 4s/step - accuracy: 0.5585 - loss: 0.9507Step 34/94 - Loss: 0.8324, Accuracy: 0.5907, Time: 3.91 seconds\n",
      "\u001B[1m34/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:05\u001B[0m 4s/step - accuracy: 0.5594 - loss: 0.9472Step 35/94 - Loss: 0.8224, Accuracy: 0.5952, Time: 4.05 seconds\n",
      "\u001B[1m35/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:01\u001B[0m 4s/step - accuracy: 0.5604 - loss: 0.9437Step 36/94 - Loss: 0.8105, Accuracy: 0.6019, Time: 4.13 seconds\n",
      "\u001B[1m36/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:57\u001B[0m 4s/step - accuracy: 0.5616 - loss: 0.9400Step 37/94 - Loss: 0.8070, Accuracy: 0.6059, Time: 4.00 seconds\n",
      "\u001B[1m37/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:53\u001B[0m 4s/step - accuracy: 0.5628 - loss: 0.9364Step 38/94 - Loss: 0.7955, Accuracy: 0.6118, Time: 3.78 seconds\n",
      "\u001B[1m38/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:48\u001B[0m 4s/step - accuracy: 0.5641 - loss: 0.9327Step 39/94 - Loss: 0.8043, Accuracy: 0.6111, Time: 3.87 seconds\n",
      "\u001B[1m39/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:44\u001B[0m 4s/step - accuracy: 0.5653 - loss: 0.9294Step 40/94 - Loss: 0.7994, Accuracy: 0.6146, Time: 3.91 seconds\n",
      "\u001B[1m40/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:39\u001B[0m 4s/step - accuracy: 0.5665 - loss: 0.9261Step 41/94 - Loss: 0.7999, Accuracy: 0.6179, Time: 3.80 seconds\n",
      "\u001B[1m41/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:35\u001B[0m 4s/step - accuracy: 0.5678 - loss: 0.9231Step 42/94 - Loss: 0.7981, Accuracy: 0.6171, Time: 3.77 seconds\n",
      "\u001B[1m42/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:30\u001B[0m 4s/step - accuracy: 0.5689 - loss: 0.9201Step 43/94 - Loss: 0.7934, Accuracy: 0.6202, Time: 3.84 seconds\n",
      "\u001B[1m43/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:26\u001B[0m 4s/step - accuracy: 0.5701 - loss: 0.9171Step 44/94 - Loss: 0.7874, Accuracy: 0.6250, Time: 3.91 seconds\n",
      "\u001B[1m44/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:22\u001B[0m 4s/step - accuracy: 0.5714 - loss: 0.9142Step 45/94 - Loss: 0.7750, Accuracy: 0.6315, Time: 3.82 seconds\n",
      "\u001B[1m45/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:18\u001B[0m 4s/step - accuracy: 0.5727 - loss: 0.9111Step 46/94 - Loss: 0.7697, Accuracy: 0.6322, Time: 3.85 seconds\n",
      "\u001B[1m46/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:13\u001B[0m 4s/step - accuracy: 0.5740 - loss: 0.9080Step 47/94 - Loss: 0.7629, Accuracy: 0.6348, Time: 3.89 seconds\n",
      "\u001B[1m47/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:09\u001B[0m 4s/step - accuracy: 0.5753 - loss: 0.9049Step 48/94 - Loss: 0.7690, Accuracy: 0.6319, Time: 3.82 seconds\n",
      "\u001B[1m48/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:05\u001B[0m 4s/step - accuracy: 0.5765 - loss: 0.9021Step 49/94 - Loss: 0.7634, Accuracy: 0.6327, Time: 3.86 seconds\n",
      "\u001B[1m49/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:01\u001B[0m 4s/step - accuracy: 0.5776 - loss: 0.8993Step 50/94 - Loss: 0.7550, Accuracy: 0.6367, Time: 3.82 seconds\n",
      "\u001B[1m50/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:57\u001B[0m 4s/step - accuracy: 0.5788 - loss: 0.8964Step 51/94 - Loss: 0.7525, Accuracy: 0.6389, Time: 3.90 seconds\n",
      "\u001B[1m51/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:52\u001B[0m 4s/step - accuracy: 0.5800 - loss: 0.8936Step 52/94 - Loss: 0.7456, Accuracy: 0.6426, Time: 3.85 seconds\n",
      "\u001B[1m52/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:48\u001B[0m 4s/step - accuracy: 0.5812 - loss: 0.8907Step 53/94 - Loss: 0.7393, Accuracy: 0.6462, Time: 3.94 seconds\n",
      "\u001B[1m53/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:44\u001B[0m 4s/step - accuracy: 0.5824 - loss: 0.8879Step 54/94 - Loss: 0.7394, Accuracy: 0.6481, Time: 3.89 seconds\n",
      "\u001B[1m54/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:40\u001B[0m 4s/step - accuracy: 0.5836 - loss: 0.8851Step 55/94 - Loss: 0.7402, Accuracy: 0.6485, Time: 3.99 seconds\n",
      "\u001B[1m55/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:36\u001B[0m 4s/step - accuracy: 0.5848 - loss: 0.8825Step 56/94 - Loss: 0.7386, Accuracy: 0.6518, Time: 4.01 seconds\n",
      "\u001B[1m56/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:32\u001B[0m 4s/step - accuracy: 0.5860 - loss: 0.8799Step 57/94 - Loss: 0.7430, Accuracy: 0.6520, Time: 3.87 seconds\n",
      "\u001B[1m57/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:28\u001B[0m 4s/step - accuracy: 0.5872 - loss: 0.8775Step 58/94 - Loss: 0.7449, Accuracy: 0.6509, Time: 3.81 seconds\n",
      "\u001B[1m58/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:24\u001B[0m 4s/step - accuracy: 0.5883 - loss: 0.8752Step 59/94 - Loss: 0.7406, Accuracy: 0.6511, Time: 3.91 seconds\n",
      "\u001B[1m59/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:20\u001B[0m 4s/step - accuracy: 0.5893 - loss: 0.8729Step 60/94 - Loss: 0.7388, Accuracy: 0.6500, Time: 3.83 seconds\n",
      "\u001B[1m60/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:16\u001B[0m 4s/step - accuracy: 0.5903 - loss: 0.8707Step 61/94 - Loss: 0.7349, Accuracy: 0.6544, Time: 3.80 seconds\n",
      "\u001B[1m61/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:12\u001B[0m 4s/step - accuracy: 0.5914 - loss: 0.8685Step 62/94 - Loss: 0.7323, Accuracy: 0.6573, Time: 3.79 seconds\n",
      "\u001B[1m62/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:07\u001B[0m 4s/step - accuracy: 0.5925 - loss: 0.8663Step 63/94 - Loss: 0.7290, Accuracy: 0.6601, Time: 3.84 seconds\n",
      "\u001B[1m63/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:03\u001B[0m 4s/step - accuracy: 0.5935 - loss: 0.8641Step 64/94 - Loss: 0.7265, Accuracy: 0.6615, Time: 3.86 seconds\n",
      "\u001B[1m64/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:59\u001B[0m 4s/step - accuracy: 0.5946 - loss: 0.8619Step 65/94 - Loss: 0.7292, Accuracy: 0.6603, Time: 3.80 seconds\n",
      "\u001B[1m65/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:55\u001B[0m 4s/step - accuracy: 0.5956 - loss: 0.8599Step 66/94 - Loss: 0.7245, Accuracy: 0.6616, Time: 3.90 seconds\n",
      "\u001B[1m66/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:51\u001B[0m 4s/step - accuracy: 0.5966 - loss: 0.8579Step 67/94 - Loss: 0.7236, Accuracy: 0.6617, Time: 3.87 seconds\n",
      "\u001B[1m67/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:47\u001B[0m 4s/step - accuracy: 0.5976 - loss: 0.8559Step 68/94 - Loss: 0.7190, Accuracy: 0.6630, Time: 3.88 seconds\n",
      "\u001B[1m68/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:43\u001B[0m 4s/step - accuracy: 0.5985 - loss: 0.8538Step 69/94 - Loss: 0.7207, Accuracy: 0.6630, Time: 3.82 seconds\n",
      "\u001B[1m69/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:39\u001B[0m 4s/step - accuracy: 0.5995 - loss: 0.8519Step 70/94 - Loss: 0.7147, Accuracy: 0.6655, Time: 3.85 seconds\n",
      "\u001B[1m70/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:35\u001B[0m 4s/step - accuracy: 0.6004 - loss: 0.8499Step 71/94 - Loss: 0.7103, Accuracy: 0.6667, Time: 3.94 seconds\n",
      "\u001B[1m71/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:31\u001B[0m 4s/step - accuracy: 0.6013 - loss: 0.8480Step 72/94 - Loss: 0.7101, Accuracy: 0.6667, Time: 3.90 seconds\n",
      "\u001B[1m72/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:27\u001B[0m 4s/step - accuracy: 0.6023 - loss: 0.8461Step 73/94 - Loss: 0.7083, Accuracy: 0.6678, Time: 3.77 seconds\n",
      "\u001B[1m73/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:23\u001B[0m 4s/step - accuracy: 0.6031 - loss: 0.8442Step 74/94 - Loss: 0.7084, Accuracy: 0.6655, Time: 3.80 seconds\n",
      "\u001B[1m74/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:19\u001B[0m 4s/step - accuracy: 0.6040 - loss: 0.8423Step 75/94 - Loss: 0.7029, Accuracy: 0.6678, Time: 3.89 seconds\n",
      "\u001B[1m75/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:15\u001B[0m 4s/step - accuracy: 0.6048 - loss: 0.8405Step 76/94 - Loss: 0.6978, Accuracy: 0.6711, Time: 3.92 seconds\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:11\u001B[0m 4s/step - accuracy: 0.6057 - loss: 0.8386Step 77/94 - Loss: 0.6963, Accuracy: 0.6710, Time: 3.88 seconds\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:07\u001B[0m 4s/step - accuracy: 0.6066 - loss: 0.8368Step 78/94 - Loss: 0.6917, Accuracy: 0.6731, Time: 3.94 seconds\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:03\u001B[0m 4s/step - accuracy: 0.6074 - loss: 0.8349Step 79/94 - Loss: 0.6882, Accuracy: 0.6751, Time: 3.89 seconds\n",
      "\u001B[1m79/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m59s\u001B[0m 4s/step - accuracy: 0.6083 - loss: 0.8330 Step 80/94 - Loss: 0.6882, Accuracy: 0.6750, Time: 3.82 seconds\n",
      "\u001B[1m80/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m55s\u001B[0m 4s/step - accuracy: 0.6091 - loss: 0.8312Step 81/94 - Loss: 0.6833, Accuracy: 0.6770, Time: 3.96 seconds\n",
      "\u001B[1m81/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m51s\u001B[0m 4s/step - accuracy: 0.6099 - loss: 0.8294Step 82/94 - Loss: 0.6819, Accuracy: 0.6768, Time: 3.82 seconds\n",
      "\u001B[1m82/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m47s\u001B[0m 4s/step - accuracy: 0.6108 - loss: 0.8276Step 83/94 - Loss: 0.6812, Accuracy: 0.6777, Time: 3.88 seconds\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m43s\u001B[0m 4s/step - accuracy: 0.6116 - loss: 0.8258Step 84/94 - Loss: 0.6775, Accuracy: 0.6796, Time: 3.89 seconds\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m39s\u001B[0m 4s/step - accuracy: 0.6124 - loss: 0.8241Step 85/94 - Loss: 0.6764, Accuracy: 0.6794, Time: 3.86 seconds\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m35s\u001B[0m 4s/step - accuracy: 0.6132 - loss: 0.8223Step 86/94 - Loss: 0.6744, Accuracy: 0.6802, Time: 3.90 seconds\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m31s\u001B[0m 4s/step - accuracy: 0.6139 - loss: 0.8206Step 87/94 - Loss: 0.6730, Accuracy: 0.6801, Time: 3.87 seconds\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m27s\u001B[0m 4s/step - accuracy: 0.6147 - loss: 0.8189Step 88/94 - Loss: 0.6697, Accuracy: 0.6818, Time: 3.74 seconds\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m23s\u001B[0m 4s/step - accuracy: 0.6155 - loss: 0.8172Step 89/94 - Loss: 0.6706, Accuracy: 0.6807, Time: 3.73 seconds\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m19s\u001B[0m 4s/step - accuracy: 0.6162 - loss: 0.8156Step 90/94 - Loss: 0.6690, Accuracy: 0.6815, Time: 6.64 seconds\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m15s\u001B[0m 4s/step - accuracy: 0.6169 - loss: 0.8140Step 91/94 - Loss: 0.6685, Accuracy: 0.6832, Time: 3.94 seconds\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.6177 - loss: 0.8124Step 92/94 - Loss: 0.6645, Accuracy: 0.6848, Time: 3.82 seconds\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 0.6184 - loss: 0.8107 Step 93/94 - Loss: 0.6628, Accuracy: 0.6864, Time: 3.72 seconds\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 0.6191 - loss: 0.8092Step 94/94 - Loss: 0.6622, Accuracy: 0.6871, Time: 3.78 seconds\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.6198 - loss: 0.8076\n",
      "Epoch 1: val_loss improved from inf to 0.69608, saving model to ./mobilenetV2_checkpoints\\model_epoch_01_val_loss_0.70.keras\n",
      "--- Epoch 1 completed in 721.76 seconds ---\n",
      "\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m722s\u001B[0m 6s/step - accuracy: 0.6205 - loss: 0.8061 - val_accuracy: 0.5042 - val_loss: 0.6961 - learning_rate: 1.0000e-05\n",
      "\n",
      "--- Starting Epoch 2 ---\n",
      "Epoch 2/10\n",
      "Step 1/94 - Loss: 0.2996, Accuracy: 0.8333, Time: 15.02 seconds\n",
      "\u001B[1m 1/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m28:05\u001B[0m 18s/step - accuracy: 0.8333 - loss: 0.2996Step 2/94 - Loss: 0.2498, Accuracy: 0.8750, Time: 4.07 seconds\n",
      "\u001B[1m 2/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:26\u001B[0m 4s/step - accuracy: 0.8542 - loss: 0.2747  Step 3/94 - Loss: 0.3847, Accuracy: 0.8056, Time: 3.93 seconds\n",
      "\u001B[1m 3/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:09\u001B[0m 4s/step - accuracy: 0.8380 - loss: 0.3113Step 4/94 - Loss: 0.3655, Accuracy: 0.8125, Time: 4.00 seconds\n",
      "\u001B[1m 4/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:03\u001B[0m 4s/step - accuracy: 0.8316 - loss: 0.3249Step 5/94 - Loss: 0.3675, Accuracy: 0.8167, Time: 3.95 seconds\n",
      "\u001B[1m 5/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:57\u001B[0m 4s/step - accuracy: 0.8286 - loss: 0.3334Step 6/94 - Loss: 0.3298, Accuracy: 0.8472, Time: 4.18 seconds\n",
      "\u001B[1m 6/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:56\u001B[0m 4s/step - accuracy: 0.8317 - loss: 0.3328Step 7/94 - Loss: 0.3466, Accuracy: 0.8333, Time: 4.05 seconds\n",
      "\u001B[1m 7/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:52\u001B[0m 4s/step - accuracy: 0.8319 - loss: 0.3348Step 8/94 - Loss: 0.3535, Accuracy: 0.8333, Time: 3.97 seconds\n",
      "\u001B[1m 8/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:47\u001B[0m 4s/step - accuracy: 0.8321 - loss: 0.3371Step 9/94 - Loss: 0.3392, Accuracy: 0.8519, Time: 4.13 seconds\n",
      "\u001B[1m 9/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:44\u001B[0m 4s/step - accuracy: 0.8343 - loss: 0.3373Step 10/94 - Loss: 0.3479, Accuracy: 0.8500, Time: 4.11 seconds\n",
      "\u001B[1m10/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:41\u001B[0m 4s/step - accuracy: 0.8359 - loss: 0.3384Step 11/94 - Loss: 0.3611, Accuracy: 0.8485, Time: 4.02 seconds\n",
      "\u001B[1m11/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:36\u001B[0m 4s/step - accuracy: 0.8370 - loss: 0.3405Step 12/94 - Loss: 0.3655, Accuracy: 0.8472, Time: 4.08 seconds\n",
      "\u001B[1m12/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:32\u001B[0m 4s/step - accuracy: 0.8379 - loss: 0.3426Step 13/94 - Loss: 0.3815, Accuracy: 0.8397, Time: 4.09 seconds\n",
      "\u001B[1m13/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:29\u001B[0m 4s/step - accuracy: 0.8380 - loss: 0.3456Step 14/94 - Loss: 0.3714, Accuracy: 0.8512, Time: 3.94 seconds\n",
      "\u001B[1m14/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:24\u001B[0m 4s/step - accuracy: 0.8390 - loss: 0.3474Step 15/94 - Loss: 0.3756, Accuracy: 0.8500, Time: 3.89 seconds\n",
      "\u001B[1m15/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:19\u001B[0m 4s/step - accuracy: 0.8397 - loss: 0.3493Step 16/94 - Loss: 0.3724, Accuracy: 0.8490, Time: 3.95 seconds\n",
      "\u001B[1m16/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:14\u001B[0m 4s/step - accuracy: 0.8403 - loss: 0.3507Step 17/94 - Loss: 0.3622, Accuracy: 0.8529, Time: 3.89 seconds\n",
      "\u001B[1m17/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:10\u001B[0m 4s/step - accuracy: 0.8410 - loss: 0.3514Step 18/94 - Loss: 0.3850, Accuracy: 0.8426, Time: 3.96 seconds\n",
      "\u001B[1m18/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:05\u001B[0m 4s/step - accuracy: 0.8411 - loss: 0.3533Step 19/94 - Loss: 0.3918, Accuracy: 0.8377, Time: 4.03 seconds\n",
      "\u001B[1m19/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:01\u001B[0m 4s/step - accuracy: 0.8409 - loss: 0.3553Step 20/94 - Loss: 0.4013, Accuracy: 0.8292, Time: 3.98 seconds\n",
      "\u001B[1m20/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:57\u001B[0m 4s/step - accuracy: 0.8403 - loss: 0.3576Step 21/94 - Loss: 0.4130, Accuracy: 0.8254, Time: 4.05 seconds\n",
      "\u001B[1m21/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:53\u001B[0m 4s/step - accuracy: 0.8396 - loss: 0.3602Step 22/94 - Loss: 0.4276, Accuracy: 0.8182, Time: 3.92 seconds\n",
      "\u001B[1m22/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:49\u001B[0m 4s/step - accuracy: 0.8387 - loss: 0.3633Step 23/94 - Loss: 0.4249, Accuracy: 0.8188, Time: 4.38 seconds\n",
      "\u001B[1m23/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:46\u001B[0m 4s/step - accuracy: 0.8378 - loss: 0.3660Step 24/94 - Loss: 0.4273, Accuracy: 0.8194, Time: 5.42 seconds\n",
      "\u001B[1m24/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:46\u001B[0m 4s/step - accuracy: 0.8370 - loss: 0.3685Step 25/94 - Loss: 0.4431, Accuracy: 0.8167, Time: 5.47 seconds\n",
      "\u001B[1m25/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:46\u001B[0m 4s/step - accuracy: 0.8362 - loss: 0.3715Step 26/94 - Loss: 0.4466, Accuracy: 0.8173, Time: 5.05 seconds\n",
      "\u001B[1m26/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:44\u001B[0m 4s/step - accuracy: 0.8355 - loss: 0.3744Step 27/94 - Loss: 0.4686, Accuracy: 0.8117, Time: 5.17 seconds\n",
      "\u001B[1m27/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:43\u001B[0m 4s/step - accuracy: 0.8346 - loss: 0.3779Step 28/94 - Loss: 0.4672, Accuracy: 0.8095, Time: 5.09 seconds\n",
      "\u001B[1m28/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:41\u001B[0m 4s/step - accuracy: 0.8337 - loss: 0.3811Step 29/94 - Loss: 0.4607, Accuracy: 0.8103, Time: 4.69 seconds\n",
      "\u001B[1m29/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:37\u001B[0m 4s/step - accuracy: 0.8329 - loss: 0.3838Step 30/94 - Loss: 0.4498, Accuracy: 0.8167, Time: 4.58 seconds\n",
      "\u001B[1m30/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:34\u001B[0m 4s/step - accuracy: 0.8324 - loss: 0.3860Step 31/94 - Loss: 0.4469, Accuracy: 0.8172, Time: 4.77 seconds\n",
      "\u001B[1m31/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:31\u001B[0m 4s/step - accuracy: 0.8319 - loss: 0.3880Step 32/94 - Loss: 0.4480, Accuracy: 0.8151, Time: 4.65 seconds\n",
      "\u001B[1m32/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:27\u001B[0m 4s/step - accuracy: 0.8314 - loss: 0.3899Step 33/94 - Loss: 0.4366, Accuracy: 0.8207, Time: 4.83 seconds\n",
      "\u001B[1m33/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:24\u001B[0m 4s/step - accuracy: 0.8310 - loss: 0.3913Step 34/94 - Loss: 0.4344, Accuracy: 0.8186, Time: 4.89 seconds\n",
      "\u001B[1m34/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:20\u001B[0m 4s/step - accuracy: 0.8307 - loss: 0.3925Step 35/94 - Loss: 0.4334, Accuracy: 0.8190, Time: 5.40 seconds\n",
      "\u001B[1m35/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:18\u001B[0m 4s/step - accuracy: 0.8303 - loss: 0.3937Step 36/94 - Loss: 0.4305, Accuracy: 0.8194, Time: 6.16 seconds\n",
      "\u001B[1m36/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:17\u001B[0m 4s/step - accuracy: 0.8300 - loss: 0.3947Step 37/94 - Loss: 0.4267, Accuracy: 0.8221, Time: 8.61 seconds\n",
      "\u001B[1m37/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:19\u001B[0m 5s/step - accuracy: 0.8298 - loss: 0.3956Step 38/94 - Loss: 0.4283, Accuracy: 0.8246, Time: 8.04 seconds\n",
      "\u001B[1m38/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:20\u001B[0m 5s/step - accuracy: 0.8297 - loss: 0.3965Step 39/94 - Loss: 0.4267, Accuracy: 0.8248, Time: 4.65 seconds\n",
      "\u001B[1m39/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:16\u001B[0m 5s/step - accuracy: 0.8296 - loss: 0.3972Step 40/94 - Loss: 0.4224, Accuracy: 0.8271, Time: 6.41 seconds\n",
      "\u001B[1m40/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:13\u001B[0m 5s/step - accuracy: 0.8295 - loss: 0.3979Step 41/94 - Loss: 0.4187, Accuracy: 0.8272, Time: 4.57 seconds\n",
      "\u001B[1m41/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:09\u001B[0m 5s/step - accuracy: 0.8294 - loss: 0.3984Step 42/94 - Loss: 0.4226, Accuracy: 0.8234, Time: 4.68 seconds\n",
      "\u001B[1m42/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:04\u001B[0m 5s/step - accuracy: 0.8293 - loss: 0.3989Step 43/94 - Loss: 0.4172, Accuracy: 0.8256, Time: 4.86 seconds\n",
      "\u001B[1m43/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:59\u001B[0m 5s/step - accuracy: 0.8292 - loss: 0.3994Step 44/94 - Loss: 0.4165, Accuracy: 0.8258, Time: 4.52 seconds\n",
      "\u001B[1m44/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:54\u001B[0m 5s/step - accuracy: 0.8291 - loss: 0.3998Step 45/94 - Loss: 0.4147, Accuracy: 0.8259, Time: 4.26 seconds\n",
      "\u001B[1m45/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:49\u001B[0m 5s/step - accuracy: 0.8291 - loss: 0.4001Step 46/94 - Loss: 0.4178, Accuracy: 0.8225, Time: 4.05 seconds\n",
      "\u001B[1m46/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:44\u001B[0m 5s/step - accuracy: 0.8289 - loss: 0.4005Step 47/94 - Loss: 0.4158, Accuracy: 0.8227, Time: 3.94 seconds\n",
      "\u001B[1m47/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:38\u001B[0m 5s/step - accuracy: 0.8288 - loss: 0.4008Step 48/94 - Loss: 0.4196, Accuracy: 0.8212, Time: 3.94 seconds\n",
      "\u001B[1m48/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:33\u001B[0m 5s/step - accuracy: 0.8286 - loss: 0.4012Step 49/94 - Loss: 0.4132, Accuracy: 0.8231, Time: 3.86 seconds\n",
      "\u001B[1m49/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:28\u001B[0m 5s/step - accuracy: 0.8285 - loss: 0.4014Step 50/94 - Loss: 0.4066, Accuracy: 0.8267, Time: 4.20 seconds\n",
      "\u001B[1m50/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:23\u001B[0m 5s/step - accuracy: 0.8285 - loss: 0.4015Step 51/94 - Loss: 0.4036, Accuracy: 0.8284, Time: 4.39 seconds\n",
      "\u001B[1m51/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:18\u001B[0m 5s/step - accuracy: 0.8285 - loss: 0.4016Step 52/94 - Loss: 0.4049, Accuracy: 0.8269, Time: 4.04 seconds\n",
      "\u001B[1m52/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m3:13\u001B[0m 5s/step - accuracy: 0.8284 - loss: 0.4016Step 53/94 - Loss: 0.4096, Accuracy: 0.8270, Time: 4.66 seconds\n",
      "\u001B[1m53/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m3:08\u001B[0m 5s/step - accuracy: 0.8284 - loss: 0.4018Step 54/94 - Loss: 0.4138, Accuracy: 0.8256, Time: 5.38 seconds\n",
      "\u001B[1m54/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m3:04\u001B[0m 5s/step - accuracy: 0.8284 - loss: 0.4020Step 55/94 - Loss: 0.4094, Accuracy: 0.8273, Time: 5.19 seconds\n",
      "\u001B[1m55/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m3:00\u001B[0m 5s/step - accuracy: 0.8283 - loss: 0.4022Step 56/94 - Loss: 0.4101, Accuracy: 0.8259, Time: 4.89 seconds\n",
      "\u001B[1m56/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:56\u001B[0m 5s/step - accuracy: 0.8283 - loss: 0.4023Step 57/94 - Loss: 0.4146, Accuracy: 0.8231, Time: 4.92 seconds\n",
      "\u001B[1m57/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:51\u001B[0m 5s/step - accuracy: 0.8282 - loss: 0.4025Step 58/94 - Loss: 0.4167, Accuracy: 0.8247, Time: 4.61 seconds\n",
      "\u001B[1m58/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:47\u001B[0m 5s/step - accuracy: 0.8281 - loss: 0.4028Step 59/94 - Loss: 0.4195, Accuracy: 0.8220, Time: 5.20 seconds\n",
      "\u001B[1m59/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:42\u001B[0m 5s/step - accuracy: 0.8280 - loss: 0.4030Step 60/94 - Loss: 0.4250, Accuracy: 0.8208, Time: 4.93 seconds\n",
      "\u001B[1m60/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:38\u001B[0m 5s/step - accuracy: 0.8279 - loss: 0.4034Step 61/94 - Loss: 0.4202, Accuracy: 0.8238, Time: 5.52 seconds\n",
      "\u001B[1m61/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:34\u001B[0m 5s/step - accuracy: 0.8279 - loss: 0.4037Step 62/94 - Loss: 0.4237, Accuracy: 0.8239, Time: 4.56 seconds\n",
      "\u001B[1m62/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:29\u001B[0m 5s/step - accuracy: 0.8278 - loss: 0.4040Step 63/94 - Loss: 0.4225, Accuracy: 0.8241, Time: 4.86 seconds\n",
      "\u001B[1m63/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:24\u001B[0m 5s/step - accuracy: 0.8277 - loss: 0.4043Step 64/94 - Loss: 0.4169, Accuracy: 0.8268, Time: 4.33 seconds\n",
      "\u001B[1m64/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:19\u001B[0m 5s/step - accuracy: 0.8277 - loss: 0.4045Step 65/94 - Loss: 0.4237, Accuracy: 0.8244, Time: 4.89 seconds\n",
      "\u001B[1m65/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:15\u001B[0m 5s/step - accuracy: 0.8277 - loss: 0.4048Step 66/94 - Loss: 0.4214, Accuracy: 0.8245, Time: 4.09 seconds\n",
      "\u001B[1m66/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m2:10\u001B[0m 5s/step - accuracy: 0.8276 - loss: 0.4050Step 67/94 - Loss: 0.4190, Accuracy: 0.8246, Time: 4.41 seconds\n",
      "\u001B[1m67/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m2:05\u001B[0m 5s/step - accuracy: 0.8276 - loss: 0.4053Step 68/94 - Loss: 0.4194, Accuracy: 0.8235, Time: 4.39 seconds\n",
      "\u001B[1m68/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m2:00\u001B[0m 5s/step - accuracy: 0.8275 - loss: 0.4055Step 69/94 - Loss: 0.4162, Accuracy: 0.8237, Time: 4.46 seconds\n",
      "\u001B[1m69/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:56\u001B[0m 5s/step - accuracy: 0.8275 - loss: 0.4056Step 70/94 - Loss: 0.4198, Accuracy: 0.8226, Time: 5.50 seconds\n",
      "\u001B[1m70/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:51\u001B[0m 5s/step - accuracy: 0.8274 - loss: 0.4058Step 71/94 - Loss: 0.4170, Accuracy: 0.8251, Time: 7.53 seconds\n",
      "\u001B[1m71/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:48\u001B[0m 5s/step - accuracy: 0.8274 - loss: 0.4060Step 72/94 - Loss: 0.4187, Accuracy: 0.8229, Time: 5.02 seconds\n",
      "\u001B[1m72/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:43\u001B[0m 5s/step - accuracy: 0.8273 - loss: 0.4062Step 73/94 - Loss: 0.4189, Accuracy: 0.8231, Time: 6.21 seconds\n",
      "\u001B[1m73/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:39\u001B[0m 5s/step - accuracy: 0.8272 - loss: 0.4063Step 74/94 - Loss: 0.4233, Accuracy: 0.8198, Time: 4.80 seconds\n",
      "\u001B[1m74/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:34\u001B[0m 5s/step - accuracy: 0.8271 - loss: 0.4066Step 75/94 - Loss: 0.4240, Accuracy: 0.8189, Time: 4.86 seconds\n",
      "\u001B[1m75/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:30\u001B[0m 5s/step - accuracy: 0.8270 - loss: 0.4068Step 76/94 - Loss: 0.4215, Accuracy: 0.8202, Time: 4.55 seconds\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:25\u001B[0m 5s/step - accuracy: 0.8269 - loss: 0.4070Step 77/94 - Loss: 0.4249, Accuracy: 0.8193, Time: 4.75 seconds\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:20\u001B[0m 5s/step - accuracy: 0.8268 - loss: 0.4072Step 78/94 - Loss: 0.4221, Accuracy: 0.8194, Time: 5.00 seconds\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:15\u001B[0m 5s/step - accuracy: 0.8267 - loss: 0.4074Step 79/94 - Loss: 0.4192, Accuracy: 0.8217, Time: 5.32 seconds\n",
      "\u001B[1m79/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:11\u001B[0m 5s/step - accuracy: 0.8267 - loss: 0.4076Step 80/94 - Loss: 0.4185, Accuracy: 0.8219, Time: 6.55 seconds\n",
      "\u001B[1m80/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m1:06\u001B[0m 5s/step - accuracy: 0.8266 - loss: 0.4077Step 81/94 - Loss: 0.4183, Accuracy: 0.8220, Time: 5.35 seconds\n",
      "\u001B[1m81/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m1:02\u001B[0m 5s/step - accuracy: 0.8266 - loss: 0.4078Step 82/94 - Loss: 0.4199, Accuracy: 0.8222, Time: 5.01 seconds\n",
      "\u001B[1m82/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m57s\u001B[0m 5s/step - accuracy: 0.8265 - loss: 0.4080 Step 83/94 - Loss: 0.4191, Accuracy: 0.8213, Time: 4.88 seconds\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m52s\u001B[0m 5s/step - accuracy: 0.8264 - loss: 0.4081Step 84/94 - Loss: 0.4156, Accuracy: 0.8234, Time: 4.32 seconds\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m47s\u001B[0m 5s/step - accuracy: 0.8264 - loss: 0.4082Step 85/94 - Loss: 0.4196, Accuracy: 0.8225, Time: 5.00 seconds\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m43s\u001B[0m 5s/step - accuracy: 0.8264 - loss: 0.4083Step 86/94 - Loss: 0.4198, Accuracy: 0.8207, Time: 4.83 seconds\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m38s\u001B[0m 5s/step - accuracy: 0.8263 - loss: 0.4085Step 87/94 - Loss: 0.4199, Accuracy: 0.8190, Time: 5.08 seconds\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m33s\u001B[0m 5s/step - accuracy: 0.8262 - loss: 0.4086Step 88/94 - Loss: 0.4213, Accuracy: 0.8191, Time: 4.46 seconds\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m28s\u001B[0m 5s/step - accuracy: 0.8261 - loss: 0.4087Step 89/94 - Loss: 0.4207, Accuracy: 0.8193, Time: 4.82 seconds\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m23s\u001B[0m 5s/step - accuracy: 0.8261 - loss: 0.4089Step 90/94 - Loss: 0.4212, Accuracy: 0.8176, Time: 4.55 seconds\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m19s\u001B[0m 5s/step - accuracy: 0.8260 - loss: 0.4090Step 91/94 - Loss: 0.4216, Accuracy: 0.8168, Time: 5.18 seconds\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m14s\u001B[0m 5s/step - accuracy: 0.8259 - loss: 0.4091Step 92/94 - Loss: 0.4200, Accuracy: 0.8170, Time: 4.82 seconds\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m9s\u001B[0m 5s/step - accuracy: 0.8258 - loss: 0.4093 Step 93/94 - Loss: 0.4180, Accuracy: 0.8172, Time: 4.98 seconds\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m4s\u001B[0m 5s/step - accuracy: 0.8257 - loss: 0.4094Step 94/94 - Loss: 0.4175, Accuracy: 0.8174, Time: 4.55 seconds\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5s/step - accuracy: 0.8256 - loss: 0.4094\n",
      "Epoch 2: val_loss improved from 0.69608 to 0.63417, saving model to ./mobilenetV2_checkpoints\\model_epoch_02_val_loss_0.63.keras\n",
      "--- Epoch 2 completed in 646.53 seconds ---\n",
      "\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m647s\u001B[0m 7s/step - accuracy: 0.8255 - loss: 0.4095 - val_accuracy: 0.6729 - val_loss: 0.6342 - learning_rate: 1.0000e-05\n",
      "\n",
      "--- Starting Epoch 3 ---\n",
      "Epoch 3/10\n",
      "Step 1/94 - Loss: 0.2554, Accuracy: 0.9167, Time: 28.02 seconds\n",
      "\u001B[1m 1/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m50:38\u001B[0m 33s/step - accuracy: 0.9167 - loss: 0.2554Step 2/94 - Loss: 0.3466, Accuracy: 0.8750, Time: 4.38 seconds\n",
      "\u001B[1m 2/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:31\u001B[0m 5s/step - accuracy: 0.8958 - loss: 0.3010  Step 3/94 - Loss: 0.4299, Accuracy: 0.8056, Time: 5.34 seconds\n",
      "\u001B[1m 3/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:46\u001B[0m 5s/step - accuracy: 0.8657 - loss: 0.3440Step 4/94 - Loss: 0.4135, Accuracy: 0.7917, Time: 3.90 seconds\n",
      "\u001B[1m 4/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:04\u001B[0m 5s/step - accuracy: 0.8472 - loss: 0.3613Step 5/94 - Loss: 0.4478, Accuracy: 0.8000, Time: 3.81 seconds\n",
      "\u001B[1m 5/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:39\u001B[0m 4s/step - accuracy: 0.8378 - loss: 0.3786Step 6/94 - Loss: 0.4871, Accuracy: 0.7917, Time: 3.85 seconds\n",
      "\u001B[1m 6/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:24\u001B[0m 4s/step - accuracy: 0.8301 - loss: 0.3967Step 7/94 - Loss: 0.4350, Accuracy: 0.8214, Time: 3.87 seconds\n",
      "\u001B[1m 7/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:12\u001B[0m 4s/step - accuracy: 0.8289 - loss: 0.4022Step 8/94 - Loss: 0.4361, Accuracy: 0.8229, Time: 3.79 seconds\n",
      "\u001B[1m 8/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:02\u001B[0m 4s/step - accuracy: 0.8281 - loss: 0.4064Step 9/94 - Loss: 0.4279, Accuracy: 0.8241, Time: 3.99 seconds\n",
      "\u001B[1m 9/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:55\u001B[0m 4s/step - accuracy: 0.8277 - loss: 0.4088Step 10/94 - Loss: 0.4816, Accuracy: 0.8167, Time: 3.86 seconds\n",
      "\u001B[1m10/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:48\u001B[0m 4s/step - accuracy: 0.8266 - loss: 0.4161Step 11/94 - Loss: 0.4576, Accuracy: 0.8258, Time: 4.00 seconds\n",
      "\u001B[1m11/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:43\u001B[0m 4s/step - accuracy: 0.8265 - loss: 0.4199Step 12/94 - Loss: 0.4339, Accuracy: 0.8403, Time: 3.87 seconds\n",
      "\u001B[1m12/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:37\u001B[0m 4s/step - accuracy: 0.8276 - loss: 0.4210Step 13/94 - Loss: 0.4338, Accuracy: 0.8397, Time: 3.96 seconds\n",
      "\u001B[1m13/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:32\u001B[0m 4s/step - accuracy: 0.8286 - loss: 0.4220Step 14/94 - Loss: 0.4201, Accuracy: 0.8452, Time: 3.97 seconds\n",
      "\u001B[1m14/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:27\u001B[0m 4s/step - accuracy: 0.8298 - loss: 0.4219Step 15/94 - Loss: 0.4179, Accuracy: 0.8444, Time: 3.95 seconds\n",
      "\u001B[1m15/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:22\u001B[0m 4s/step - accuracy: 0.8307 - loss: 0.4216Step 16/94 - Loss: 0.3996, Accuracy: 0.8542, Time: 3.94 seconds\n",
      "\u001B[1m16/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:17\u001B[0m 4s/step - accuracy: 0.8322 - loss: 0.4202Step 17/94 - Loss: 0.3856, Accuracy: 0.8627, Time: 3.90 seconds\n",
      "\u001B[1m17/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:12\u001B[0m 4s/step - accuracy: 0.8340 - loss: 0.4182Step 18/94 - Loss: 0.3906, Accuracy: 0.8657, Time: 3.91 seconds\n",
      "\u001B[1m18/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:08\u001B[0m 4s/step - accuracy: 0.8358 - loss: 0.4167Step 19/94 - Loss: 0.3860, Accuracy: 0.8640, Time: 3.82 seconds\n",
      "\u001B[1m19/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:03\u001B[0m 4s/step - accuracy: 0.8373 - loss: 0.4151Step 20/94 - Loss: 0.3913, Accuracy: 0.8583, Time: 3.88 seconds\n",
      "\u001B[1m20/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:58\u001B[0m 4s/step - accuracy: 0.8383 - loss: 0.4139Step 21/94 - Loss: 0.3991, Accuracy: 0.8611, Time: 3.77 seconds\n",
      "\u001B[1m21/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:53\u001B[0m 4s/step - accuracy: 0.8394 - loss: 0.4132Step 22/94 - Loss: 0.3903, Accuracy: 0.8598, Time: 3.85 seconds\n",
      "\u001B[1m22/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:48\u001B[0m 4s/step - accuracy: 0.8403 - loss: 0.4121Step 23/94 - Loss: 0.3866, Accuracy: 0.8587, Time: 3.91 seconds\n",
      "\u001B[1m23/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:44\u001B[0m 4s/step - accuracy: 0.8411 - loss: 0.4110Step 24/94 - Loss: 0.3843, Accuracy: 0.8507, Time: 3.99 seconds\n",
      "\u001B[1m24/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:40\u001B[0m 4s/step - accuracy: 0.8415 - loss: 0.4099Step 25/94 - Loss: 0.3947, Accuracy: 0.8433, Time: 4.00 seconds\n",
      "\u001B[1m25/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:36\u001B[0m 4s/step - accuracy: 0.8416 - loss: 0.4093Step 26/94 - Loss: 0.4076, Accuracy: 0.8397, Time: 3.89 seconds\n",
      "\u001B[1m26/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:32\u001B[0m 4s/step - accuracy: 0.8415 - loss: 0.4092Step 27/94 - Loss: 0.4141, Accuracy: 0.8426, Time: 3.96 seconds\n",
      "\u001B[1m27/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:28\u001B[0m 4s/step - accuracy: 0.8416 - loss: 0.4094Step 28/94 - Loss: 0.4283, Accuracy: 0.8363, Time: 3.86 seconds\n",
      "\u001B[1m28/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:23\u001B[0m 4s/step - accuracy: 0.8414 - loss: 0.4101Step 29/94 - Loss: 0.4208, Accuracy: 0.8391, Time: 3.80 seconds\n",
      "\u001B[1m29/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:19\u001B[0m 4s/step - accuracy: 0.8413 - loss: 0.4105Step 30/94 - Loss: 0.4222, Accuracy: 0.8333, Time: 3.99 seconds\n",
      "\u001B[1m30/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:15\u001B[0m 4s/step - accuracy: 0.8410 - loss: 0.4108Step 31/94 - Loss: 0.4339, Accuracy: 0.8226, Time: 3.81 seconds\n",
      "\u001B[1m31/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:10\u001B[0m 4s/step - accuracy: 0.8404 - loss: 0.4116Step 32/94 - Loss: 0.4288, Accuracy: 0.8229, Time: 3.91 seconds\n",
      "\u001B[1m32/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:06\u001B[0m 4s/step - accuracy: 0.8399 - loss: 0.4121Step 33/94 - Loss: 0.4231, Accuracy: 0.8232, Time: 3.80 seconds\n",
      "\u001B[1m33/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:02\u001B[0m 4s/step - accuracy: 0.8394 - loss: 0.4125Step 34/94 - Loss: 0.4271, Accuracy: 0.8211, Time: 3.86 seconds\n",
      "\u001B[1m34/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:58\u001B[0m 4s/step - accuracy: 0.8388 - loss: 0.4129Step 35/94 - Loss: 0.4203, Accuracy: 0.8238, Time: 3.92 seconds\n",
      "\u001B[1m35/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:54\u001B[0m 4s/step - accuracy: 0.8384 - loss: 0.4131Step 36/94 - Loss: 0.4184, Accuracy: 0.8218, Time: 3.80 seconds\n",
      "\u001B[1m36/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:50\u001B[0m 4s/step - accuracy: 0.8380 - loss: 0.4133Step 37/94 - Loss: 0.4149, Accuracy: 0.8221, Time: 3.92 seconds\n",
      "\u001B[1m37/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:45\u001B[0m 4s/step - accuracy: 0.8375 - loss: 0.4133Step 38/94 - Loss: 0.4093, Accuracy: 0.8246, Time: 3.85 seconds\n",
      "\u001B[1m38/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:41\u001B[0m 4s/step - accuracy: 0.8372 - loss: 0.4132Step 39/94 - Loss: 0.4083, Accuracy: 0.8248, Time: 3.97 seconds\n",
      "\u001B[1m39/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:37\u001B[0m 4s/step - accuracy: 0.8369 - loss: 0.4131Step 40/94 - Loss: 0.4074, Accuracy: 0.8250, Time: 3.91 seconds\n",
      "\u001B[1m40/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:33\u001B[0m 4s/step - accuracy: 0.8366 - loss: 0.4129Step 41/94 - Loss: 0.4060, Accuracy: 0.8252, Time: 4.01 seconds\n",
      "\u001B[1m41/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:29\u001B[0m 4s/step - accuracy: 0.8363 - loss: 0.4128Step 42/94 - Loss: 0.4023, Accuracy: 0.8274, Time: 3.88 seconds\n",
      "\u001B[1m42/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:25\u001B[0m 4s/step - accuracy: 0.8361 - loss: 0.4125Step 43/94 - Loss: 0.4083, Accuracy: 0.8256, Time: 3.96 seconds\n",
      "\u001B[1m43/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:21\u001B[0m 4s/step - accuracy: 0.8358 - loss: 0.4124Step 44/94 - Loss: 0.4034, Accuracy: 0.8295, Time: 3.88 seconds\n",
      "\u001B[1m44/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:17\u001B[0m 4s/step - accuracy: 0.8357 - loss: 0.4122Step 45/94 - Loss: 0.4026, Accuracy: 0.8296, Time: 4.04 seconds\n",
      "\u001B[1m45/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:14\u001B[0m 4s/step - accuracy: 0.8356 - loss: 0.4120Step 46/94 - Loss: 0.3991, Accuracy: 0.8315, Time: 4.00 seconds\n",
      "\u001B[1m46/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:10\u001B[0m 4s/step - accuracy: 0.8355 - loss: 0.4117Step 47/94 - Loss: 0.4013, Accuracy: 0.8298, Time: 3.88 seconds\n",
      "\u001B[1m47/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:06\u001B[0m 4s/step - accuracy: 0.8353 - loss: 0.4115Step 48/94 - Loss: 0.4042, Accuracy: 0.8281, Time: 4.42 seconds\n",
      "\u001B[1m48/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:02\u001B[0m 4s/step - accuracy: 0.8352 - loss: 0.4113Step 49/94 - Loss: 0.3987, Accuracy: 0.8316, Time: 4.30 seconds\n",
      "\u001B[1m49/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:58\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4111Step 50/94 - Loss: 0.3971, Accuracy: 0.8317, Time: 4.73 seconds\n",
      "\u001B[1m50/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:55\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4108Step 51/94 - Loss: 0.3972, Accuracy: 0.8301, Time: 4.53 seconds\n",
      "\u001B[1m51/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:52\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4105Step 52/94 - Loss: 0.3938, Accuracy: 0.8333, Time: 6.17 seconds\n",
      "\u001B[1m52/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:49\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4102Step 53/94 - Loss: 0.4027, Accuracy: 0.8333, Time: 8.43 seconds\n",
      "\u001B[1m53/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:49\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4101Step 54/94 - Loss: 0.3988, Accuracy: 0.8349, Time: 7.76 seconds\n",
      "\u001B[1m54/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:48\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4099Step 55/94 - Loss: 0.3971, Accuracy: 0.8348, Time: 5.48 seconds\n",
      "\u001B[1m55/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:45\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4096Step 56/94 - Loss: 0.4052, Accuracy: 0.8333, Time: 4.77 seconds\n",
      "\u001B[1m56/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:41\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4095Step 57/94 - Loss: 0.4030, Accuracy: 0.8333, Time: 4.63 seconds\n",
      "\u001B[1m57/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:37\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4094Step 58/94 - Loss: 0.3992, Accuracy: 0.8348, Time: 4.75 seconds\n",
      "\u001B[1m58/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:33\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4093Step 59/94 - Loss: 0.3998, Accuracy: 0.8362, Time: 4.22 seconds\n",
      "\u001B[1m59/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:28\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4091Step 60/94 - Loss: 0.3966, Accuracy: 0.8375, Time: 4.46 seconds\n",
      "\u001B[1m60/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:24\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4089Step 61/94 - Loss: 0.3955, Accuracy: 0.8361, Time: 4.54 seconds\n",
      "\u001B[1m61/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:20\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4087Step 62/94 - Loss: 0.3918, Accuracy: 0.8374, Time: 4.26 seconds\n",
      "\u001B[1m62/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:16\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4084Step 63/94 - Loss: 0.3919, Accuracy: 0.8360, Time: 4.59 seconds\n",
      "\u001B[1m63/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:12\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4081Step 64/94 - Loss: 0.3906, Accuracy: 0.8359, Time: 4.71 seconds\n",
      "\u001B[1m64/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:08\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4079Step 65/94 - Loss: 0.3899, Accuracy: 0.8359, Time: 4.22 seconds\n",
      "\u001B[1m65/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:04\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4076Step 66/94 - Loss: 0.3890, Accuracy: 0.8359, Time: 4.50 seconds\n",
      "\u001B[1m66/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:59\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4073Step 67/94 - Loss: 0.3911, Accuracy: 0.8371, Time: 4.27 seconds\n",
      "\u001B[1m67/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:55\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4071Step 68/94 - Loss: 0.3944, Accuracy: 0.8346, Time: 4.43 seconds\n",
      "\u001B[1m68/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:51\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4069Step 69/94 - Loss: 0.3922, Accuracy: 0.8345, Time: 4.42 seconds\n",
      "\u001B[1m69/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:47\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4067Step 70/94 - Loss: 0.3886, Accuracy: 0.8357, Time: 4.52 seconds\n",
      "\u001B[1m70/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:42\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4064Step 71/94 - Loss: 0.3886, Accuracy: 0.8345, Time: 4.44 seconds\n",
      "\u001B[1m71/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:38\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4062Step 72/94 - Loss: 0.3891, Accuracy: 0.8333, Time: 4.32 seconds\n",
      "\u001B[1m72/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:34\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4059Step 73/94 - Loss: 0.3874, Accuracy: 0.8345, Time: 4.55 seconds\n",
      "\u001B[1m73/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:30\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4057Step 74/94 - Loss: 0.3858, Accuracy: 0.8356, Time: 4.31 seconds\n",
      "\u001B[1m74/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:25\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4054Step 75/94 - Loss: 0.3874, Accuracy: 0.8356, Time: 4.17 seconds\n",
      "\u001B[1m75/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:21\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4052Step 76/94 - Loss: 0.3866, Accuracy: 0.8355, Time: 4.37 seconds\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:17\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4049Step 77/94 - Loss: 0.3838, Accuracy: 0.8377, Time: 4.21 seconds\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:12\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4046Step 78/94 - Loss: 0.3867, Accuracy: 0.8376, Time: 4.42 seconds\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:08\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4044Step 79/94 - Loss: 0.3892, Accuracy: 0.8354, Time: 4.37 seconds\n",
      "\u001B[1m79/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:04\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4042Step 80/94 - Loss: 0.3923, Accuracy: 0.8333, Time: 4.48 seconds\n",
      "\u001B[1m80/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m1:00\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4041Step 81/94 - Loss: 0.3917, Accuracy: 0.8333, Time: 4.62 seconds\n",
      "\u001B[1m81/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m55s\u001B[0m 4s/step - accuracy: 0.8351 - loss: 0.4039 Step 82/94 - Loss: 0.3903, Accuracy: 0.8343, Time: 4.49 seconds\n",
      "\u001B[1m82/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m51s\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4037Step 83/94 - Loss: 0.3953, Accuracy: 0.8313, Time: 4.34 seconds\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m47s\u001B[0m 4s/step - accuracy: 0.8350 - loss: 0.4036Step 84/94 - Loss: 0.3953, Accuracy: 0.8304, Time: 4.59 seconds\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m43s\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4035Step 85/94 - Loss: 0.3973, Accuracy: 0.8294, Time: 4.49 seconds\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m38s\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.4035Step 86/94 - Loss: 0.3946, Accuracy: 0.8314, Time: 4.46 seconds\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m34s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4034Step 87/94 - Loss: 0.3932, Accuracy: 0.8314, Time: 4.42 seconds\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m30s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4033Step 88/94 - Loss: 0.3907, Accuracy: 0.8333, Time: 4.42 seconds\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m25s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4031Step 89/94 - Loss: 0.3935, Accuracy: 0.8333, Time: 4.43 seconds\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m21s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4030Step 90/94 - Loss: 0.3902, Accuracy: 0.8352, Time: 4.33 seconds\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4029Step 91/94 - Loss: 0.3883, Accuracy: 0.8352, Time: 4.68 seconds\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m12s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4027Step 92/94 - Loss: 0.3857, Accuracy: 0.8361, Time: 4.39 seconds\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4025 Step 93/94 - Loss: 0.3842, Accuracy: 0.8369, Time: 4.34 seconds\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4023Step 94/94 - Loss: 0.3834, Accuracy: 0.8369, Time: 4.37 seconds\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8348 - loss: 0.4021\n",
      "Epoch 3: val_loss did not improve from 0.63417\n",
      "--- Epoch 3 completed in 606.82 seconds ---\n",
      "\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m607s\u001B[0m 6s/step - accuracy: 0.8349 - loss: 0.4019 - val_accuracy: 0.5271 - val_loss: 0.6828 - learning_rate: 9.0000e-06\n",
      "\n",
      "--- Starting Epoch 4 ---\n",
      "Epoch 4/10\n",
      "Step 1/94 - Loss: 0.1891, Accuracy: 0.9167, Time: 9.60 seconds\n",
      "\u001B[1m 1/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m15:14\u001B[0m 10s/step - accuracy: 0.9167 - loss: 0.1891Step 2/94 - Loss: 0.3891, Accuracy: 0.7500, Time: 4.94 seconds\n",
      "\u001B[1m 2/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:35\u001B[0m 5s/step - accuracy: 0.8333 - loss: 0.2891  Step 3/94 - Loss: 0.3173, Accuracy: 0.8056, Time: 4.95 seconds\n",
      "\u001B[1m 3/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:30\u001B[0m 5s/step - accuracy: 0.8241 - loss: 0.2985Step 4/94 - Loss: 0.3218, Accuracy: 0.7917, Time: 5.04 seconds\n",
      "\u001B[1m 4/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:28\u001B[0m 5s/step - accuracy: 0.8160 - loss: 0.3044Step 5/94 - Loss: 0.3264, Accuracy: 0.8167, Time: 4.86 seconds\n",
      "\u001B[1m 5/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:21\u001B[0m 5s/step - accuracy: 0.8161 - loss: 0.3088Step 6/94 - Loss: 0.3328, Accuracy: 0.8194, Time: 4.81 seconds\n",
      "\u001B[1m 6/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:13\u001B[0m 5s/step - accuracy: 0.8167 - loss: 0.3128Step 7/94 - Loss: 0.3342, Accuracy: 0.8095, Time: 4.78 seconds\n",
      "\u001B[1m 7/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:06\u001B[0m 5s/step - accuracy: 0.8156 - loss: 0.3158Step 8/94 - Loss: 0.3489, Accuracy: 0.8021, Time: 4.63 seconds\n",
      "\u001B[1m 8/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:58\u001B[0m 5s/step - accuracy: 0.8140 - loss: 0.3200Step 9/94 - Loss: 0.3376, Accuracy: 0.8056, Time: 4.62 seconds\n",
      "\u001B[1m 9/94\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:51\u001B[0m 5s/step - accuracy: 0.8130 - loss: 0.3219Step 10/94 - Loss: 0.3450, Accuracy: 0.8083, Time: 4.80 seconds\n",
      "\u001B[1m10/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:45\u001B[0m 5s/step - accuracy: 0.8125 - loss: 0.3242Step 11/94 - Loss: 0.3274, Accuracy: 0.8182, Time: 4.67 seconds\n",
      "\u001B[1m11/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:39\u001B[0m 5s/step - accuracy: 0.8131 - loss: 0.3245Step 12/94 - Loss: 0.3199, Accuracy: 0.8264, Time: 4.77 seconds\n",
      "\u001B[1m12/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:34\u001B[0m 5s/step - accuracy: 0.8142 - loss: 0.3241Step 13/94 - Loss: 0.3047, Accuracy: 0.8397, Time: 4.68 seconds\n",
      "\u001B[1m13/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:29\u001B[0m 5s/step - accuracy: 0.8161 - loss: 0.3226Step 14/94 - Loss: 0.3041, Accuracy: 0.8452, Time: 4.75 seconds\n",
      "\u001B[1m14/94\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:23\u001B[0m 5s/step - accuracy: 0.8182 - loss: 0.3213Step 15/94 - Loss: 0.2979, Accuracy: 0.8500, Time: 4.80 seconds\n",
      "\u001B[1m15/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:19\u001B[0m 5s/step - accuracy: 0.8203 - loss: 0.3198Step 16/94 - Loss: 0.3205, Accuracy: 0.8333, Time: 5.02 seconds\n",
      "\u001B[1m16/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:15\u001B[0m 5s/step - accuracy: 0.8211 - loss: 0.3198Step 17/94 - Loss: 0.3331, Accuracy: 0.8235, Time: 4.89 seconds\n",
      "\u001B[1m17/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:11\u001B[0m 5s/step - accuracy: 0.8213 - loss: 0.3206Step 18/94 - Loss: 0.3233, Accuracy: 0.8287, Time: 4.64 seconds\n",
      "\u001B[1m18/94\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:05\u001B[0m 5s/step - accuracy: 0.8217 - loss: 0.3207Step 19/94 - Loss: 0.3579, Accuracy: 0.8202, Time: 4.75 seconds\n",
      "\u001B[1m19/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:00\u001B[0m 5s/step - accuracy: 0.8216 - loss: 0.3227Step 20/94 - Loss: 0.3519, Accuracy: 0.8250, Time: 4.67 seconds\n",
      "\u001B[1m20/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:55\u001B[0m 5s/step - accuracy: 0.8218 - loss: 0.3242Step 21/94 - Loss: 0.3510, Accuracy: 0.8214, Time: 4.61 seconds\n",
      "\u001B[1m21/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:49\u001B[0m 5s/step - accuracy: 0.8218 - loss: 0.3254Step 22/94 - Loss: 0.3427, Accuracy: 0.8258, Time: 4.82 seconds\n",
      "\u001B[1m22/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:45\u001B[0m 5s/step - accuracy: 0.8220 - loss: 0.3262Step 23/94 - Loss: 0.3527, Accuracy: 0.8225, Time: 4.81 seconds\n",
      "\u001B[1m23/94\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:40\u001B[0m 5s/step - accuracy: 0.8220 - loss: 0.3274Step 24/94 - Loss: 0.3487, Accuracy: 0.8264, Time: 5.09 seconds\n",
      "\u001B[1m24/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:36\u001B[0m 5s/step - accuracy: 0.8222 - loss: 0.3283Step 25/94 - Loss: 0.3646, Accuracy: 0.8267, Time: 4.41 seconds\n",
      "\u001B[1m25/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:30\u001B[0m 5s/step - accuracy: 0.8223 - loss: 0.3297Step 26/94 - Loss: 0.3559, Accuracy: 0.8333, Time: 4.14 seconds\n",
      "\u001B[1m26/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:23\u001B[0m 5s/step - accuracy: 0.8228 - loss: 0.3307Step 27/94 - Loss: 0.3676, Accuracy: 0.8302, Time: 4.98 seconds\n",
      "\u001B[1m27/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:19\u001B[0m 5s/step - accuracy: 0.8230 - loss: 0.3321Step 28/94 - Loss: 0.3629, Accuracy: 0.8333, Time: 5.51 seconds\n",
      "\u001B[1m28/94\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:16\u001B[0m 5s/step - accuracy: 0.8234 - loss: 0.3332Step 29/94 - Loss: 0.3544, Accuracy: 0.8391, Time: 5.19 seconds\n",
      "\u001B[1m29/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:12\u001B[0m 5s/step - accuracy: 0.8239 - loss: 0.3339Step 30/94 - Loss: 0.3597, Accuracy: 0.8361, Time: 5.41 seconds\n",
      "\u001B[1m30/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:09\u001B[0m 5s/step - accuracy: 0.8244 - loss: 0.3348Step 31/94 - Loss: 0.3556, Accuracy: 0.8360, Time: 6.08 seconds\n",
      "\u001B[1m31/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:07\u001B[0m 5s/step - accuracy: 0.8247 - loss: 0.3355Step 32/94 - Loss: 0.3730, Accuracy: 0.8281, Time: 6.10 seconds\n",
      "\u001B[1m32/94\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:04\u001B[0m 5s/step - accuracy: 0.8248 - loss: 0.3366Step 33/94 - Loss: 0.3678, Accuracy: 0.8333, Time: 5.32 seconds\n",
      "\u001B[1m33/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m5:00\u001B[0m 5s/step - accuracy: 0.8251 - loss: 0.3376Step 34/94 - Loss: 0.3603, Accuracy: 0.8382, Time: 5.06 seconds\n",
      "\u001B[1m34/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:56\u001B[0m 5s/step - accuracy: 0.8255 - loss: 0.3382Step 35/94 - Loss: 0.3628, Accuracy: 0.8381, Time: 4.03 seconds\n",
      "\u001B[1m35/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:49\u001B[0m 5s/step - accuracy: 0.8258 - loss: 0.3389Step 36/94 - Loss: 0.3680, Accuracy: 0.8333, Time: 4.14 seconds\n",
      "\u001B[1m36/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:43\u001B[0m 5s/step - accuracy: 0.8260 - loss: 0.3397Step 37/94 - Loss: 0.3681, Accuracy: 0.8311, Time: 3.97 seconds\n",
      "\u001B[1m37/94\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m4:37\u001B[0m 5s/step - accuracy: 0.8262 - loss: 0.3405Step 38/94 - Loss: 0.3630, Accuracy: 0.8333, Time: 3.85 seconds\n",
      "\u001B[1m38/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:30\u001B[0m 5s/step - accuracy: 0.8264 - loss: 0.3411Step 39/94 - Loss: 0.3574, Accuracy: 0.8355, Time: 4.05 seconds\n",
      "\u001B[1m39/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:24\u001B[0m 5s/step - accuracy: 0.8266 - loss: 0.3415Step 40/94 - Loss: 0.3524, Accuracy: 0.8396, Time: 3.89 seconds\n",
      "\u001B[1m40/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:18\u001B[0m 5s/step - accuracy: 0.8269 - loss: 0.3418Step 41/94 - Loss: 0.3504, Accuracy: 0.8394, Time: 3.87 seconds\n",
      "\u001B[1m41/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:12\u001B[0m 5s/step - accuracy: 0.8272 - loss: 0.3420Step 42/94 - Loss: 0.3475, Accuracy: 0.8413, Time: 3.89 seconds\n",
      "\u001B[1m42/94\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m4:06\u001B[0m 5s/step - accuracy: 0.8276 - loss: 0.3421Step 43/94 - Loss: 0.3427, Accuracy: 0.8430, Time: 3.96 seconds\n",
      "\u001B[1m43/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m4:01\u001B[0m 5s/step - accuracy: 0.8279 - loss: 0.3421Step 44/94 - Loss: 0.3382, Accuracy: 0.8466, Time: 3.89 seconds\n",
      "\u001B[1m44/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:55\u001B[0m 5s/step - accuracy: 0.8284 - loss: 0.3421Step 45/94 - Loss: 0.3348, Accuracy: 0.8481, Time: 3.91 seconds\n",
      "\u001B[1m45/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:49\u001B[0m 5s/step - accuracy: 0.8288 - loss: 0.3419Step 46/94 - Loss: 0.3330, Accuracy: 0.8478, Time: 3.88 seconds\n",
      "\u001B[1m46/94\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:44\u001B[0m 5s/step - accuracy: 0.8292 - loss: 0.3417Step 47/94 - Loss: 0.3276, Accuracy: 0.8511, Time: 3.88 seconds\n",
      "\u001B[1m47/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:38\u001B[0m 5s/step - accuracy: 0.8297 - loss: 0.3414Step 48/94 - Loss: 0.3345, Accuracy: 0.8455, Time: 3.95 seconds\n",
      "\u001B[1m48/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:33\u001B[0m 5s/step - accuracy: 0.8300 - loss: 0.3413Step 49/94 - Loss: 0.3323, Accuracy: 0.8469, Time: 3.84 seconds\n",
      "\u001B[1m49/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:28\u001B[0m 5s/step - accuracy: 0.8303 - loss: 0.3411Step 50/94 - Loss: 0.3288, Accuracy: 0.8483, Time: 4.01 seconds\n",
      "\u001B[1m50/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:22\u001B[0m 5s/step - accuracy: 0.8307 - loss: 0.3408Step 51/94 - Loss: 0.3280, Accuracy: 0.8480, Time: 3.82 seconds\n",
      "\u001B[1m51/94\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m3:17\u001B[0m 5s/step - accuracy: 0.8310 - loss: 0.3406Step 52/94 - Loss: 0.3238, Accuracy: 0.8510, Time: 3.98 seconds\n",
      "\u001B[1m52/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m3:12\u001B[0m 5s/step - accuracy: 0.8314 - loss: 0.3403Step 53/94 - Loss: 0.3226, Accuracy: 0.8522, Time: 4.01 seconds\n",
      "\u001B[1m53/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m3:07\u001B[0m 5s/step - accuracy: 0.8318 - loss: 0.3399Step 54/94 - Loss: 0.3207, Accuracy: 0.8534, Time: 3.97 seconds\n",
      "\u001B[1m54/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m3:02\u001B[0m 5s/step - accuracy: 0.8322 - loss: 0.3396Step 55/94 - Loss: 0.3235, Accuracy: 0.8515, Time: 4.02 seconds\n",
      "\u001B[1m55/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:57\u001B[0m 5s/step - accuracy: 0.8326 - loss: 0.3393Step 56/94 - Loss: 0.3191, Accuracy: 0.8542, Time: 3.96 seconds\n",
      "\u001B[1m56/94\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:52\u001B[0m 5s/step - accuracy: 0.8330 - loss: 0.3389Step 57/94 - Loss: 0.3172, Accuracy: 0.8553, Time: 3.90 seconds\n",
      "\u001B[1m57/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:47\u001B[0m 5s/step - accuracy: 0.8333 - loss: 0.3385Step 58/94 - Loss: 0.3144, Accuracy: 0.8563, Time: 3.87 seconds\n",
      "\u001B[1m58/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:42\u001B[0m 5s/step - accuracy: 0.8337 - loss: 0.3381Step 59/94 - Loss: 0.3115, Accuracy: 0.8573, Time: 3.89 seconds\n",
      "\u001B[1m59/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:37\u001B[0m 5s/step - accuracy: 0.8341 - loss: 0.3377Step 60/94 - Loss: 0.3078, Accuracy: 0.8597, Time: 4.28 seconds\n",
      "\u001B[1m60/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:33\u001B[0m 5s/step - accuracy: 0.8346 - loss: 0.3372Step 61/94 - Loss: 0.3126, Accuracy: 0.8566, Time: 3.83 seconds\n",
      "\u001B[1m61/94\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:28\u001B[0m 4s/step - accuracy: 0.8349 - loss: 0.3368Step 62/94 - Loss: 0.3116, Accuracy: 0.8548, Time: 3.88 seconds\n",
      "\u001B[1m62/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:23\u001B[0m 4s/step - accuracy: 0.8353 - loss: 0.3364Step 63/94 - Loss: 0.3149, Accuracy: 0.8532, Time: 3.85 seconds\n",
      "\u001B[1m63/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:18\u001B[0m 4s/step - accuracy: 0.8355 - loss: 0.3360Step 64/94 - Loss: 0.3129, Accuracy: 0.8555, Time: 4.29 seconds\n",
      "\u001B[1m64/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:14\u001B[0m 4s/step - accuracy: 0.8358 - loss: 0.3357Step 65/94 - Loss: 0.3101, Accuracy: 0.8577, Time: 4.29 seconds\n",
      "\u001B[1m65/94\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m2:09\u001B[0m 4s/step - accuracy: 0.8362 - loss: 0.3353Step 66/94 - Loss: 0.3060, Accuracy: 0.8598, Time: 4.16 seconds\n",
      "\u001B[1m66/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m2:04\u001B[0m 4s/step - accuracy: 0.8365 - loss: 0.3348Step 67/94 - Loss: 0.3057, Accuracy: 0.8607, Time: 4.00 seconds\n",
      "\u001B[1m67/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m2:00\u001B[0m 4s/step - accuracy: 0.8369 - loss: 0.3344Step 68/94 - Loss: 0.3112, Accuracy: 0.8603, Time: 4.10 seconds\n",
      "\u001B[1m68/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:55\u001B[0m 4s/step - accuracy: 0.8372 - loss: 0.3340Step 69/94 - Loss: 0.3122, Accuracy: 0.8599, Time: 4.02 seconds\n",
      "\u001B[1m69/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:51\u001B[0m 4s/step - accuracy: 0.8376 - loss: 0.3337Step 70/94 - Loss: 0.3102, Accuracy: 0.8619, Time: 4.11 seconds\n",
      "\u001B[1m70/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:46\u001B[0m 4s/step - accuracy: 0.8379 - loss: 0.3334Step 71/94 - Loss: 0.3102, Accuracy: 0.8627, Time: 4.02 seconds\n",
      "\u001B[1m71/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:41\u001B[0m 4s/step - accuracy: 0.8383 - loss: 0.3331Step 72/94 - Loss: 0.3104, Accuracy: 0.8623, Time: 3.92 seconds\n",
      "\u001B[1m72/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:37\u001B[0m 4s/step - accuracy: 0.8386 - loss: 0.3328Step 73/94 - Loss: 0.3110, Accuracy: 0.8619, Time: 3.99 seconds\n",
      "\u001B[1m73/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:32\u001B[0m 4s/step - accuracy: 0.8389 - loss: 0.3325Step 74/94 - Loss: 0.3079, Accuracy: 0.8637, Time: 3.96 seconds\n",
      "\u001B[1m74/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:28\u001B[0m 4s/step - accuracy: 0.8393 - loss: 0.3321Step 75/94 - Loss: 0.3079, Accuracy: 0.8633, Time: 4.08 seconds\n",
      "\u001B[1m75/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:23\u001B[0m 4s/step - accuracy: 0.8396 - loss: 0.3318Step 76/94 - Loss: 0.3058, Accuracy: 0.8640, Time: 4.16 seconds\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:19\u001B[0m 4s/step - accuracy: 0.8399 - loss: 0.3315Step 77/94 - Loss: 0.3085, Accuracy: 0.8636, Time: 4.00 seconds\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:14\u001B[0m 4s/step - accuracy: 0.8402 - loss: 0.3312Step 78/94 - Loss: 0.3072, Accuracy: 0.8643, Time: 3.94 seconds\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:10\u001B[0m 4s/step - accuracy: 0.8405 - loss: 0.3309Step 79/94 - Loss: 0.3052, Accuracy: 0.8650, Time: 4.17 seconds\n",
      "\u001B[1m79/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:05\u001B[0m 4s/step - accuracy: 0.8408 - loss: 0.3305Step 80/94 - Loss: 0.3021, Accuracy: 0.8667, Time: 4.42 seconds\n",
      "\u001B[1m80/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m1:01\u001B[0m 4s/step - accuracy: 0.8412 - loss: 0.3302Step 81/94 - Loss: 0.2992, Accuracy: 0.8683, Time: 4.40 seconds\n",
      "\u001B[1m81/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m57s\u001B[0m 4s/step - accuracy: 0.8415 - loss: 0.3298 Step 82/94 - Loss: 0.2982, Accuracy: 0.8689, Time: 4.16 seconds\n",
      "\u001B[1m82/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m52s\u001B[0m 4s/step - accuracy: 0.8418 - loss: 0.3294Step 83/94 - Loss: 0.2965, Accuracy: 0.8695, Time: 3.84 seconds\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m48s\u001B[0m 4s/step - accuracy: 0.8422 - loss: 0.3290Step 84/94 - Loss: 0.2965, Accuracy: 0.8700, Time: 4.09 seconds\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m43s\u001B[0m 4s/step - accuracy: 0.8425 - loss: 0.3286Step 85/94 - Loss: 0.2935, Accuracy: 0.8716, Time: 3.78 seconds\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m39s\u001B[0m 4s/step - accuracy: 0.8428 - loss: 0.3282Step 86/94 - Loss: 0.2928, Accuracy: 0.8721, Time: 4.02 seconds\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m34s\u001B[0m 4s/step - accuracy: 0.8432 - loss: 0.3278Step 87/94 - Loss: 0.2928, Accuracy: 0.8716, Time: 3.99 seconds\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m30s\u001B[0m 4s/step - accuracy: 0.8435 - loss: 0.3274Step 88/94 - Loss: 0.2938, Accuracy: 0.8703, Time: 4.27 seconds\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.8438 - loss: 0.3270Step 89/94 - Loss: 0.2929, Accuracy: 0.8708, Time: 4.32 seconds\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m21s\u001B[0m 4s/step - accuracy: 0.8441 - loss: 0.3266Step 90/94 - Loss: 0.2930, Accuracy: 0.8704, Time: 4.00 seconds\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.8444 - loss: 0.3263Step 91/94 - Loss: 0.2922, Accuracy: 0.8709, Time: 3.89 seconds\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m13s\u001B[0m 4s/step - accuracy: 0.8447 - loss: 0.3259Step 92/94 - Loss: 0.2920, Accuracy: 0.8705, Time: 3.89 seconds\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.8450 - loss: 0.3255 Step 93/94 - Loss: 0.2897, Accuracy: 0.8719, Time: 3.80 seconds\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.8453 - loss: 0.3251Step 94/94 - Loss: 0.2924, Accuracy: 0.8706, Time: 3.76 seconds\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8455 - loss: 0.3248\n",
      "Epoch 4: val_loss improved from 0.63417 to 0.58194, saving model to ./mobilenetV2_checkpoints\\model_epoch_04_val_loss_0.58.keras\n",
      "--- Epoch 4 completed in 564.88 seconds ---\n",
      "\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m565s\u001B[0m 6s/step - accuracy: 0.8458 - loss: 0.3244 - val_accuracy: 0.6229 - val_loss: 0.5819 - learning_rate: 8.1000e-06\n",
      "\n",
      "--- Starting Epoch 5 ---\n",
      "Epoch 5/10\n",
      "Step 1/94 - Loss: 0.0242, Accuracy: 1.0000, Time: 8.08 seconds\n",
      "\u001B[1m 1/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m12:37\u001B[0m 8s/step - accuracy: 1.0000 - loss: 0.0242Step 2/94 - Loss: 0.0988, Accuracy: 1.0000, Time: 4.10 seconds\n",
      "\n",
      "Early stopping triggered at batch 2: loss = 0.0988\n",
      "\u001B[1m 2/94\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m6:17\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0615 \n",
      "Epoch 5: val_loss improved from 0.58194 to 0.55969, saving model to ./mobilenetV2_checkpoints\\model_epoch_05_val_loss_0.56.keras\n",
      "--- Epoch 5 completed in 166.34 seconds ---\n",
      "\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m166s\u001B[0m 2s/step - accuracy: 1.0000 - loss: 0.0980 - val_accuracy: 0.6396 - val_loss: 0.5597 - learning_rate: 7.2900e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x251aee75bb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6ef6982f39c9699a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
