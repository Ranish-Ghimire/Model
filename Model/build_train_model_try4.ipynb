{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T12:15:41.026171Z",
     "start_time": "2024-12-20T12:14:52.260264Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-19T04:15:59.866197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_path, y_path, indices, batch_size):\n",
    "        self.X = np.memmap(X_path, dtype='float32', mode='r', shape=(726, 15, 224, 224, 3))\n",
    "        self.y = np.memmap(y_path, dtype='int32', mode='r', shape=(726,))\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X_batch = self.X[batch_indices]\n",
    "        X_batch = preprocess_input(X_batch)\n",
    "        y_batch = np.eye(2)[self.y[batch_indices]]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "class StepTimerCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\n--- Starting Epoch {epoch + 1} ---\")\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        print(f\"--- Epoch {epoch + 1} completed in {epoch_time:.2f} seconds ---\\n\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.step_start_time = time.time()\n",
    "        print(f\"Step {batch + 1}/{self.params['steps']} - \", end=\"\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        step_time = time.time() - self.step_start_time\n",
    "        print(f\"Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}, Time: {step_time:.2f} seconds\")\n",
    "        \n",
    "class BatchEarlyStopping(Callback):\n",
    "    def __init__(self, monitor='loss', threshold=0.1, patience=5):\n",
    "        \"\"\"\n",
    "        Early stopping within the same epoch based on a monitored metric.\n",
    "        Args:\n",
    "            monitor: Metric to monitor ('loss', 'accuracy', etc.).\n",
    "            threshold: Threshold value for stopping (e.g., loss < 0.1).\n",
    "            patience: Number of batches to wait for improvement before stopping.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        current_value = logs.get(self.monitor)\n",
    "        if current_value is not None:\n",
    "            if current_value < self.threshold:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    print(f\"\\nEarly stopping triggered at batch {batch + 1}: {self.monitor} = {current_value:.4f}\")\n",
    "                    self.model.stop_training = True\n",
    "            else:\n",
    "                self.wait = 0 \n",
    "\n",
    "batch_early_stopping_callback = BatchEarlyStopping(\n",
    "    monitor='loss',     \n",
    "    threshold=0.1,       \n",
    "    patience=2          \n",
    ")\n",
    "\n",
    "def build_cnn_lstm_model(seq_length, height, width, channels, num_classes):\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(height, width, channels))\n",
    "    base_model.trainable = False  \n",
    "\n",
    "    sequence_input = Input(shape=(seq_length, height, width, channels))\n",
    "    \n",
    "    cnn_features = TimeDistributed(base_model)(sequence_input)\n",
    "    flattened_features = TimeDistributed(Flatten())(cnn_features)\n",
    "\n",
    "    lstm_out = LSTM(128)(flattened_features)\n",
    "    lstm_out = Dropout(0.5)(lstm_out)\n",
    "\n",
    "    dense_out = Dense(64, activation='relu')(lstm_out)\n",
    "    dense_out = Dropout(0.5)(dense_out)\n",
    "    output = Dense(num_classes, activation='softmax')(dense_out)\n",
    "\n",
    "    model = Model(inputs=sequence_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_lstm_model = build_cnn_lstm_model(seq_length=15, height=224, width=224, channels=3, num_classes=2)\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "indices = np.arange(726)\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_combined.dat', r'E:\\PosePerfect\\Dataset Creation\\y_combined.dat', train_indices, batch_size=5)\n",
    "val_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_combined.dat', r'E:\\PosePerfect\\Dataset Creation\\y_combined.dat', val_indices, batch_size=5)\n",
    "\n",
    "checkpoint_dir = './Checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}.keras')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',  \n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2: \n",
    "        return lr\n",
    "    return lr * 0.9 \n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "step_timer_callback = StepTimerCallback()\n",
    "\n",
    "cnn_lstm_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=[checkpoint_callback, lr_callback, step_timer_callback, batch_early_stopping_callback],\n",
    "    verbose=1  \n",
    ")\n"
   ],
   "id": "7aff14832bb21254",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T10:38:02.631637Z",
     "start_time": "2024-12-19T09:52:28.265998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Flatten, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_path, y_path, indices, batch_size):\n",
    "        self.X = np.memmap(X_path, dtype='float32', mode='r', shape=(726, 15, 224, 224, 3))\n",
    "        self.y = np.memmap(y_path, dtype='int32', mode='r', shape=(726,))\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X_batch = self.X[batch_indices]\n",
    "        X_batch = preprocess_input(X_batch)  \n",
    "        y_batch = np.eye(2)[self.y[batch_indices]]  \n",
    "        return X_batch, y_batch\n",
    "\n",
    "class StepTimerCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\n--- Starting Epoch {epoch + 1} ---\")\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        print(f\"--- Epoch {epoch + 1} completed in {epoch_time:.2f} seconds ---\\n\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.step_start_time = time.time()\n",
    "        print(f\"Step {batch + 1}/{self.params['steps']} - \", end=\"\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        step_time = time.time() - self.step_start_time\n",
    "        print(f\"Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}, Time: {step_time:.2f} seconds\")\n",
    "\n",
    "class BatchEarlyStopping(Callback):\n",
    "    def __init__(self, monitor='loss', threshold=0.1, patience=5):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        current_value = logs.get(self.monitor)\n",
    "        if current_value is not None and current_value < self.threshold:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"\\nEarly stopping triggered at batch {batch + 1}: {self.monitor} = {current_value:.4f}\")\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0\n",
    "\n",
    "batch_early_stopping_callback = BatchEarlyStopping(monitor='loss', threshold=0.1, patience=2)\n",
    "\n",
    "def build_cnn_lstm_model(seq_length, height, width, channels, num_classes):\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(height, width, channels))\n",
    "    base_model.trainable = False  # Freeze the pre-trained model\n",
    "\n",
    "    sequence_input = Input(shape=(seq_length, height, width, channels))\n",
    "    cnn_features = TimeDistributed(base_model)(sequence_input)\n",
    "    flattened_features = TimeDistributed(Flatten())(cnn_features)\n",
    "\n",
    "    lstm_out = LSTM(128)(flattened_features)\n",
    "    lstm_out = Dropout(0.5)(lstm_out)\n",
    "\n",
    "    dense_out = Dense(64, activation='relu')(lstm_out)\n",
    "    dense_out = Dropout(0.5)(dense_out)\n",
    "    output = Dense(num_classes, activation='softmax')(dense_out)\n",
    "\n",
    "    model = Model(inputs=sequence_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "indices = np.arange(726)\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_combined.dat', r'E:\\PosePerfect\\Dataset Creation\\y_combined.dat', train_indices, batch_size=5)\n",
    "val_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_combined.dat', r'E:\\PosePerfect\\Dataset Creation\\y_combined.dat', val_indices, batch_size=5)\n",
    "\n",
    "checkpoint_dir = './Checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}.keras')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    return lr * 0.9\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "latest_checkpoint = './Checkpoints/model_epoch_06_val_loss_0.68.keras'  # Update to your latest checkpoint\n",
    "\n",
    "cnn_lstm_model = load_model(latest_checkpoint)\n",
    "\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "cnn_lstm_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10, \n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=[checkpoint_callback, lr_callback, StepTimerCallback(), batch_early_stopping_callback],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "e7df62bf9af81319",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:43:36.289836Z",
     "start_time": "2024-12-19T11:42:51.943871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_loss, val_accuracy = cnn_lstm_model.evaluate(val_gen, verbose=1)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ],
   "id": "aa37c2b16ecae837",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:46:18.027568Z",
     "start_time": "2024-12-19T11:45:04.498254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_true = np.concatenate([val_gen[i][1] for i in range(len(val_gen))])\n",
    "y_true = np.argmax(y_true, axis=1)  \n",
    "\n",
    "y_pred = cnn_lstm_model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ],
   "id": "39734890f7545d7",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:48:21.741935Z",
     "start_time": "2024-12-19T11:48:15.843121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saved_model_path = './saved_model/cnn_lstm_model_try2.h5'\n",
    "\n",
    "cnn_lstm_model.save(saved_model_path)\n",
    "\n",
    "print(f\"Model saved to {saved_model_path}\")"
   ],
   "id": "76aafcbd09da2faf",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T12:54:01.893679Z",
     "start_time": "2024-12-19T12:53:16.194007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "model_path = './Checkpoints/model_epoch_10_val_loss_0.67.keras'\n",
    "cnn_lstm_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "example_input = np.memmap(\n",
    "    r'E:\\PosePerfect\\Model\\Process Example\\X_exam_7.dat',\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(2, 15, 224, 224, 3)\n",
    ")\n",
    "\n",
    "example_input_writable = np.array(example_input) \n",
    "\n",
    "example_input_preprocessed = preprocess_input(example_input_writable)\n",
    "print(\"Input preprocessed successfully!\")\n",
    "\n",
    "print(f\"Input Shape: {example_input_preprocessed.shape}\")\n",
    "print(f\"Input Summary: Min={example_input_preprocessed.min()}, Max={example_input_preprocessed.max()}, Mean={example_input_preprocessed.mean()}\")\n",
    "\n",
    "predictions = cnn_lstm_model.predict(example_input_preprocessed)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Raw Predictions:\", predictions)\n",
    "print(\"Predicted Class Probabilities:\", predictions[0]) \n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ],
   "id": "f40c44155ba1d8b1",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:14:44.753196Z",
     "start_time": "2024-12-19T15:25:39.259359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Flatten, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_path, y_path, indices, batch_size):\n",
    "        self.X = np.memmap(X_path, dtype='float32', mode='r', shape=(726, 15, 224, 224, 3))\n",
    "        self.y = np.memmap(y_path, dtype='int32', mode='r', shape=(726,))\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X_batch = self.X[batch_indices]\n",
    "        X_batch = preprocess_input(X_batch)  \n",
    "        y_batch = np.eye(2)[self.y[batch_indices]]  \n",
    "        return X_batch, y_batch\n",
    "\n",
    "class StepTimerCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\n--- Starting Epoch {epoch + 1} ---\")\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        print(f\"--- Epoch {epoch + 1} completed in {epoch_time:.2f} seconds ---\\n\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.step_start_time = time.time()\n",
    "        print(f\"Step {batch + 1}/{self.params['steps']} - \", end=\"\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        step_time = time.time() - self.step_start_time\n",
    "        print(f\"Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}, Time: {step_time:.2f} seconds\")\n",
    "\n",
    "class BatchEarlyStopping(Callback):\n",
    "    def __init__(self, monitor='loss', threshold=0.1, patience=5):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        current_value = logs.get(self.monitor)\n",
    "        if current_value is not None and current_value < self.threshold:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"\\nEarly stopping triggered at batch {batch + 1}: {self.monitor} = {current_value:.4f}\")\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0\n",
    "\n",
    "batch_early_stopping_callback = BatchEarlyStopping(monitor='loss', threshold=0.1, patience=2)\n",
    "\n",
    "def build_cnn_lstm_model(seq_length, height, width, channels, num_classes):\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(height, width, channels))\n",
    "    base_model.trainable = False  # Freeze the pre-trained model\n",
    "\n",
    "    sequence_input = Input(shape=(seq_length, height, width, channels))\n",
    "    cnn_features = TimeDistributed(base_model)(sequence_input)\n",
    "    flattened_features = TimeDistributed(Flatten())(cnn_features)\n",
    "\n",
    "    lstm_out = LSTM(128)(flattened_features)\n",
    "    lstm_out = Dropout(0.5)(lstm_out)\n",
    "\n",
    "    dense_out = Dense(64, activation='relu')(lstm_out)\n",
    "    dense_out = Dropout(0.5)(dense_out)\n",
    "    output = Dense(num_classes, activation='softmax')(dense_out)\n",
    "\n",
    "    model = Model(inputs=sequence_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "indices = np.arange(726)\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_combined.dat', r'E:\\PosePerfect\\Dataset Creation\\y_combined.dat', train_indices, batch_size=5)\n",
    "val_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_combined.dat', r'E:\\PosePerfect\\Dataset Creation\\y_combined.dat', val_indices, batch_size=5)\n",
    "\n",
    "checkpoint_dir = './MoreCheckpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}.keras')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    return lr * 0.9\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "latest_checkpoint = './Checkpoints/model_epoch_10_val_loss_0.67.keras'  # Update to your latest checkpoint\n",
    "\n",
    "cnn_lstm_model = load_model(latest_checkpoint)\n",
    "\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "cnn_lstm_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10, \n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=[checkpoint_callback, lr_callback, StepTimerCallback(), batch_early_stopping_callback],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "2b777e381650b625",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:17:37.844983Z",
     "start_time": "2024-12-19T16:16:58.546951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_loss, val_accuracy = cnn_lstm_model.evaluate(val_gen, verbose=1)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ],
   "id": "62433c187c6d5efe",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:19:03.827724Z",
     "start_time": "2024-12-19T16:18:08.174307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_true = np.concatenate([val_gen[i][1] for i in range(len(val_gen))])\n",
    "y_true = np.argmax(y_true, axis=1)  \n",
    "\n",
    "y_pred = cnn_lstm_model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ],
   "id": "223a9203297dc797",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:25:11.099314Z",
     "start_time": "2024-12-19T16:24:41.495400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "model_path = r'E:\\PosePerfect\\Model\\MoreCheckpoints\\model_epoch_10_val_loss_0.60.keras'\n",
    "cnn_lstm_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "example_input = np.memmap(\n",
    "    r'E:\\PosePerfect\\Model\\Process Example\\X_exam_7.dat',\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(2, 15, 224, 224, 3)\n",
    ")\n",
    "\n",
    "example_input_writable = np.array(example_input) \n",
    "\n",
    "example_input_preprocessed = preprocess_input(example_input_writable)\n",
    "print(\"Input preprocessed successfully!\")\n",
    "\n",
    "print(f\"Input Shape: {example_input_preprocessed.shape}\")\n",
    "print(f\"Input Summary: Min={example_input_preprocessed.min()}, Max={example_input_preprocessed.max()}, Mean={example_input_preprocessed.mean()}\")\n",
    "\n",
    "predictions = cnn_lstm_model.predict(example_input_preprocessed)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Raw Predictions:\", predictions)\n",
    "print(\"Predicted Class Probabilities:\", predictions[0]) \n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ],
   "id": "752ce9beacc150ea",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:27:24.889086Z",
     "start_time": "2024-12-19T16:27:24.856844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_input = np.memmap(\n",
    "    r'E:\\PosePerfect\\Model\\Process Example\\X_exam_1.dat',\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(2, 15, 224, 224, 3)\n",
    ")"
   ],
   "id": "c1afda59f5212251",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:28:50.777139Z",
     "start_time": "2024-12-19T16:28:25.041129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "model_path = r'E:\\PosePerfect\\Model\\MoreCheckpoints\\model_epoch_10_val_loss_0.60.keras'\n",
    "cnn_lstm_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "example_input = np.memmap(\n",
    "    r'E:\\PosePerfect\\Model\\Process Example\\X_exam_1.dat',\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(2, 15, 224, 224, 3)\n",
    ")\n",
    "\n",
    "example_input_writable = np.array(example_input) \n",
    "\n",
    "example_input_preprocessed = preprocess_input(example_input_writable)\n",
    "print(\"Input preprocessed successfully!\")\n",
    "\n",
    "print(f\"Input Shape: {example_input_preprocessed.shape}\")\n",
    "print(f\"Input Summary: Min={example_input_preprocessed.min()}, Max={example_input_preprocessed.max()}, Mean={example_input_preprocessed.mean()}\")\n",
    "\n",
    "predictions = cnn_lstm_model.predict(example_input_preprocessed)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Raw Predictions:\", predictions)\n",
    "print(\"Predicted Class Probabilities:\", predictions[0]) \n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ],
   "id": "8901441e335e0d14",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T06:19:23.739390Z",
     "start_time": "2024-12-20T06:18:43.071124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "model_path = r'E:\\PosePerfect\\Model\\MoreCheckpoints\\model_epoch_10_val_loss_0.60.keras'\n",
    "cnn_lstm_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "example_input = np.memmap(\n",
    "    r'E:\\PosePerfect\\Model\\Process Example\\X_exam_8.dat',\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(2, 15, 224, 224, 3)\n",
    ")\n",
    "\n",
    "example_input_writable = np.array(example_input) \n",
    "\n",
    "example_input_preprocessed = preprocess_input(example_input_writable)\n",
    "print(\"Input preprocessed successfully!\")\n",
    "\n",
    "print(f\"Input Shape: {example_input_preprocessed.shape}\")\n",
    "print(f\"Input Summary: Min={example_input_preprocessed.min()}, Max={example_input_preprocessed.max()}, Mean={example_input_preprocessed.mean()}\")\n",
    "\n",
    "predictions = cnn_lstm_model.predict(example_input_preprocessed)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Raw Predictions:\", predictions)\n",
    "print(\"Predicted Class Probabilities:\", predictions[0]) \n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ],
   "id": "9c4a5b754ad6971b",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:19:40.125348Z",
     "start_time": "2024-12-20T12:19:00.097817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "model_path = r'E:\\PosePerfect\\Model\\MoreCheckpoints\\model_epoch_10_val_loss_0.60.keras'\n",
    "cnn_lstm_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "example_input = np.memmap(\n",
    "    r'E:\\PosePerfect\\Model\\Process Example\\X_exam_7.dat',\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(2, 15, 224, 224, 3)\n",
    ")\n",
    "\n",
    "example_input_writable = np.array(example_input) \n",
    "\n",
    "example_input_preprocessed = preprocess_input(example_input_writable)\n",
    "print(\"Input preprocessed successfully!\")\n",
    "\n",
    "print(f\"Input Shape: {example_input_preprocessed.shape}\")\n",
    "print(f\"Input Summary: Min={example_input_preprocessed.min()}, Max={example_input_preprocessed.max()}, Mean={example_input_preprocessed.mean()}\")\n",
    "\n",
    "predictions = cnn_lstm_model.predict(example_input_preprocessed)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Raw Predictions:\", predictions)\n",
    "print(\"Predicted Class Probabilities:\", predictions[0]) \n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ],
   "id": "eba7d8a19c131ab4",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "a42b7b88a3c53ae3",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
