{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-27T07:44:41.404026Z",
     "start_time": "2024-12-27T07:43:51.235466Z"
    }
   },
   "source": [
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T08:24:40.729098Z",
     "start_time": "2024-12-27T07:44:51.306294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def unfreeze_and_fine_tune(model, num_layers_to_unfreeze):\n",
    "    \"\"\"\n",
    "    Unfreeze the last n layers of the MobileNet base model for fine-tuning.\n",
    "    \n",
    "    Args:\n",
    "        model: The loaded Keras model containing MobileNet\n",
    "        num_layers_to_unfreeze: Number of layers to unfreeze from the end\n",
    "    \n",
    "    Returns:\n",
    "        Modified model ready for fine-tuning\n",
    "    \"\"\"\n",
    "    # First, we need to find the MobileNet layers within the TimeDistributed layer\n",
    "    time_distributed_layers = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.TimeDistributed):\n",
    "            # Check if the wrapped layer is part of MobileNet\n",
    "            if hasattr(layer.layer, 'name') and 'mobilenet' in layer.layer.name.lower():\n",
    "                time_distributed_layers.append(layer)\n",
    "    \n",
    "    if not time_distributed_layers:\n",
    "        raise ValueError(\"Could not find TimeDistributed layers containing MobileNet\")\n",
    "    \n",
    "    # Print the model structure to understand what we're working with\n",
    "    print(\"Model Layer Structure:\")\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.TimeDistributed):\n",
    "            print(f\"TimeDistributed wrapping: {layer.layer.__class__.__name__}\")\n",
    "            if hasattr(layer.layer, 'layers'):\n",
    "                print(\"Sublayers:\")\n",
    "                for sublayer in layer.layer.layers:\n",
    "                    print(f\"  - {sublayer.name}: {sublayer.__class__.__name__}\")\n",
    "    \n",
    "    # Start by freezing all layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        if isinstance(layer, tf.keras.layers.TimeDistributed):\n",
    "            if hasattr(layer.layer, 'trainable'):\n",
    "                layer.layer.trainable = False\n",
    "    \n",
    "    # Unfreeze the LSTM layers (they're usually after TimeDistributed layers)\n",
    "    lstm_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.LSTM)]\n",
    "    for layer in lstm_layers:\n",
    "        layer.trainable = True\n",
    "        print(f\"Unfroze LSTM layer: {layer.name}\")\n",
    "    \n",
    "    # Unfreeze the dense layers at the end\n",
    "    dense_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Dense)]\n",
    "    for layer in dense_layers:\n",
    "        layer.trainable = True\n",
    "        print(f\"Unfroze Dense layer: {layer.name}\")\n",
    "    \n",
    "    # For the TimeDistributed MobileNet layers, we'll selectively unfreeze the last few layers\n",
    "    for td_layer in time_distributed_layers:\n",
    "        if hasattr(td_layer.layer, 'layers'):\n",
    "            mobilenet_layers = td_layer.layer.layers[-num_layers_to_unfreeze:]\n",
    "            for layer in mobilenet_layers:\n",
    "                if hasattr(layer, 'trainable'):\n",
    "                    layer.trainable = True\n",
    "                    print(f\"Unfroze MobileNet layer: {layer.name}\")\n",
    "    \n",
    "    # Recompile the model with a lower learning rate for fine-tuning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_path, y_path, indices, batch_size):\n",
    "        self.X = np.memmap(X_path, dtype='float32', mode='r', shape=(1000, 15, 224, 224, 3))\n",
    "        self.y = np.memmap(y_path, dtype='int32', mode='r', shape=(1000,))\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X_batch = self.X[batch_indices]\n",
    "        X_batch = preprocess_input(X_batch)  \n",
    "        y_batch = np.eye(2)[self.y[batch_indices]]  \n",
    "        return X_batch, y_batch\n",
    "\n",
    "class StepTimerCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\n--- Starting Epoch {epoch + 1} ---\")\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        print(f\"--- Epoch {epoch + 1} completed in {epoch_time:.2f} seconds ---\\n\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.step_start_time = time.time()\n",
    "        print(f\"Step {batch + 1}/{self.params['steps']} - \", end=\"\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        step_time = time.time() - self.step_start_time\n",
    "        print(f\"Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}, Time: {step_time:.2f} seconds\")\n",
    "\n",
    "class BatchEarlyStopping(Callback):\n",
    "    def __init__(self, monitor='loss', threshold=0.1, patience=5):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        current_value = logs.get(self.monitor)\n",
    "        if current_value is not None and current_value < self.threshold:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"\\nEarly stopping triggered at batch {batch + 1}: {self.monitor} = {current_value:.4f}\")\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0\n",
    "\n",
    "batch_early_stopping_callback = BatchEarlyStopping(monitor='loss', threshold=0.1, patience=2)\n",
    "\n",
    "checkpoint_dir = './Finetune_Checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}.keras')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    return lr * 0.9\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Load your existing model\n",
    "latest_checkpoint = r'E:\\PosePerfect\\Model\\Further_improvements_Checkpoints\\model_epoch_05_val_loss_0.37.keras'\n",
    "cnn_lstm_model = load_model(latest_checkpoint)\n",
    "\n",
    "indices = np.arange(1000)\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_final_15k.dat', r'E:\\PosePerfect\\Dataset Creation\\y_final_15k.dat', train_indices, batch_size=10)\n",
    "val_gen = DataGenerator(r'E:\\PosePerfect\\Dataset Creation\\X_final_15k.dat', r'E:\\PosePerfect\\Dataset Creation\\y_final_15k.dat', val_indices, batch_size=10)\n",
    "\n",
    "# Unfreeze the last 10 layers of MobileNet\n",
    "cnn_lstm_model = unfreeze_and_fine_tune(cnn_lstm_model, num_layers_to_unfreeze=20)\n",
    "\n",
    "# Print the trainable status of all layers\n",
    "print(\"\\nTrainable status after unfreezing:\")\n",
    "for layer in cnn_lstm_model.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")\n",
    "        \n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "# Continue training with the same data generators and callbacks\n",
    "cnn_lstm_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=[checkpoint_callback, lr_callback, StepTimerCallback(), batch_early_stopping_callback],\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "6170007245c512ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Layer Structure:\n",
      "TimeDistributed wrapping: Functional\n",
      "Sublayers:\n",
      "  - input_layer_2: InputLayer\n",
      "  - conv1: Conv2D\n",
      "  - conv1_bn: BatchNormalization\n",
      "  - conv1_relu: ReLU\n",
      "  - conv_dw_1: DepthwiseConv2D\n",
      "  - conv_dw_1_bn: BatchNormalization\n",
      "  - conv_dw_1_relu: ReLU\n",
      "  - conv_pw_1: Conv2D\n",
      "  - conv_pw_1_bn: BatchNormalization\n",
      "  - conv_pw_1_relu: ReLU\n",
      "  - conv_pad_2: ZeroPadding2D\n",
      "  - conv_dw_2: DepthwiseConv2D\n",
      "  - conv_dw_2_bn: BatchNormalization\n",
      "  - conv_dw_2_relu: ReLU\n",
      "  - conv_pw_2: Conv2D\n",
      "  - conv_pw_2_bn: BatchNormalization\n",
      "  - conv_pw_2_relu: ReLU\n",
      "  - conv_dw_3: DepthwiseConv2D\n",
      "  - conv_dw_3_bn: BatchNormalization\n",
      "  - conv_dw_3_relu: ReLU\n",
      "  - conv_pw_3: Conv2D\n",
      "  - conv_pw_3_bn: BatchNormalization\n",
      "  - conv_pw_3_relu: ReLU\n",
      "  - conv_pad_4: ZeroPadding2D\n",
      "  - conv_dw_4: DepthwiseConv2D\n",
      "  - conv_dw_4_bn: BatchNormalization\n",
      "  - conv_dw_4_relu: ReLU\n",
      "  - conv_pw_4: Conv2D\n",
      "  - conv_pw_4_bn: BatchNormalization\n",
      "  - conv_pw_4_relu: ReLU\n",
      "  - conv_dw_5: DepthwiseConv2D\n",
      "  - conv_dw_5_bn: BatchNormalization\n",
      "  - conv_dw_5_relu: ReLU\n",
      "  - conv_pw_5: Conv2D\n",
      "  - conv_pw_5_bn: BatchNormalization\n",
      "  - conv_pw_5_relu: ReLU\n",
      "  - conv_pad_6: ZeroPadding2D\n",
      "  - conv_dw_6: DepthwiseConv2D\n",
      "  - conv_dw_6_bn: BatchNormalization\n",
      "  - conv_dw_6_relu: ReLU\n",
      "  - conv_pw_6: Conv2D\n",
      "  - conv_pw_6_bn: BatchNormalization\n",
      "  - conv_pw_6_relu: ReLU\n",
      "  - conv_dw_7: DepthwiseConv2D\n",
      "  - conv_dw_7_bn: BatchNormalization\n",
      "  - conv_dw_7_relu: ReLU\n",
      "  - conv_pw_7: Conv2D\n",
      "  - conv_pw_7_bn: BatchNormalization\n",
      "  - conv_pw_7_relu: ReLU\n",
      "  - conv_dw_8: DepthwiseConv2D\n",
      "  - conv_dw_8_bn: BatchNormalization\n",
      "  - conv_dw_8_relu: ReLU\n",
      "  - conv_pw_8: Conv2D\n",
      "  - conv_pw_8_bn: BatchNormalization\n",
      "  - conv_pw_8_relu: ReLU\n",
      "  - conv_dw_9: DepthwiseConv2D\n",
      "  - conv_dw_9_bn: BatchNormalization\n",
      "  - conv_dw_9_relu: ReLU\n",
      "  - conv_pw_9: Conv2D\n",
      "  - conv_pw_9_bn: BatchNormalization\n",
      "  - conv_pw_9_relu: ReLU\n",
      "  - conv_dw_10: DepthwiseConv2D\n",
      "  - conv_dw_10_bn: BatchNormalization\n",
      "  - conv_dw_10_relu: ReLU\n",
      "  - conv_pw_10: Conv2D\n",
      "  - conv_pw_10_bn: BatchNormalization\n",
      "  - conv_pw_10_relu: ReLU\n",
      "  - conv_dw_11: DepthwiseConv2D\n",
      "  - conv_dw_11_bn: BatchNormalization\n",
      "  - conv_dw_11_relu: ReLU\n",
      "  - conv_pw_11: Conv2D\n",
      "  - conv_pw_11_bn: BatchNormalization\n",
      "  - conv_pw_11_relu: ReLU\n",
      "  - conv_pad_12: ZeroPadding2D\n",
      "  - conv_dw_12: DepthwiseConv2D\n",
      "  - conv_dw_12_bn: BatchNormalization\n",
      "  - conv_dw_12_relu: ReLU\n",
      "  - conv_pw_12: Conv2D\n",
      "  - conv_pw_12_bn: BatchNormalization\n",
      "  - conv_pw_12_relu: ReLU\n",
      "  - conv_dw_13: DepthwiseConv2D\n",
      "  - conv_dw_13_bn: BatchNormalization\n",
      "  - conv_dw_13_relu: ReLU\n",
      "  - conv_pw_13: Conv2D\n",
      "  - conv_pw_13_bn: BatchNormalization\n",
      "  - conv_pw_13_relu: ReLU\n",
      "TimeDistributed wrapping: Flatten\n",
      "Unfroze LSTM layer: lstm_2\n",
      "Unfroze LSTM layer: lstm_3\n",
      "Unfroze Dense layer: dense\n",
      "Unfroze Dense layer: dense_1\n",
      "Unfroze MobileNet layer: conv_pw_10_relu\n",
      "Unfroze MobileNet layer: conv_dw_11\n",
      "Unfroze MobileNet layer: conv_dw_11_bn\n",
      "Unfroze MobileNet layer: conv_dw_11_relu\n",
      "Unfroze MobileNet layer: conv_pw_11\n",
      "Unfroze MobileNet layer: conv_pw_11_bn\n",
      "Unfroze MobileNet layer: conv_pw_11_relu\n",
      "Unfroze MobileNet layer: conv_pad_12\n",
      "Unfroze MobileNet layer: conv_dw_12\n",
      "Unfroze MobileNet layer: conv_dw_12_bn\n",
      "Unfroze MobileNet layer: conv_dw_12_relu\n",
      "Unfroze MobileNet layer: conv_pw_12\n",
      "Unfroze MobileNet layer: conv_pw_12_bn\n",
      "Unfroze MobileNet layer: conv_pw_12_relu\n",
      "Unfroze MobileNet layer: conv_dw_13\n",
      "Unfroze MobileNet layer: conv_dw_13_bn\n",
      "Unfroze MobileNet layer: conv_dw_13_relu\n",
      "Unfroze MobileNet layer: conv_pw_13\n",
      "Unfroze MobileNet layer: conv_pw_13_bn\n",
      "Unfroze MobileNet layer: conv_pw_13_relu\n",
      "\n",
      "Trainable status after unfreezing:\n",
      "input_layer_3: False\n",
      "time_distributed_2: False\n",
      "time_distributed_3: False\n",
      "lstm_2: True\n",
      "dropout_1: False\n",
      "lstm_3: True\n",
      "dropout_2: False\n",
      "dense: True\n",
      "dropout_3: False\n",
      "dense_1: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m,   │             \u001B[38;5;34m0\u001B[0m │\n",
       "│                                 │ \u001B[38;5;34m3\u001B[0m)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m1024\u001B[0m) │     \u001B[38;5;34m3,228,864\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m50176\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │    \u001B[38;5;34m25,756,160\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │           \u001B[38;5;34m130\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,756,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m29,124,994\u001B[0m (111.10 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,124,994</span> (111.10 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m27,758,786\u001B[0m (105.89 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,758,786</span> (105.89 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m1,366,208\u001B[0m (5.21 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,366,208</span> (5.21 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PosePerfect\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Epoch 1 ---\n",
      "Epoch 1/10\n",
      "Step 1/80 - Loss: 0.7564, Accuracy: 0.3000, Time: 105.32 seconds\n",
      "\u001B[1m 1/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m2:21:41\u001B[0m 108s/step - accuracy: 0.3000 - loss: 0.7564Step 2/80 - Loss: 0.7547, Accuracy: 0.4000, Time: 3.93 seconds\n",
      "\u001B[1m 2/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:12\u001B[0m 4s/step - accuracy: 0.3500 - loss: 0.7556     Step 3/80 - Loss: 0.7723, Accuracy: 0.4000, Time: 3.76 seconds\n",
      "\u001B[1m 3/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:59\u001B[0m 4s/step - accuracy: 0.3667 - loss: 0.7611Step 4/80 - Loss: 0.7177, Accuracy: 0.4500, Time: 3.70 seconds\n",
      "\u001B[1m 4/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:50\u001B[0m 4s/step - accuracy: 0.3875 - loss: 0.7503Step 5/80 - Loss: 0.7063, Accuracy: 0.4800, Time: 3.65 seconds\n",
      "\u001B[1m 5/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:43\u001B[0m 4s/step - accuracy: 0.4060 - loss: 0.7415Step 6/80 - Loss: 0.6983, Accuracy: 0.5000, Time: 3.63 seconds\n",
      "\u001B[1m 6/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:37\u001B[0m 4s/step - accuracy: 0.4217 - loss: 0.7343Step 7/80 - Loss: 0.6917, Accuracy: 0.5286, Time: 3.62 seconds\n",
      "\u001B[1m 7/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:32\u001B[0m 4s/step - accuracy: 0.4369 - loss: 0.7282Step 8/80 - Loss: 0.6817, Accuracy: 0.5375, Time: 3.66 seconds\n",
      "\u001B[1m 8/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:27\u001B[0m 4s/step - accuracy: 0.4495 - loss: 0.7224Step 9/80 - Loss: 0.6769, Accuracy: 0.5556, Time: 3.62 seconds\n",
      "\u001B[1m 9/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:23\u001B[0m 4s/step - accuracy: 0.4613 - loss: 0.7173Step 10/80 - Loss: 0.6782, Accuracy: 0.5400, Time: 3.62 seconds\n",
      "\u001B[1m10/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:18\u001B[0m 4s/step - accuracy: 0.4692 - loss: 0.7134Step 11/80 - Loss: 0.6725, Accuracy: 0.5364, Time: 3.81 seconds\n",
      "\u001B[1m11/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:15\u001B[0m 4s/step - accuracy: 0.4753 - loss: 0.7097Step 12/80 - Loss: 0.6763, Accuracy: 0.5417, Time: 3.69 seconds\n",
      "\u001B[1m12/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:12\u001B[0m 4s/step - accuracy: 0.4808 - loss: 0.7069Step 13/80 - Loss: 0.6801, Accuracy: 0.5385, Time: 3.69 seconds\n",
      "\u001B[1m13/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:08\u001B[0m 4s/step - accuracy: 0.4852 - loss: 0.7049Step 14/80 - Loss: 0.6880, Accuracy: 0.5286, Time: 3.71 seconds\n",
      "\u001B[1m14/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:04\u001B[0m 4s/step - accuracy: 0.4883 - loss: 0.7037Step 15/80 - Loss: 0.6921, Accuracy: 0.5133, Time: 3.67 seconds\n",
      "\u001B[1m15/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:00\u001B[0m 4s/step - accuracy: 0.4900 - loss: 0.7029Step 16/80 - Loss: 0.7005, Accuracy: 0.5000, Time: 3.65 seconds\n",
      "\u001B[1m16/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:56\u001B[0m 4s/step - accuracy: 0.4906 - loss: 0.7027Step 17/80 - Loss: 0.6996, Accuracy: 0.5000, Time: 3.74 seconds\n",
      "\u001B[1m17/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:53\u001B[0m 4s/step - accuracy: 0.4912 - loss: 0.7025Step 18/80 - Loss: 0.6965, Accuracy: 0.5111, Time: 3.60 seconds\n",
      "\u001B[1m18/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:49\u001B[0m 4s/step - accuracy: 0.4923 - loss: 0.7022Step 19/80 - Loss: 0.6917, Accuracy: 0.5211, Time: 3.97 seconds\n",
      "\u001B[1m19/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:46\u001B[0m 4s/step - accuracy: 0.4938 - loss: 0.7017Step 20/80 - Loss: 0.6832, Accuracy: 0.5400, Time: 3.63 seconds\n",
      "\u001B[1m20/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:42\u001B[0m 4s/step - accuracy: 0.4961 - loss: 0.7007Step 21/80 - Loss: 0.6808, Accuracy: 0.5476, Time: 3.74 seconds\n",
      "\u001B[1m21/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:38\u001B[0m 4s/step - accuracy: 0.4986 - loss: 0.6998Step 22/80 - Loss: 0.6807, Accuracy: 0.5545, Time: 3.72 seconds\n",
      "\u001B[1m22/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:35\u001B[0m 4s/step - accuracy: 0.5011 - loss: 0.6989Step 23/80 - Loss: 0.6859, Accuracy: 0.5478, Time: 3.63 seconds\n",
      "\u001B[1m23/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:31\u001B[0m 4s/step - accuracy: 0.5031 - loss: 0.6984Step 24/80 - Loss: 0.6833, Accuracy: 0.5458, Time: 3.65 seconds\n",
      "\u001B[1m24/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:27\u001B[0m 4s/step - accuracy: 0.5049 - loss: 0.6977Step 25/80 - Loss: 0.6835, Accuracy: 0.5400, Time: 3.66 seconds\n",
      "\u001B[1m25/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:23\u001B[0m 4s/step - accuracy: 0.5063 - loss: 0.6972Step 26/80 - Loss: 0.6857, Accuracy: 0.5423, Time: 3.99 seconds\n",
      "\u001B[1m26/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:20\u001B[0m 4s/step - accuracy: 0.5077 - loss: 0.6967Step 27/80 - Loss: 0.6809, Accuracy: 0.5481, Time: 3.94 seconds\n",
      "\u001B[1m27/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:17\u001B[0m 4s/step - accuracy: 0.5092 - loss: 0.6961Step 28/80 - Loss: 0.6770, Accuracy: 0.5571, Time: 3.67 seconds\n",
      "\u001B[1m28/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:13\u001B[0m 4s/step - accuracy: 0.5109 - loss: 0.6955Step 29/80 - Loss: 0.6846, Accuracy: 0.5483, Time: 3.73 seconds\n",
      "\u001B[1m29/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:09\u001B[0m 4s/step - accuracy: 0.5122 - loss: 0.6951Step 30/80 - Loss: 0.6826, Accuracy: 0.5567, Time: 3.68 seconds\n",
      "\u001B[1m30/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:06\u001B[0m 4s/step - accuracy: 0.5137 - loss: 0.6947Step 31/80 - Loss: 0.6826, Accuracy: 0.5613, Time: 3.67 seconds\n",
      "\u001B[1m31/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:02\u001B[0m 4s/step - accuracy: 0.5152 - loss: 0.6943Step 32/80 - Loss: 0.6755, Accuracy: 0.5719, Time: 3.70 seconds\n",
      "\u001B[1m32/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:58\u001B[0m 4s/step - accuracy: 0.5170 - loss: 0.6937Step 33/80 - Loss: 0.6758, Accuracy: 0.5697, Time: 3.58 seconds\n",
      "\u001B[1m33/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:54\u001B[0m 4s/step - accuracy: 0.5186 - loss: 0.6931Step 34/80 - Loss: 0.6769, Accuracy: 0.5706, Time: 4.98 seconds\n",
      "\u001B[1m34/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:52\u001B[0m 4s/step - accuracy: 0.5201 - loss: 0.6927Step 35/80 - Loss: 0.6761, Accuracy: 0.5714, Time: 4.71 seconds\n",
      "\u001B[1m35/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:50\u001B[0m 4s/step - accuracy: 0.5216 - loss: 0.6922Step 36/80 - Loss: 0.6746, Accuracy: 0.5750, Time: 3.88 seconds\n",
      "\u001B[1m36/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:46\u001B[0m 4s/step - accuracy: 0.5231 - loss: 0.6917Step 37/80 - Loss: 0.6730, Accuracy: 0.5757, Time: 3.71 seconds\n",
      "\u001B[1m37/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:42\u001B[0m 4s/step - accuracy: 0.5245 - loss: 0.6912Step 38/80 - Loss: 0.6712, Accuracy: 0.5816, Time: 3.74 seconds\n",
      "\u001B[1m38/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:38\u001B[0m 4s/step - accuracy: 0.5260 - loss: 0.6907Step 39/80 - Loss: 0.6764, Accuracy: 0.5744, Time: 3.65 seconds\n",
      "\u001B[1m39/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:34\u001B[0m 4s/step - accuracy: 0.5272 - loss: 0.6903Step 40/80 - Loss: 0.6775, Accuracy: 0.5750, Time: 3.76 seconds\n",
      "\u001B[1m40/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:31\u001B[0m 4s/step - accuracy: 0.5284 - loss: 0.6900Step 41/80 - Loss: 0.6757, Accuracy: 0.5756, Time: 3.71 seconds\n",
      "\u001B[1m41/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:27\u001B[0m 4s/step - accuracy: 0.5296 - loss: 0.6896Step 42/80 - Loss: 0.6728, Accuracy: 0.5810, Time: 3.67 seconds\n",
      "\u001B[1m42/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:23\u001B[0m 4s/step - accuracy: 0.5308 - loss: 0.6892Step 43/80 - Loss: 0.6710, Accuracy: 0.5837, Time: 3.68 seconds\n",
      "\u001B[1m43/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:19\u001B[0m 4s/step - accuracy: 0.5320 - loss: 0.6888Step 44/80 - Loss: 0.6710, Accuracy: 0.5841, Time: 3.71 seconds\n",
      "\u001B[1m44/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:15\u001B[0m 4s/step - accuracy: 0.5332 - loss: 0.6884Step 45/80 - Loss: 0.6708, Accuracy: 0.5800, Time: 3.70 seconds\n",
      "\u001B[1m45/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:11\u001B[0m 4s/step - accuracy: 0.5343 - loss: 0.6880Step 46/80 - Loss: 0.6736, Accuracy: 0.5739, Time: 3.63 seconds\n",
      "\u001B[1m46/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:08\u001B[0m 4s/step - accuracy: 0.5351 - loss: 0.6877Step 47/80 - Loss: 0.6734, Accuracy: 0.5723, Time: 3.65 seconds\n",
      "\u001B[1m47/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:04\u001B[0m 4s/step - accuracy: 0.5359 - loss: 0.6874Step 48/80 - Loss: 0.6725, Accuracy: 0.5729, Time: 3.66 seconds\n",
      "\u001B[1m48/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:00\u001B[0m 4s/step - accuracy: 0.5367 - loss: 0.6871Step 49/80 - Loss: 0.6724, Accuracy: 0.5714, Time: 3.62 seconds\n",
      "\u001B[1m49/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:56\u001B[0m 4s/step - accuracy: 0.5374 - loss: 0.6868Step 50/80 - Loss: 0.6734, Accuracy: 0.5740, Time: 3.66 seconds\n",
      "\u001B[1m50/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:52\u001B[0m 4s/step - accuracy: 0.5381 - loss: 0.6865Step 51/80 - Loss: 0.6705, Accuracy: 0.5784, Time: 3.70 seconds\n",
      "\u001B[1m51/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:48\u001B[0m 4s/step - accuracy: 0.5389 - loss: 0.6862Step 52/80 - Loss: 0.6684, Accuracy: 0.5769, Time: 3.74 seconds\n",
      "\u001B[1m52/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:45\u001B[0m 4s/step - accuracy: 0.5396 - loss: 0.6859Step 53/80 - Loss: 0.6660, Accuracy: 0.5849, Time: 3.65 seconds\n",
      "\u001B[1m53/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:41\u001B[0m 4s/step - accuracy: 0.5405 - loss: 0.6855Step 54/80 - Loss: 0.6656, Accuracy: 0.5852, Time: 3.65 seconds\n",
      "\u001B[1m54/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:37\u001B[0m 4s/step - accuracy: 0.5413 - loss: 0.6851Step 55/80 - Loss: 0.6649, Accuracy: 0.5836, Time: 3.68 seconds\n",
      "\u001B[1m55/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:33\u001B[0m 4s/step - accuracy: 0.5421 - loss: 0.6848Step 56/80 - Loss: 0.6660, Accuracy: 0.5804, Time: 3.62 seconds\n",
      "\u001B[1m56/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:29\u001B[0m 4s/step - accuracy: 0.5428 - loss: 0.6844Step 57/80 - Loss: 0.6640, Accuracy: 0.5842, Time: 3.65 seconds\n",
      "\u001B[1m57/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:26\u001B[0m 4s/step - accuracy: 0.5435 - loss: 0.6841Step 58/80 - Loss: 0.6642, Accuracy: 0.5828, Time: 3.74 seconds\n",
      "\u001B[1m58/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:22\u001B[0m 4s/step - accuracy: 0.5442 - loss: 0.6837Step 59/80 - Loss: 0.6643, Accuracy: 0.5814, Time: 3.64 seconds\n",
      "\u001B[1m59/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:18\u001B[0m 4s/step - accuracy: 0.5448 - loss: 0.6834Step 60/80 - Loss: 0.6634, Accuracy: 0.5850, Time: 3.62 seconds\n",
      "\u001B[1m60/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:14\u001B[0m 4s/step - accuracy: 0.5455 - loss: 0.6831Step 61/80 - Loss: 0.6627, Accuracy: 0.5869, Time: 3.75 seconds\n",
      "\u001B[1m61/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:11\u001B[0m 4s/step - accuracy: 0.5462 - loss: 0.6827Step 62/80 - Loss: 0.6613, Accuracy: 0.5887, Time: 3.61 seconds\n",
      "\u001B[1m62/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:07\u001B[0m 4s/step - accuracy: 0.5468 - loss: 0.6824Step 63/80 - Loss: 0.6616, Accuracy: 0.5889, Time: 3.61 seconds\n",
      "\u001B[1m63/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:03\u001B[0m 4s/step - accuracy: 0.5475 - loss: 0.6820Step 64/80 - Loss: 0.6606, Accuracy: 0.5891, Time: 3.68 seconds\n",
      "\u001B[1m64/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m59s\u001B[0m 4s/step - accuracy: 0.5482 - loss: 0.6817 Step 65/80 - Loss: 0.6602, Accuracy: 0.5892, Time: 3.63 seconds\n",
      "\u001B[1m65/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m56s\u001B[0m 4s/step - accuracy: 0.5488 - loss: 0.6814Step 66/80 - Loss: 0.6599, Accuracy: 0.5909, Time: 3.64 seconds\n",
      "\u001B[1m66/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m52s\u001B[0m 4s/step - accuracy: 0.5494 - loss: 0.6811Step 67/80 - Loss: 0.6598, Accuracy: 0.5896, Time: 3.69 seconds\n",
      "\u001B[1m67/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m48s\u001B[0m 4s/step - accuracy: 0.5500 - loss: 0.6807Step 68/80 - Loss: 0.6586, Accuracy: 0.5926, Time: 3.71 seconds\n",
      "\u001B[1m68/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m44s\u001B[0m 4s/step - accuracy: 0.5507 - loss: 0.6804Step 69/80 - Loss: 0.6561, Accuracy: 0.5957, Time: 3.62 seconds\n",
      "\u001B[1m69/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m41s\u001B[0m 4s/step - accuracy: 0.5513 - loss: 0.6801Step 70/80 - Loss: 0.6536, Accuracy: 0.6000, Time: 3.59 seconds\n",
      "\u001B[1m70/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m37s\u001B[0m 4s/step - accuracy: 0.5520 - loss: 0.6797Step 71/80 - Loss: 0.6522, Accuracy: 0.6028, Time: 3.71 seconds\n",
      "\u001B[1m71/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m33s\u001B[0m 4s/step - accuracy: 0.5527 - loss: 0.6793Step 72/80 - Loss: 0.6508, Accuracy: 0.6056, Time: 3.67 seconds\n",
      "\u001B[1m72/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m29s\u001B[0m 4s/step - accuracy: 0.5535 - loss: 0.6789Step 73/80 - Loss: 0.6465, Accuracy: 0.6110, Time: 3.66 seconds\n",
      "\u001B[1m73/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.5542 - loss: 0.6785Step 74/80 - Loss: 0.6462, Accuracy: 0.6122, Time: 3.72 seconds\n",
      "\u001B[1m74/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m22s\u001B[0m 4s/step - accuracy: 0.5550 - loss: 0.6780Step 75/80 - Loss: 0.6445, Accuracy: 0.6120, Time: 3.69 seconds\n",
      "\u001B[1m75/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m18s\u001B[0m 4s/step - accuracy: 0.5558 - loss: 0.6776Step 76/80 - Loss: 0.6437, Accuracy: 0.6132, Time: 3.65 seconds\n",
      "\u001B[1m76/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m14s\u001B[0m 4s/step - accuracy: 0.5565 - loss: 0.6771Step 77/80 - Loss: 0.6416, Accuracy: 0.6156, Time: 3.70 seconds\n",
      "\u001B[1m77/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.5573 - loss: 0.6767Step 78/80 - Loss: 0.6419, Accuracy: 0.6179, Time: 3.66 seconds\n",
      "\u001B[1m78/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 0.5581 - loss: 0.6762 Step 79/80 - Loss: 0.6431, Accuracy: 0.6177, Time: 3.56 seconds\n",
      "\u001B[1m79/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 0.5588 - loss: 0.6758Step 80/80 - Loss: 0.6423, Accuracy: 0.6187, Time: 3.55 seconds\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.5596 - loss: 0.6754\n",
      "Epoch 1: saving model to ./Finetune_Checkpoints\\model_epoch_01_val_loss_0.52.keras\n",
      "--- Epoch 1 completed in 483.01 seconds ---\n",
      "\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m483s\u001B[0m 5s/step - accuracy: 0.5603 - loss: 0.6750 - val_accuracy: 0.8050 - val_loss: 0.5154 - learning_rate: 1.0000e-05\n",
      "\n",
      "--- Starting Epoch 2 ---\n",
      "Epoch 2/10\n",
      "Step 1/80 - Loss: 0.6079, Accuracy: 0.6000, Time: 7.88 seconds\n",
      "\u001B[1m 1/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m10:28\u001B[0m 8s/step - accuracy: 0.6000 - loss: 0.6079Step 2/80 - Loss: 0.6266, Accuracy: 0.6000, Time: 4.14 seconds\n",
      "\u001B[1m 2/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:23\u001B[0m 4s/step - accuracy: 0.6000 - loss: 0.6172 Step 3/80 - Loss: 0.5681, Accuracy: 0.6667, Time: 3.84 seconds\n",
      "\u001B[1m 3/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m5:07\u001B[0m 4s/step - accuracy: 0.6222 - loss: 0.6009Step 4/80 - Loss: 0.5658, Accuracy: 0.7250, Time: 3.79 seconds\n",
      "\u001B[1m 4/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:58\u001B[0m 4s/step - accuracy: 0.6479 - loss: 0.5921Step 5/80 - Loss: 0.5951, Accuracy: 0.6800, Time: 3.76 seconds\n",
      "\u001B[1m 5/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:51\u001B[0m 4s/step - accuracy: 0.6543 - loss: 0.5927Step 6/80 - Loss: 0.6059, Accuracy: 0.6667, Time: 3.75 seconds\n",
      "\u001B[1m 6/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:45\u001B[0m 4s/step - accuracy: 0.6564 - loss: 0.5949Step 7/80 - Loss: 0.6170, Accuracy: 0.6571, Time: 3.78 seconds\n",
      "\u001B[1m 7/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:40\u001B[0m 4s/step - accuracy: 0.6565 - loss: 0.5980Step 8/80 - Loss: 0.6241, Accuracy: 0.6375, Time: 3.78 seconds\n",
      "\u001B[1m 8/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:36\u001B[0m 4s/step - accuracy: 0.6541 - loss: 0.6013Step 9/80 - Loss: 0.6150, Accuracy: 0.6444, Time: 3.67 seconds\n",
      "\u001B[1m 9/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:30\u001B[0m 4s/step - accuracy: 0.6530 - loss: 0.6028Step 10/80 - Loss: 0.6049, Accuracy: 0.6700, Time: 3.70 seconds\n",
      "\u001B[1m10/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:26\u001B[0m 4s/step - accuracy: 0.6547 - loss: 0.6030Step 11/80 - Loss: 0.6158, Accuracy: 0.6545, Time: 3.66 seconds\n",
      "\u001B[1m11/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:21\u001B[0m 4s/step - accuracy: 0.6547 - loss: 0.6042Step 12/80 - Loss: 0.6187, Accuracy: 0.6500, Time: 3.70 seconds\n",
      "\u001B[1m12/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:17\u001B[0m 4s/step - accuracy: 0.6543 - loss: 0.6054Step 13/80 - Loss: 0.6186, Accuracy: 0.6462, Time: 3.75 seconds\n",
      "\u001B[1m13/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:13\u001B[0m 4s/step - accuracy: 0.6537 - loss: 0.6064Step 14/80 - Loss: 0.6167, Accuracy: 0.6500, Time: 3.77 seconds\n",
      "\u001B[1m14/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:09\u001B[0m 4s/step - accuracy: 0.6534 - loss: 0.6072Step 15/80 - Loss: 0.6171, Accuracy: 0.6467, Time: 5.93 seconds\n",
      "\u001B[1m15/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:15\u001B[0m 4s/step - accuracy: 0.6530 - loss: 0.6078Step 16/80 - Loss: 0.6286, Accuracy: 0.6375, Time: 3.72 seconds\n",
      "\u001B[1m16/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:10\u001B[0m 4s/step - accuracy: 0.6520 - loss: 0.6091Step 17/80 - Loss: 0.6310, Accuracy: 0.6353, Time: 3.74 seconds\n",
      "\u001B[1m17/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:06\u001B[0m 4s/step - accuracy: 0.6510 - loss: 0.6104Step 18/80 - Loss: 0.6189, Accuracy: 0.6444, Time: 3.71 seconds\n",
      "\u001B[1m18/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:01\u001B[0m 4s/step - accuracy: 0.6507 - loss: 0.6109Step 19/80 - Loss: 0.6236, Accuracy: 0.6526, Time: 3.64 seconds\n",
      "\u001B[1m19/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:56\u001B[0m 4s/step - accuracy: 0.6508 - loss: 0.6115Step 20/80 - Loss: 0.6223, Accuracy: 0.6550, Time: 3.87 seconds\n",
      "\u001B[1m20/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:52\u001B[0m 4s/step - accuracy: 0.6510 - loss: 0.6121Step 21/80 - Loss: 0.6134, Accuracy: 0.6619, Time: 3.62 seconds\n",
      "\u001B[1m21/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:48\u001B[0m 4s/step - accuracy: 0.6515 - loss: 0.6121Step 22/80 - Loss: 0.6037, Accuracy: 0.6727, Time: 3.69 seconds\n",
      "\u001B[1m22/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:43\u001B[0m 4s/step - accuracy: 0.6525 - loss: 0.6118Step 23/80 - Loss: 0.5969, Accuracy: 0.6739, Time: 3.78 seconds\n",
      "\u001B[1m23/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:39\u001B[0m 4s/step - accuracy: 0.6534 - loss: 0.6111Step 24/80 - Loss: 0.5953, Accuracy: 0.6792, Time: 3.77 seconds\n",
      "\u001B[1m24/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:35\u001B[0m 4s/step - accuracy: 0.6545 - loss: 0.6105Step 25/80 - Loss: 0.5944, Accuracy: 0.6840, Time: 3.70 seconds\n",
      "\u001B[1m25/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:31\u001B[0m 4s/step - accuracy: 0.6557 - loss: 0.6098Step 26/80 - Loss: 0.5860, Accuracy: 0.6923, Time: 3.64 seconds\n",
      "\u001B[1m26/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:27\u001B[0m 4s/step - accuracy: 0.6571 - loss: 0.6089Step 27/80 - Loss: 0.5817, Accuracy: 0.6963, Time: 3.73 seconds\n",
      "\u001B[1m27/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:23\u001B[0m 4s/step - accuracy: 0.6585 - loss: 0.6079Step 28/80 - Loss: 0.5753, Accuracy: 0.7071, Time: 3.65 seconds\n",
      "\u001B[1m28/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:19\u001B[0m 4s/step - accuracy: 0.6603 - loss: 0.6067Step 29/80 - Loss: 0.5767, Accuracy: 0.7138, Time: 3.74 seconds\n",
      "\u001B[1m29/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:15\u001B[0m 4s/step - accuracy: 0.6621 - loss: 0.6057Step 30/80 - Loss: 0.5701, Accuracy: 0.7233, Time: 3.73 seconds\n",
      "\u001B[1m30/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:11\u001B[0m 4s/step - accuracy: 0.6641 - loss: 0.6045Step 31/80 - Loss: 0.5702, Accuracy: 0.7290, Time: 3.71 seconds\n",
      "\u001B[1m31/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:07\u001B[0m 4s/step - accuracy: 0.6662 - loss: 0.6034Step 32/80 - Loss: 0.5697, Accuracy: 0.7312, Time: 3.71 seconds\n",
      "\u001B[1m32/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m3:03\u001B[0m 4s/step - accuracy: 0.6683 - loss: 0.6023Step 33/80 - Loss: 0.5686, Accuracy: 0.7333, Time: 3.68 seconds\n",
      "\u001B[1m33/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:59\u001B[0m 4s/step - accuracy: 0.6702 - loss: 0.6013Step 34/80 - Loss: 0.5726, Accuracy: 0.7294, Time: 3.73 seconds\n",
      "\u001B[1m34/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:55\u001B[0m 4s/step - accuracy: 0.6720 - loss: 0.6005Step 35/80 - Loss: 0.5727, Accuracy: 0.7286, Time: 3.72 seconds\n",
      "\u001B[1m35/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:51\u001B[0m 4s/step - accuracy: 0.6736 - loss: 0.5997Step 36/80 - Loss: 0.5759, Accuracy: 0.7250, Time: 3.75 seconds\n",
      "\u001B[1m36/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:47\u001B[0m 4s/step - accuracy: 0.6750 - loss: 0.5990Step 37/80 - Loss: 0.5716, Accuracy: 0.7270, Time: 4.08 seconds\n",
      "\u001B[1m37/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:43\u001B[0m 4s/step - accuracy: 0.6764 - loss: 0.5983Step 38/80 - Loss: 0.5707, Accuracy: 0.7263, Time: 4.05 seconds\n",
      "\u001B[1m38/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:40\u001B[0m 4s/step - accuracy: 0.6777 - loss: 0.5976Step 39/80 - Loss: 0.5750, Accuracy: 0.7231, Time: 3.66 seconds\n",
      "\u001B[1m39/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:36\u001B[0m 4s/step - accuracy: 0.6789 - loss: 0.5970Step 40/80 - Loss: 0.5770, Accuracy: 0.7175, Time: 3.73 seconds\n",
      "\u001B[1m40/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:32\u001B[0m 4s/step - accuracy: 0.6799 - loss: 0.5965Step 41/80 - Loss: 0.5748, Accuracy: 0.7195, Time: 3.77 seconds\n",
      "\u001B[1m41/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:28\u001B[0m 4s/step - accuracy: 0.6808 - loss: 0.5959Step 42/80 - Loss: 0.5753, Accuracy: 0.7190, Time: 3.65 seconds\n",
      "\u001B[1m42/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:24\u001B[0m 4s/step - accuracy: 0.6817 - loss: 0.5955Step 43/80 - Loss: 0.5824, Accuracy: 0.7163, Time: 3.78 seconds\n",
      "\u001B[1m43/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:20\u001B[0m 4s/step - accuracy: 0.6825 - loss: 0.5952Step 44/80 - Loss: 0.5788, Accuracy: 0.7205, Time: 3.79 seconds\n",
      "\u001B[1m44/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:17\u001B[0m 4s/step - accuracy: 0.6834 - loss: 0.5948Step 45/80 - Loss: 0.5787, Accuracy: 0.7222, Time: 3.68 seconds\n",
      "\u001B[1m45/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:13\u001B[0m 4s/step - accuracy: 0.6843 - loss: 0.5944Step 46/80 - Loss: 0.5759, Accuracy: 0.7239, Time: 3.62 seconds\n",
      "\u001B[1m46/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:09\u001B[0m 4s/step - accuracy: 0.6851 - loss: 0.5940Step 47/80 - Loss: 0.5726, Accuracy: 0.7277, Time: 3.68 seconds\n",
      "\u001B[1m47/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:05\u001B[0m 4s/step - accuracy: 0.6860 - loss: 0.5936Step 48/80 - Loss: 0.5725, Accuracy: 0.7271, Time: 3.73 seconds\n",
      "\u001B[1m48/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:01\u001B[0m 4s/step - accuracy: 0.6869 - loss: 0.5931Step 49/80 - Loss: 0.5710, Accuracy: 0.7286, Time: 3.78 seconds\n",
      "\u001B[1m49/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:57\u001B[0m 4s/step - accuracy: 0.6877 - loss: 0.5927Step 50/80 - Loss: 0.5669, Accuracy: 0.7300, Time: 3.61 seconds\n",
      "\u001B[1m50/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:53\u001B[0m 4s/step - accuracy: 0.6886 - loss: 0.5922Step 51/80 - Loss: 0.5624, Accuracy: 0.7353, Time: 3.69 seconds\n",
      "\u001B[1m51/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:49\u001B[0m 4s/step - accuracy: 0.6895 - loss: 0.5916Step 52/80 - Loss: 0.5591, Accuracy: 0.7365, Time: 3.70 seconds\n",
      "\u001B[1m52/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:46\u001B[0m 4s/step - accuracy: 0.6904 - loss: 0.5910Step 53/80 - Loss: 0.5567, Accuracy: 0.7377, Time: 3.65 seconds\n",
      "\u001B[1m53/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:42\u001B[0m 4s/step - accuracy: 0.6913 - loss: 0.5903Step 54/80 - Loss: 0.5577, Accuracy: 0.7333, Time: 3.71 seconds\n",
      "\u001B[1m54/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:38\u001B[0m 4s/step - accuracy: 0.6921 - loss: 0.5897Step 55/80 - Loss: 0.5537, Accuracy: 0.7382, Time: 3.71 seconds\n",
      "\u001B[1m55/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:34\u001B[0m 4s/step - accuracy: 0.6929 - loss: 0.5890Step 56/80 - Loss: 0.5503, Accuracy: 0.7429, Time: 3.66 seconds\n",
      "\u001B[1m56/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:30\u001B[0m 4s/step - accuracy: 0.6938 - loss: 0.5884Step 57/80 - Loss: 0.5495, Accuracy: 0.7439, Time: 3.68 seconds\n",
      "\u001B[1m57/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:26\u001B[0m 4s/step - accuracy: 0.6947 - loss: 0.5877Step 58/80 - Loss: 0.5537, Accuracy: 0.7397, Time: 3.68 seconds\n",
      "\u001B[1m58/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:23\u001B[0m 4s/step - accuracy: 0.6955 - loss: 0.5871Step 59/80 - Loss: 0.5516, Accuracy: 0.7390, Time: 3.67 seconds\n",
      "\u001B[1m59/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:19\u001B[0m 4s/step - accuracy: 0.6962 - loss: 0.5865Step 60/80 - Loss: 0.5504, Accuracy: 0.7400, Time: 3.69 seconds\n",
      "\u001B[1m60/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:15\u001B[0m 4s/step - accuracy: 0.6969 - loss: 0.5859Step 61/80 - Loss: 0.5478, Accuracy: 0.7410, Time: 3.71 seconds\n",
      "\u001B[1m61/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:11\u001B[0m 4s/step - accuracy: 0.6977 - loss: 0.5853Step 62/80 - Loss: 0.5435, Accuracy: 0.7452, Time: 3.70 seconds\n",
      "\u001B[1m62/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:07\u001B[0m 4s/step - accuracy: 0.6984 - loss: 0.5846Step 63/80 - Loss: 0.5420, Accuracy: 0.7460, Time: 3.66 seconds\n",
      "\u001B[1m63/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:04\u001B[0m 4s/step - accuracy: 0.6992 - loss: 0.5839Step 64/80 - Loss: 0.5411, Accuracy: 0.7437, Time: 3.69 seconds\n",
      "\u001B[1m64/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m1:00\u001B[0m 4s/step - accuracy: 0.6999 - loss: 0.5832Step 65/80 - Loss: 0.5386, Accuracy: 0.7477, Time: 3.68 seconds\n",
      "\u001B[1m65/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m56s\u001B[0m 4s/step - accuracy: 0.7006 - loss: 0.5826 Step 66/80 - Loss: 0.5391, Accuracy: 0.7470, Time: 3.71 seconds\n",
      "\u001B[1m66/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m52s\u001B[0m 4s/step - accuracy: 0.7013 - loss: 0.5819Step 67/80 - Loss: 0.5389, Accuracy: 0.7463, Time: 3.63 seconds\n",
      "\u001B[1m67/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m48s\u001B[0m 4s/step - accuracy: 0.7020 - loss: 0.5813Step 68/80 - Loss: 0.5424, Accuracy: 0.7456, Time: 3.66 seconds\n",
      "\u001B[1m68/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m45s\u001B[0m 4s/step - accuracy: 0.7026 - loss: 0.5807Step 69/80 - Loss: 0.5390, Accuracy: 0.7493, Time: 3.70 seconds\n",
      "\u001B[1m69/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m41s\u001B[0m 4s/step - accuracy: 0.7033 - loss: 0.5801Step 70/80 - Loss: 0.5384, Accuracy: 0.7500, Time: 3.67 seconds\n",
      "\u001B[1m70/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m37s\u001B[0m 4s/step - accuracy: 0.7040 - loss: 0.5795Step 71/80 - Loss: 0.5387, Accuracy: 0.7507, Time: 3.77 seconds\n",
      "\u001B[1m71/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m33s\u001B[0m 4s/step - accuracy: 0.7046 - loss: 0.5789Step 72/80 - Loss: 0.5345, Accuracy: 0.7542, Time: 3.70 seconds\n",
      "\u001B[1m72/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m30s\u001B[0m 4s/step - accuracy: 0.7053 - loss: 0.5783Step 73/80 - Loss: 0.5317, Accuracy: 0.7575, Time: 3.64 seconds\n",
      "\u001B[1m73/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.7060 - loss: 0.5777Step 74/80 - Loss: 0.5349, Accuracy: 0.7541, Time: 3.66 seconds\n",
      "\u001B[1m74/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m22s\u001B[0m 4s/step - accuracy: 0.7067 - loss: 0.5771Step 75/80 - Loss: 0.5354, Accuracy: 0.7533, Time: 3.76 seconds\n",
      "\u001B[1m75/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m18s\u001B[0m 4s/step - accuracy: 0.7073 - loss: 0.5765Step 76/80 - Loss: 0.5348, Accuracy: 0.7539, Time: 3.72 seconds\n",
      "\u001B[1m76/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m15s\u001B[0m 4s/step - accuracy: 0.7079 - loss: 0.5760Step 77/80 - Loss: 0.5349, Accuracy: 0.7519, Time: 3.63 seconds\n",
      "\u001B[1m77/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.7085 - loss: 0.5754Step 78/80 - Loss: 0.5380, Accuracy: 0.7474, Time: 3.67 seconds\n",
      "\u001B[1m78/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 0.7090 - loss: 0.5750 Step 79/80 - Loss: 0.5344, Accuracy: 0.7506, Time: 3.59 seconds\n",
      "\u001B[1m79/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 0.7095 - loss: 0.5744Step 80/80 - Loss: 0.5336, Accuracy: 0.7513, Time: 3.59 seconds\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.7100 - loss: 0.5739\n",
      "Epoch 2: saving model to ./Finetune_Checkpoints\\model_epoch_02_val_loss_0.41.keras\n",
      "--- Epoch 2 completed in 372.71 seconds ---\n",
      "\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m373s\u001B[0m 5s/step - accuracy: 0.7105 - loss: 0.5734 - val_accuracy: 0.8500 - val_loss: 0.4129 - learning_rate: 1.0000e-05\n",
      "\n",
      "--- Starting Epoch 3 ---\n",
      "Epoch 3/10\n",
      "Step 1/80 - Loss: 0.3138, Accuracy: 1.0000, Time: 8.74 seconds\n",
      "\u001B[1m 1/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m11:37\u001B[0m 9s/step - accuracy: 1.0000 - loss: 0.3138Step 2/80 - Loss: 0.3410, Accuracy: 1.0000, Time: 3.72 seconds\n",
      "\u001B[1m 2/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:50\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.3274 Step 3/80 - Loss: 0.3051, Accuracy: 1.0000, Time: 3.69 seconds\n",
      "\u001B[1m 3/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:45\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.3200Step 4/80 - Loss: 0.3353, Accuracy: 0.9500, Time: 3.82 seconds\n",
      "\u001B[1m 4/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:44\u001B[0m 4s/step - accuracy: 0.9875 - loss: 0.3238Step 5/80 - Loss: 0.3303, Accuracy: 0.9400, Time: 3.77 seconds\n",
      "\u001B[1m 5/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:41\u001B[0m 4s/step - accuracy: 0.9780 - loss: 0.3251Step 6/80 - Loss: 0.3328, Accuracy: 0.9500, Time: 3.72 seconds\n",
      "\u001B[1m 6/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:37\u001B[0m 4s/step - accuracy: 0.9733 - loss: 0.3264Step 7/80 - Loss: 0.3565, Accuracy: 0.9286, Time: 3.90 seconds\n",
      "\u001B[1m 7/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:35\u001B[0m 4s/step - accuracy: 0.9669 - loss: 0.3307Step 8/80 - Loss: 0.3597, Accuracy: 0.9125, Time: 3.78 seconds\n",
      "\u001B[1m 8/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:31\u001B[0m 4s/step - accuracy: 0.9601 - loss: 0.3343Step 9/80 - Loss: 0.3745, Accuracy: 0.9111, Time: 3.76 seconds\n",
      "\u001B[1m 9/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:27\u001B[0m 4s/step - accuracy: 0.9547 - loss: 0.3388Step 10/80 - Loss: 0.3633, Accuracy: 0.9200, Time: 3.77 seconds\n",
      "\u001B[1m10/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:24\u001B[0m 4s/step - accuracy: 0.9512 - loss: 0.3412Step 11/80 - Loss: 0.3880, Accuracy: 0.8909, Time: 3.75 seconds\n",
      "\u001B[1m11/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:20\u001B[0m 4s/step - accuracy: 0.9457 - loss: 0.3455Step 12/80 - Loss: 0.3917, Accuracy: 0.8750, Time: 3.73 seconds\n",
      "\u001B[1m12/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:16\u001B[0m 4s/step - accuracy: 0.9398 - loss: 0.3494Step 13/80 - Loss: 0.3797, Accuracy: 0.8846, Time: 3.69 seconds\n",
      "\u001B[1m13/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:12\u001B[0m 4s/step - accuracy: 0.9356 - loss: 0.3517Step 14/80 - Loss: 0.3891, Accuracy: 0.8786, Time: 3.66 seconds\n",
      "\u001B[1m14/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:07\u001B[0m 4s/step - accuracy: 0.9315 - loss: 0.3544Step 15/80 - Loss: 0.3829, Accuracy: 0.8800, Time: 3.72 seconds\n",
      "\u001B[1m15/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:03\u001B[0m 4s/step - accuracy: 0.9281 - loss: 0.3563Step 16/80 - Loss: 0.3941, Accuracy: 0.8687, Time: 3.68 seconds\n",
      "\u001B[1m16/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:59\u001B[0m 4s/step - accuracy: 0.9244 - loss: 0.3586Step 17/80 - Loss: 0.4072, Accuracy: 0.8529, Time: 3.76 seconds\n",
      "\u001B[1m17/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:56\u001B[0m 4s/step - accuracy: 0.9202 - loss: 0.3615Step 18/80 - Loss: 0.4143, Accuracy: 0.8444, Time: 3.69 seconds\n",
      "\u001B[1m18/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:52\u001B[0m 4s/step - accuracy: 0.9160 - loss: 0.3644Step 19/80 - Loss: 0.4115, Accuracy: 0.8421, Time: 3.82 seconds\n",
      "\u001B[1m19/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:48\u001B[0m 4s/step - accuracy: 0.9121 - loss: 0.3669Step 20/80 - Loss: 0.4109, Accuracy: 0.8450, Time: 3.75 seconds\n",
      "\u001B[1m20/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:45\u001B[0m 4s/step - accuracy: 0.9087 - loss: 0.3691Step 21/80 - Loss: 0.4137, Accuracy: 0.8429, Time: 3.78 seconds\n",
      "\u001B[1m21/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:41\u001B[0m 4s/step - accuracy: 0.9056 - loss: 0.3712Step 22/80 - Loss: 0.4153, Accuracy: 0.8409, Time: 3.68 seconds\n",
      "\u001B[1m22/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:37\u001B[0m 4s/step - accuracy: 0.9026 - loss: 0.3732Step 23/80 - Loss: 0.4127, Accuracy: 0.8391, Time: 3.71 seconds\n",
      "\u001B[1m23/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:33\u001B[0m 4s/step - accuracy: 0.8999 - loss: 0.3749Step 24/80 - Loss: 0.4066, Accuracy: 0.8417, Time: 3.84 seconds\n",
      "\u001B[1m24/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:30\u001B[0m 4s/step - accuracy: 0.8975 - loss: 0.3763Step 25/80 - Loss: 0.4119, Accuracy: 0.8400, Time: 3.75 seconds\n",
      "\u001B[1m25/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:26\u001B[0m 4s/step - accuracy: 0.8952 - loss: 0.3777Step 26/80 - Loss: 0.4147, Accuracy: 0.8385, Time: 3.69 seconds\n",
      "\u001B[1m26/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:22\u001B[0m 4s/step - accuracy: 0.8930 - loss: 0.3791Step 27/80 - Loss: 0.4124, Accuracy: 0.8407, Time: 3.70 seconds\n",
      "\u001B[1m27/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:18\u001B[0m 4s/step - accuracy: 0.8910 - loss: 0.3803Step 28/80 - Loss: 0.4184, Accuracy: 0.8357, Time: 3.65 seconds\n",
      "\u001B[1m28/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:14\u001B[0m 4s/step - accuracy: 0.8891 - loss: 0.3817Step 29/80 - Loss: 0.4234, Accuracy: 0.8310, Time: 3.73 seconds\n",
      "\u001B[1m29/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:10\u001B[0m 4s/step - accuracy: 0.8871 - loss: 0.3831Step 30/80 - Loss: 0.4235, Accuracy: 0.8333, Time: 3.82 seconds\n",
      "\u001B[1m30/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:07\u001B[0m 4s/step - accuracy: 0.8853 - loss: 0.3845Step 31/80 - Loss: 0.4200, Accuracy: 0.8355, Time: 3.71 seconds\n",
      "\u001B[1m31/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:03\u001B[0m 4s/step - accuracy: 0.8837 - loss: 0.3856Step 32/80 - Loss: 0.4127, Accuracy: 0.8406, Time: 3.65 seconds\n",
      "\u001B[1m32/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:59\u001B[0m 4s/step - accuracy: 0.8823 - loss: 0.3865Step 33/80 - Loss: 0.4129, Accuracy: 0.8394, Time: 3.76 seconds\n",
      "\u001B[1m33/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:55\u001B[0m 4s/step - accuracy: 0.8810 - loss: 0.3873Step 34/80 - Loss: 0.4103, Accuracy: 0.8412, Time: 3.70 seconds\n",
      "\u001B[1m34/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:52\u001B[0m 4s/step - accuracy: 0.8799 - loss: 0.3880Step 35/80 - Loss: 0.4113, Accuracy: 0.8371, Time: 3.75 seconds\n",
      "\u001B[1m35/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:48\u001B[0m 4s/step - accuracy: 0.8786 - loss: 0.3886Step 36/80 - Loss: 0.4051, Accuracy: 0.8417, Time: 3.70 seconds\n",
      "\u001B[1m36/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:44\u001B[0m 4s/step - accuracy: 0.8776 - loss: 0.3891Step 37/80 - Loss: 0.4056, Accuracy: 0.8432, Time: 3.69 seconds\n",
      "\u001B[1m37/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:40\u001B[0m 4s/step - accuracy: 0.8767 - loss: 0.3895Step 38/80 - Loss: 0.4039, Accuracy: 0.8421, Time: 3.69 seconds\n",
      "\u001B[1m38/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:36\u001B[0m 4s/step - accuracy: 0.8758 - loss: 0.3899Step 39/80 - Loss: 0.3999, Accuracy: 0.8462, Time: 3.70 seconds\n",
      "\u001B[1m39/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:33\u001B[0m 4s/step - accuracy: 0.8750 - loss: 0.3902Step 40/80 - Loss: 0.3972, Accuracy: 0.8475, Time: 3.69 seconds\n",
      "\u001B[1m40/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:29\u001B[0m 4s/step - accuracy: 0.8743 - loss: 0.3903Step 41/80 - Loss: 0.3948, Accuracy: 0.8512, Time: 3.67 seconds\n",
      "\u001B[1m41/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:25\u001B[0m 4s/step - accuracy: 0.8738 - loss: 0.3904Step 42/80 - Loss: 0.3965, Accuracy: 0.8500, Time: 3.73 seconds\n",
      "\u001B[1m42/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:21\u001B[0m 4s/step - accuracy: 0.8732 - loss: 0.3906Step 43/80 - Loss: 0.3959, Accuracy: 0.8512, Time: 3.80 seconds\n",
      "\u001B[1m43/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:18\u001B[0m 4s/step - accuracy: 0.8727 - loss: 0.3907Step 44/80 - Loss: 0.3921, Accuracy: 0.8545, Time: 3.67 seconds\n",
      "\u001B[1m44/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:14\u001B[0m 4s/step - accuracy: 0.8723 - loss: 0.3907Step 45/80 - Loss: 0.3943, Accuracy: 0.8511, Time: 3.65 seconds\n",
      "\u001B[1m45/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:10\u001B[0m 4s/step - accuracy: 0.8718 - loss: 0.3908Step 46/80 - Loss: 0.3914, Accuracy: 0.8522, Time: 3.67 seconds\n",
      "\u001B[1m46/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:06\u001B[0m 4s/step - accuracy: 0.8714 - loss: 0.3908Step 47/80 - Loss: 0.3896, Accuracy: 0.8511, Time: 3.63 seconds\n",
      "\u001B[1m47/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:03\u001B[0m 4s/step - accuracy: 0.8709 - loss: 0.3908Step 48/80 - Loss: 0.3895, Accuracy: 0.8521, Time: 3.66 seconds\n",
      "\u001B[1m48/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:59\u001B[0m 4s/step - accuracy: 0.8705 - loss: 0.3908Step 49/80 - Loss: 0.3895, Accuracy: 0.8531, Time: 3.81 seconds\n",
      "\u001B[1m49/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:55\u001B[0m 4s/step - accuracy: 0.8702 - loss: 0.3908Step 50/80 - Loss: 0.3890, Accuracy: 0.8540, Time: 3.80 seconds\n",
      "\u001B[1m50/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:51\u001B[0m 4s/step - accuracy: 0.8699 - loss: 0.3907Step 51/80 - Loss: 0.3902, Accuracy: 0.8549, Time: 3.77 seconds\n",
      "\u001B[1m51/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:48\u001B[0m 4s/step - accuracy: 0.8696 - loss: 0.3907Step 52/80 - Loss: 0.3947, Accuracy: 0.8500, Time: 3.69 seconds\n",
      "\u001B[1m52/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:44\u001B[0m 4s/step - accuracy: 0.8692 - loss: 0.3908Step 53/80 - Loss: 0.3972, Accuracy: 0.8453, Time: 3.68 seconds\n",
      "\u001B[1m53/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:40\u001B[0m 4s/step - accuracy: 0.8687 - loss: 0.3909Step 54/80 - Loss: 0.3974, Accuracy: 0.8463, Time: 3.70 seconds\n",
      "\u001B[1m54/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:36\u001B[0m 4s/step - accuracy: 0.8683 - loss: 0.3910Step 55/80 - Loss: 0.3968, Accuracy: 0.8455, Time: 3.66 seconds\n",
      "\u001B[1m55/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:33\u001B[0m 4s/step - accuracy: 0.8679 - loss: 0.3911Step 56/80 - Loss: 0.3967, Accuracy: 0.8464, Time: 3.72 seconds\n",
      "\u001B[1m56/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:29\u001B[0m 4s/step - accuracy: 0.8675 - loss: 0.3912Step 57/80 - Loss: 0.3981, Accuracy: 0.8439, Time: 3.68 seconds\n",
      "\u001B[1m57/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:25\u001B[0m 4s/step - accuracy: 0.8671 - loss: 0.3914Step 58/80 - Loss: 0.3995, Accuracy: 0.8414, Time: 3.64 seconds\n",
      "\u001B[1m58/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:21\u001B[0m 4s/step - accuracy: 0.8667 - loss: 0.3915Step 59/80 - Loss: 0.3989, Accuracy: 0.8424, Time: 3.70 seconds\n",
      "\u001B[1m59/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:18\u001B[0m 4s/step - accuracy: 0.8663 - loss: 0.3916Step 60/80 - Loss: 0.3968, Accuracy: 0.8450, Time: 3.64 seconds\n",
      "\u001B[1m60/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:14\u001B[0m 4s/step - accuracy: 0.8659 - loss: 0.3917Step 61/80 - Loss: 0.3952, Accuracy: 0.8459, Time: 3.65 seconds\n",
      "\u001B[1m61/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:10\u001B[0m 4s/step - accuracy: 0.8656 - loss: 0.3918Step 62/80 - Loss: 0.3964, Accuracy: 0.8435, Time: 3.67 seconds\n",
      "\u001B[1m62/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:06\u001B[0m 4s/step - accuracy: 0.8652 - loss: 0.3918Step 63/80 - Loss: 0.3948, Accuracy: 0.8429, Time: 3.70 seconds\n",
      "\u001B[1m63/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:03\u001B[0m 4s/step - accuracy: 0.8649 - loss: 0.3919Step 64/80 - Loss: 0.3955, Accuracy: 0.8406, Time: 3.78 seconds\n",
      "\u001B[1m64/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m59s\u001B[0m 4s/step - accuracy: 0.8645 - loss: 0.3919 Step 65/80 - Loss: 0.3953, Accuracy: 0.8400, Time: 4.19 seconds\n",
      "\u001B[1m65/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m55s\u001B[0m 4s/step - accuracy: 0.8641 - loss: 0.3920Step 66/80 - Loss: 0.3919, Accuracy: 0.8424, Time: 3.96 seconds\n",
      "\u001B[1m66/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m52s\u001B[0m 4s/step - accuracy: 0.8638 - loss: 0.3920Step 67/80 - Loss: 0.3951, Accuracy: 0.8403, Time: 3.68 seconds\n",
      "\u001B[1m67/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m48s\u001B[0m 4s/step - accuracy: 0.8634 - loss: 0.3920Step 68/80 - Loss: 0.3965, Accuracy: 0.8397, Time: 3.70 seconds\n",
      "\u001B[1m68/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m44s\u001B[0m 4s/step - accuracy: 0.8631 - loss: 0.3921Step 69/80 - Loss: 0.3946, Accuracy: 0.8420, Time: 3.73 seconds\n",
      "\u001B[1m69/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m41s\u001B[0m 4s/step - accuracy: 0.8628 - loss: 0.3921Step 70/80 - Loss: 0.3973, Accuracy: 0.8400, Time: 3.65 seconds\n",
      "\u001B[1m70/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m37s\u001B[0m 4s/step - accuracy: 0.8625 - loss: 0.3922Step 71/80 - Loss: 0.3969, Accuracy: 0.8408, Time: 3.64 seconds\n",
      "\u001B[1m71/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m33s\u001B[0m 4s/step - accuracy: 0.8621 - loss: 0.3923Step 72/80 - Loss: 0.3972, Accuracy: 0.8389, Time: 3.66 seconds\n",
      "\u001B[1m72/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m29s\u001B[0m 4s/step - accuracy: 0.8618 - loss: 0.3923Step 73/80 - Loss: 0.3978, Accuracy: 0.8384, Time: 3.77 seconds\n",
      "\u001B[1m73/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.8615 - loss: 0.3924Step 74/80 - Loss: 0.3956, Accuracy: 0.8405, Time: 3.72 seconds\n",
      "\u001B[1m74/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m22s\u001B[0m 4s/step - accuracy: 0.8612 - loss: 0.3925Step 75/80 - Loss: 0.3950, Accuracy: 0.8413, Time: 3.72 seconds\n",
      "\u001B[1m75/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m18s\u001B[0m 4s/step - accuracy: 0.8610 - loss: 0.3925Step 76/80 - Loss: 0.3968, Accuracy: 0.8421, Time: 3.85 seconds\n",
      "\u001B[1m76/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m14s\u001B[0m 4s/step - accuracy: 0.8607 - loss: 0.3926Step 77/80 - Loss: 0.3963, Accuracy: 0.8416, Time: 3.64 seconds\n",
      "\u001B[1m77/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.8605 - loss: 0.3926Step 78/80 - Loss: 0.3936, Accuracy: 0.8436, Time: 3.75 seconds\n",
      "\u001B[1m78/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 0.8602 - loss: 0.3926 Step 79/80 - Loss: 0.3915, Accuracy: 0.8456, Time: 3.74 seconds\n",
      "\u001B[1m79/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 0.8601 - loss: 0.3926Step 80/80 - Loss: 0.3912, Accuracy: 0.8462, Time: 3.58 seconds\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8599 - loss: 0.3926\n",
      "Epoch 3: saving model to ./Finetune_Checkpoints\\model_epoch_03_val_loss_0.33.keras\n",
      "--- Epoch 3 completed in 361.05 seconds ---\n",
      "\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m361s\u001B[0m 4s/step - accuracy: 0.8597 - loss: 0.3926 - val_accuracy: 0.8800 - val_loss: 0.3285 - learning_rate: 9.0000e-06\n",
      "\n",
      "--- Starting Epoch 4 ---\n",
      "Epoch 4/10\n",
      "Step 1/80 - Loss: 0.2978, Accuracy: 1.0000, Time: 5.93 seconds\n",
      "\u001B[1m 1/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:52\u001B[0m 6s/step - accuracy: 1.0000 - loss: 0.2978Step 2/80 - Loss: 0.3204, Accuracy: 0.9000, Time: 3.69 seconds\n",
      "\u001B[1m 2/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:47\u001B[0m 4s/step - accuracy: 0.9500 - loss: 0.3091Step 3/80 - Loss: 0.3695, Accuracy: 0.8333, Time: 3.71 seconds\n",
      "\u001B[1m 3/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:45\u001B[0m 4s/step - accuracy: 0.9111 - loss: 0.3292Step 4/80 - Loss: 0.3677, Accuracy: 0.8750, Time: 3.69 seconds\n",
      "\u001B[1m 4/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:40\u001B[0m 4s/step - accuracy: 0.9021 - loss: 0.3388Step 5/80 - Loss: 0.3887, Accuracy: 0.8800, Time: 3.74 seconds\n",
      "\u001B[1m 5/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:38\u001B[0m 4s/step - accuracy: 0.8977 - loss: 0.3488Step 6/80 - Loss: 0.3474, Accuracy: 0.9000, Time: 3.67 seconds\n",
      "\u001B[1m 6/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:33\u001B[0m 4s/step - accuracy: 0.8981 - loss: 0.3486Step 7/80 - Loss: 0.3653, Accuracy: 0.8714, Time: 3.64 seconds\n",
      "\u001B[1m 7/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:29\u001B[0m 4s/step - accuracy: 0.8943 - loss: 0.3510Step 8/80 - Loss: 0.3475, Accuracy: 0.8875, Time: 3.68 seconds\n",
      "\u001B[1m 8/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:25\u001B[0m 4s/step - accuracy: 0.8934 - loss: 0.3505Step 9/80 - Loss: 0.3534, Accuracy: 0.8778, Time: 3.68 seconds\n",
      "\u001B[1m 9/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:21\u001B[0m 4s/step - accuracy: 0.8917 - loss: 0.3508Step 10/80 - Loss: 0.3360, Accuracy: 0.8900, Time: 3.65 seconds\n",
      "\u001B[1m10/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:17\u001B[0m 4s/step - accuracy: 0.8915 - loss: 0.3494Step 11/80 - Loss: 0.3192, Accuracy: 0.9000, Time: 3.66 seconds\n",
      "\u001B[1m11/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:14\u001B[0m 4s/step - accuracy: 0.8923 - loss: 0.3466Step 12/80 - Loss: 0.3264, Accuracy: 0.8917, Time: 3.70 seconds\n",
      "\u001B[1m12/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:10\u001B[0m 4s/step - accuracy: 0.8922 - loss: 0.3449Step 13/80 - Loss: 0.3228, Accuracy: 0.8923, Time: 3.78 seconds\n",
      "\u001B[1m13/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:07\u001B[0m 4s/step - accuracy: 0.8922 - loss: 0.3432Step 14/80 - Loss: 0.3158, Accuracy: 0.8929, Time: 3.79 seconds\n",
      "\u001B[1m14/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:04\u001B[0m 4s/step - accuracy: 0.8923 - loss: 0.3413Step 15/80 - Loss: 0.3228, Accuracy: 0.8933, Time: 3.70 seconds\n",
      "\u001B[1m15/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:00\u001B[0m 4s/step - accuracy: 0.8923 - loss: 0.3400Step 16/80 - Loss: 0.3150, Accuracy: 0.9000, Time: 3.62 seconds\n",
      "\u001B[1m16/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:56\u001B[0m 4s/step - accuracy: 0.8928 - loss: 0.3385Step 17/80 - Loss: 0.3099, Accuracy: 0.9000, Time: 3.70 seconds\n",
      "\u001B[1m17/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:52\u001B[0m 4s/step - accuracy: 0.8932 - loss: 0.3368Step 18/80 - Loss: 0.3049, Accuracy: 0.9056, Time: 3.66 seconds\n",
      "\u001B[1m18/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:48\u001B[0m 4s/step - accuracy: 0.8939 - loss: 0.3350Step 19/80 - Loss: 0.2992, Accuracy: 0.9105, Time: 3.69 seconds\n",
      "\u001B[1m19/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:45\u001B[0m 4s/step - accuracy: 0.8948 - loss: 0.3331Step 20/80 - Loss: 0.3032, Accuracy: 0.9050, Time: 3.62 seconds\n",
      "\u001B[1m20/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:41\u001B[0m 4s/step - accuracy: 0.8953 - loss: 0.3316Step 21/80 - Loss: 0.3090, Accuracy: 0.8952, Time: 3.77 seconds\n",
      "\u001B[1m21/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:37\u001B[0m 4s/step - accuracy: 0.8953 - loss: 0.3306Step 22/80 - Loss: 0.3034, Accuracy: 0.9000, Time: 3.70 seconds\n",
      "\u001B[1m22/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:34\u001B[0m 4s/step - accuracy: 0.8955 - loss: 0.3293Step 23/80 - Loss: 0.2988, Accuracy: 0.9043, Time: 3.67 seconds\n",
      "\u001B[1m23/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:30\u001B[0m 4s/step - accuracy: 0.8959 - loss: 0.3280Step 24/80 - Loss: 0.2962, Accuracy: 0.9083, Time: 3.78 seconds\n",
      "\u001B[1m24/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:27\u001B[0m 4s/step - accuracy: 0.8964 - loss: 0.3267Step 25/80 - Loss: 0.2916, Accuracy: 0.9120, Time: 3.67 seconds\n",
      "\u001B[1m25/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:23\u001B[0m 4s/step - accuracy: 0.8970 - loss: 0.3253Step 26/80 - Loss: 0.2914, Accuracy: 0.9115, Time: 3.66 seconds\n",
      "\u001B[1m26/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:19\u001B[0m 4s/step - accuracy: 0.8976 - loss: 0.3240Step 27/80 - Loss: 0.2976, Accuracy: 0.9000, Time: 3.71 seconds\n",
      "\u001B[1m27/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:15\u001B[0m 4s/step - accuracy: 0.8977 - loss: 0.3230Step 28/80 - Loss: 0.2986, Accuracy: 0.9000, Time: 3.67 seconds\n",
      "\u001B[1m28/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:12\u001B[0m 4s/step - accuracy: 0.8978 - loss: 0.3221Step 29/80 - Loss: 0.2940, Accuracy: 0.9034, Time: 3.66 seconds\n",
      "\u001B[1m29/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:08\u001B[0m 4s/step - accuracy: 0.8980 - loss: 0.3212Step 30/80 - Loss: 0.2921, Accuracy: 0.9067, Time: 3.62 seconds\n",
      "\u001B[1m30/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:04\u001B[0m 4s/step - accuracy: 0.8983 - loss: 0.3202Step 31/80 - Loss: 0.2908, Accuracy: 0.9097, Time: 3.72 seconds\n",
      "\u001B[1m31/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:00\u001B[0m 4s/step - accuracy: 0.8986 - loss: 0.3192Step 32/80 - Loss: 0.2909, Accuracy: 0.9094, Time: 3.65 seconds\n",
      "\u001B[1m32/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:57\u001B[0m 4s/step - accuracy: 0.8990 - loss: 0.3184Step 33/80 - Loss: 0.2872, Accuracy: 0.9121, Time: 3.64 seconds\n",
      "\u001B[1m33/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:53\u001B[0m 4s/step - accuracy: 0.8994 - loss: 0.3174Step 34/80 - Loss: 0.2852, Accuracy: 0.9147, Time: 3.71 seconds\n",
      "\u001B[1m34/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:49\u001B[0m 4s/step - accuracy: 0.8998 - loss: 0.3165Step 35/80 - Loss: 0.2820, Accuracy: 0.9143, Time: 3.67 seconds\n",
      "\u001B[1m35/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:46\u001B[0m 4s/step - accuracy: 0.9002 - loss: 0.3155Step 36/80 - Loss: 0.2815, Accuracy: 0.9139, Time: 3.67 seconds\n",
      "\u001B[1m36/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:42\u001B[0m 4s/step - accuracy: 0.9006 - loss: 0.3145Step 37/80 - Loss: 0.2805, Accuracy: 0.9162, Time: 3.67 seconds\n",
      "\u001B[1m37/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:38\u001B[0m 4s/step - accuracy: 0.9010 - loss: 0.3136Step 38/80 - Loss: 0.2882, Accuracy: 0.9079, Time: 3.67 seconds\n",
      "\u001B[1m38/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:34\u001B[0m 4s/step - accuracy: 0.9012 - loss: 0.3129Step 39/80 - Loss: 0.2923, Accuracy: 0.9051, Time: 3.73 seconds\n",
      "\u001B[1m39/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:31\u001B[0m 4s/step - accuracy: 0.9013 - loss: 0.3124Step 40/80 - Loss: 0.2919, Accuracy: 0.9050, Time: 3.74 seconds\n",
      "\u001B[1m40/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:27\u001B[0m 4s/step - accuracy: 0.9014 - loss: 0.3119Step 41/80 - Loss: 0.2929, Accuracy: 0.9024, Time: 3.68 seconds\n",
      "\u001B[1m41/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:23\u001B[0m 4s/step - accuracy: 0.9014 - loss: 0.3114Step 42/80 - Loss: 0.2941, Accuracy: 0.9024, Time: 3.73 seconds\n",
      "\u001B[1m42/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:20\u001B[0m 4s/step - accuracy: 0.9015 - loss: 0.3110Step 43/80 - Loss: 0.2915, Accuracy: 0.9047, Time: 3.69 seconds\n",
      "\u001B[1m43/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:16\u001B[0m 4s/step - accuracy: 0.9015 - loss: 0.3106Step 44/80 - Loss: 0.2967, Accuracy: 0.9023, Time: 3.75 seconds\n",
      "\u001B[1m44/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:12\u001B[0m 4s/step - accuracy: 0.9015 - loss: 0.3103Step 45/80 - Loss: 0.2961, Accuracy: 0.9000, Time: 3.64 seconds\n",
      "\u001B[1m45/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:09\u001B[0m 4s/step - accuracy: 0.9015 - loss: 0.3099Step 46/80 - Loss: 0.2950, Accuracy: 0.9022, Time: 3.63 seconds\n",
      "\u001B[1m46/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:05\u001B[0m 4s/step - accuracy: 0.9015 - loss: 0.3096Step 47/80 - Loss: 0.2931, Accuracy: 0.9043, Time: 3.67 seconds\n",
      "\u001B[1m47/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:01\u001B[0m 4s/step - accuracy: 0.9016 - loss: 0.3093Step 48/80 - Loss: 0.2919, Accuracy: 0.9062, Time: 3.79 seconds\n",
      "\u001B[1m48/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:58\u001B[0m 4s/step - accuracy: 0.9017 - loss: 0.3089Step 49/80 - Loss: 0.2910, Accuracy: 0.9082, Time: 4.05 seconds\n",
      "\u001B[1m49/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:54\u001B[0m 4s/step - accuracy: 0.9018 - loss: 0.3085Step 50/80 - Loss: 0.2883, Accuracy: 0.9080, Time: 4.08 seconds\n",
      "\u001B[1m50/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:51\u001B[0m 4s/step - accuracy: 0.9019 - loss: 0.3081Step 51/80 - Loss: 0.2905, Accuracy: 0.9039, Time: 3.82 seconds\n",
      "\u001B[1m51/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:47\u001B[0m 4s/step - accuracy: 0.9020 - loss: 0.3078Step 52/80 - Loss: 0.2901, Accuracy: 0.9058, Time: 3.72 seconds\n",
      "\u001B[1m52/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:43\u001B[0m 4s/step - accuracy: 0.9020 - loss: 0.3074Step 53/80 - Loss: 0.2914, Accuracy: 0.9019, Time: 3.79 seconds\n",
      "\u001B[1m53/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:40\u001B[0m 4s/step - accuracy: 0.9020 - loss: 0.3071Step 54/80 - Loss: 0.2982, Accuracy: 0.8981, Time: 3.70 seconds\n",
      "\u001B[1m54/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:36\u001B[0m 4s/step - accuracy: 0.9020 - loss: 0.3070Step 55/80 - Loss: 0.2981, Accuracy: 0.8982, Time: 3.78 seconds\n",
      "\u001B[1m55/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:32\u001B[0m 4s/step - accuracy: 0.9019 - loss: 0.3068Step 56/80 - Loss: 0.3030, Accuracy: 0.8946, Time: 3.72 seconds\n",
      "\u001B[1m56/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:29\u001B[0m 4s/step - accuracy: 0.9018 - loss: 0.3068Step 57/80 - Loss: 0.3062, Accuracy: 0.8930, Time: 3.74 seconds\n",
      "\u001B[1m57/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:25\u001B[0m 4s/step - accuracy: 0.9016 - loss: 0.3067Step 58/80 - Loss: 0.3040, Accuracy: 0.8948, Time: 3.72 seconds\n",
      "\u001B[1m58/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:21\u001B[0m 4s/step - accuracy: 0.9015 - loss: 0.3067Step 59/80 - Loss: 0.3070, Accuracy: 0.8915, Time: 3.64 seconds\n",
      "\u001B[1m59/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:17\u001B[0m 4s/step - accuracy: 0.9013 - loss: 0.3067Step 60/80 - Loss: 0.3117, Accuracy: 0.8900, Time: 3.84 seconds\n",
      "\u001B[1m60/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:14\u001B[0m 4s/step - accuracy: 0.9011 - loss: 0.3068Step 61/80 - Loss: 0.3117, Accuracy: 0.8902, Time: 3.88 seconds\n",
      "\u001B[1m61/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:10\u001B[0m 4s/step - accuracy: 0.9010 - loss: 0.3069Step 62/80 - Loss: 0.3109, Accuracy: 0.8919, Time: 3.64 seconds\n",
      "\u001B[1m62/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:06\u001B[0m 4s/step - accuracy: 0.9008 - loss: 0.3069Step 63/80 - Loss: 0.3153, Accuracy: 0.8889, Time: 3.69 seconds\n",
      "\u001B[1m63/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:03\u001B[0m 4s/step - accuracy: 0.9006 - loss: 0.3071Step 64/80 - Loss: 0.3163, Accuracy: 0.8875, Time: 3.70 seconds\n",
      "\u001B[1m64/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m59s\u001B[0m 4s/step - accuracy: 0.9004 - loss: 0.3072 Step 65/80 - Loss: 0.3144, Accuracy: 0.8892, Time: 3.72 seconds\n",
      "\u001B[1m65/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m55s\u001B[0m 4s/step - accuracy: 0.9003 - loss: 0.3073Step 66/80 - Loss: 0.3143, Accuracy: 0.8894, Time: 3.73 seconds\n",
      "\u001B[1m66/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m52s\u001B[0m 4s/step - accuracy: 0.9001 - loss: 0.3074Step 67/80 - Loss: 0.3175, Accuracy: 0.8881, Time: 3.73 seconds\n",
      "\u001B[1m67/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m48s\u001B[0m 4s/step - accuracy: 0.8999 - loss: 0.3076Step 68/80 - Loss: 0.3151, Accuracy: 0.8897, Time: 3.79 seconds\n",
      "\u001B[1m68/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m44s\u001B[0m 4s/step - accuracy: 0.8998 - loss: 0.3077Step 69/80 - Loss: 0.3149, Accuracy: 0.8899, Time: 3.76 seconds\n",
      "\u001B[1m69/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m40s\u001B[0m 4s/step - accuracy: 0.8996 - loss: 0.3078Step 70/80 - Loss: 0.3150, Accuracy: 0.8900, Time: 3.69 seconds\n",
      "\u001B[1m70/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m37s\u001B[0m 4s/step - accuracy: 0.8995 - loss: 0.3079Step 71/80 - Loss: 0.3164, Accuracy: 0.8901, Time: 3.79 seconds\n",
      "\u001B[1m71/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m33s\u001B[0m 4s/step - accuracy: 0.8993 - loss: 0.3080Step 72/80 - Loss: 0.3195, Accuracy: 0.8875, Time: 3.68 seconds\n",
      "\u001B[1m72/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m29s\u001B[0m 4s/step - accuracy: 0.8992 - loss: 0.3082Step 73/80 - Loss: 0.3207, Accuracy: 0.8863, Time: 3.67 seconds\n",
      "\u001B[1m73/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.8990 - loss: 0.3083Step 74/80 - Loss: 0.3200, Accuracy: 0.8878, Time: 3.66 seconds\n",
      "\u001B[1m74/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m22s\u001B[0m 4s/step - accuracy: 0.8989 - loss: 0.3085Step 75/80 - Loss: 0.3206, Accuracy: 0.8880, Time: 3.74 seconds\n",
      "\u001B[1m75/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m18s\u001B[0m 4s/step - accuracy: 0.8987 - loss: 0.3087Step 76/80 - Loss: 0.3223, Accuracy: 0.8855, Time: 3.64 seconds\n",
      "\u001B[1m76/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m14s\u001B[0m 4s/step - accuracy: 0.8985 - loss: 0.3088Step 77/80 - Loss: 0.3220, Accuracy: 0.8857, Time: 3.64 seconds\n",
      "\u001B[1m77/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.8984 - loss: 0.3090Step 78/80 - Loss: 0.3199, Accuracy: 0.8872, Time: 3.71 seconds\n",
      "\u001B[1m78/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 0.8982 - loss: 0.3092 Step 79/80 - Loss: 0.3195, Accuracy: 0.8886, Time: 3.68 seconds\n",
      "\u001B[1m79/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 0.8981 - loss: 0.3093Step 80/80 - Loss: 0.3188, Accuracy: 0.8888, Time: 3.67 seconds\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8980 - loss: 0.3094\n",
      "Epoch 4: saving model to ./Finetune_Checkpoints\\model_epoch_04_val_loss_0.31.keras\n",
      "--- Epoch 4 completed in 365.17 seconds ---\n",
      "\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m365s\u001B[0m 5s/step - accuracy: 0.8979 - loss: 0.3095 - val_accuracy: 0.8750 - val_loss: 0.3093 - learning_rate: 8.1000e-06\n",
      "\n",
      "--- Starting Epoch 5 ---\n",
      "Epoch 5/10\n",
      "Step 1/80 - Loss: 0.2144, Accuracy: 1.0000, Time: 8.20 seconds\n",
      "\u001B[1m 1/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m10:50\u001B[0m 8s/step - accuracy: 1.0000 - loss: 0.2144Step 2/80 - Loss: 0.2835, Accuracy: 0.9500, Time: 3.66 seconds\n",
      "\u001B[1m 2/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:45\u001B[0m 4s/step - accuracy: 0.9750 - loss: 0.2490 Step 3/80 - Loss: 0.2436, Accuracy: 0.9667, Time: 3.75 seconds\n",
      "\u001B[1m 3/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:45\u001B[0m 4s/step - accuracy: 0.9722 - loss: 0.2472Step 4/80 - Loss: 0.2461, Accuracy: 0.9500, Time: 3.73 seconds\n",
      "\u001B[1m 4/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:42\u001B[0m 4s/step - accuracy: 0.9667 - loss: 0.2469Step 5/80 - Loss: 0.2727, Accuracy: 0.9200, Time: 3.67 seconds\n",
      "\u001B[1m 5/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:38\u001B[0m 4s/step - accuracy: 0.9573 - loss: 0.2521Step 6/80 - Loss: 0.2734, Accuracy: 0.9167, Time: 3.65 seconds\n",
      "\u001B[1m 6/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:33\u001B[0m 4s/step - accuracy: 0.9506 - loss: 0.2556Step 7/80 - Loss: 0.2666, Accuracy: 0.9286, Time: 3.80 seconds\n",
      "\u001B[1m 7/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:31\u001B[0m 4s/step - accuracy: 0.9474 - loss: 0.2572Step 8/80 - Loss: 0.2934, Accuracy: 0.9125, Time: 3.62 seconds\n",
      "\u001B[1m 8/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:26\u001B[0m 4s/step - accuracy: 0.9431 - loss: 0.2617Step 9/80 - Loss: 0.3184, Accuracy: 0.9000, Time: 3.74 seconds\n",
      "\u001B[1m 9/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:23\u001B[0m 4s/step - accuracy: 0.9383 - loss: 0.2680Step 10/80 - Loss: 0.2990, Accuracy: 0.9100, Time: 3.74 seconds\n",
      "\u001B[1m10/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:19\u001B[0m 4s/step - accuracy: 0.9354 - loss: 0.2711Step 11/80 - Loss: 0.2901, Accuracy: 0.9182, Time: 3.61 seconds\n",
      "\u001B[1m11/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:15\u001B[0m 4s/step - accuracy: 0.9339 - loss: 0.2729Step 12/80 - Loss: 0.2822, Accuracy: 0.9167, Time: 3.80 seconds\n",
      "\u001B[1m12/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:12\u001B[0m 4s/step - accuracy: 0.9324 - loss: 0.2736Step 13/80 - Loss: 0.2833, Accuracy: 0.9154, Time: 3.63 seconds\n",
      "\u001B[1m13/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:08\u001B[0m 4s/step - accuracy: 0.9311 - loss: 0.2744Step 14/80 - Loss: 0.2719, Accuracy: 0.9214, Time: 3.76 seconds\n",
      "\u001B[1m14/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:04\u001B[0m 4s/step - accuracy: 0.9304 - loss: 0.2742Step 15/80 - Loss: 0.2681, Accuracy: 0.9267, Time: 3.66 seconds\n",
      "\u001B[1m15/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:00\u001B[0m 4s/step - accuracy: 0.9302 - loss: 0.2738Step 16/80 - Loss: 0.2631, Accuracy: 0.9312, Time: 3.62 seconds\n",
      "\u001B[1m16/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:56\u001B[0m 4s/step - accuracy: 0.9302 - loss: 0.2731Step 17/80 - Loss: 0.2638, Accuracy: 0.9294, Time: 3.77 seconds\n",
      "\u001B[1m17/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:53\u001B[0m 4s/step - accuracy: 0.9302 - loss: 0.2726Step 18/80 - Loss: 0.2589, Accuracy: 0.9333, Time: 3.66 seconds\n",
      "\u001B[1m18/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:49\u001B[0m 4s/step - accuracy: 0.9304 - loss: 0.2718Step 19/80 - Loss: 0.2583, Accuracy: 0.9316, Time: 3.62 seconds\n",
      "\u001B[1m19/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:45\u001B[0m 4s/step - accuracy: 0.9304 - loss: 0.2711Step 20/80 - Loss: 0.2558, Accuracy: 0.9300, Time: 3.75 seconds\n",
      "\u001B[1m20/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:42\u001B[0m 4s/step - accuracy: 0.9304 - loss: 0.2703Step 21/80 - Loss: 0.2487, Accuracy: 0.9333, Time: 3.80 seconds\n",
      "\u001B[1m21/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:38\u001B[0m 4s/step - accuracy: 0.9306 - loss: 0.2693Step 22/80 - Loss: 0.2500, Accuracy: 0.9318, Time: 3.78 seconds\n",
      "\u001B[1m22/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:35\u001B[0m 4s/step - accuracy: 0.9306 - loss: 0.2684Step 23/80 - Loss: 0.2481, Accuracy: 0.9304, Time: 3.69 seconds\n",
      "\u001B[1m23/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:31\u001B[0m 4s/step - accuracy: 0.9306 - loss: 0.2676Step 24/80 - Loss: 0.2428, Accuracy: 0.9333, Time: 3.71 seconds\n",
      "\u001B[1m24/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:27\u001B[0m 4s/step - accuracy: 0.9307 - loss: 0.2665Step 25/80 - Loss: 0.2426, Accuracy: 0.9320, Time: 3.67 seconds\n",
      "\u001B[1m25/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:23\u001B[0m 4s/step - accuracy: 0.9308 - loss: 0.2656Step 26/80 - Loss: 0.2417, Accuracy: 0.9308, Time: 3.67 seconds\n",
      "\u001B[1m26/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:20\u001B[0m 4s/step - accuracy: 0.9308 - loss: 0.2646Step 27/80 - Loss: 0.2501, Accuracy: 0.9259, Time: 3.70 seconds\n",
      "\u001B[1m27/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:16\u001B[0m 4s/step - accuracy: 0.9306 - loss: 0.2641Step 28/80 - Loss: 0.2591, Accuracy: 0.9143, Time: 3.69 seconds\n",
      "\u001B[1m28/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:12\u001B[0m 4s/step - accuracy: 0.9300 - loss: 0.2639Step 29/80 - Loss: 0.2575, Accuracy: 0.9138, Time: 3.63 seconds\n",
      "\u001B[1m29/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:08\u001B[0m 4s/step - accuracy: 0.9294 - loss: 0.2637Step 30/80 - Loss: 0.2550, Accuracy: 0.9133, Time: 3.80 seconds\n",
      "\u001B[1m30/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:05\u001B[0m 4s/step - accuracy: 0.9289 - loss: 0.2634Step 31/80 - Loss: 0.2522, Accuracy: 0.9161, Time: 4.18 seconds\n",
      "\u001B[1m31/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:02\u001B[0m 4s/step - accuracy: 0.9285 - loss: 0.2631Step 32/80 - Loss: 0.2487, Accuracy: 0.9187, Time: 3.93 seconds\n",
      "\u001B[1m32/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:59\u001B[0m 4s/step - accuracy: 0.9282 - loss: 0.2626Step 33/80 - Loss: 0.2457, Accuracy: 0.9212, Time: 3.79 seconds\n",
      "\u001B[1m33/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:55\u001B[0m 4s/step - accuracy: 0.9280 - loss: 0.2621Step 34/80 - Loss: 0.2407, Accuracy: 0.9235, Time: 3.63 seconds\n",
      "\u001B[1m34/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:51\u001B[0m 4s/step - accuracy: 0.9279 - loss: 0.2615Step 35/80 - Loss: 0.2406, Accuracy: 0.9257, Time: 3.66 seconds\n",
      "\u001B[1m35/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:47\u001B[0m 4s/step - accuracy: 0.9278 - loss: 0.2609Step 36/80 - Loss: 0.2398, Accuracy: 0.9278, Time: 3.74 seconds\n",
      "\u001B[1m36/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:44\u001B[0m 4s/step - accuracy: 0.9278 - loss: 0.2603Step 37/80 - Loss: 0.2375, Accuracy: 0.9297, Time: 3.68 seconds\n",
      "\u001B[1m37/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:40\u001B[0m 4s/step - accuracy: 0.9278 - loss: 0.2597Step 38/80 - Loss: 0.2423, Accuracy: 0.9237, Time: 3.78 seconds\n",
      "\u001B[1m38/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:36\u001B[0m 4s/step - accuracy: 0.9277 - loss: 0.2592Step 39/80 - Loss: 0.2401, Accuracy: 0.9256, Time: 3.92 seconds\n",
      "\u001B[1m39/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:33\u001B[0m 4s/step - accuracy: 0.9277 - loss: 0.2587Step 40/80 - Loss: 0.2491, Accuracy: 0.9175, Time: 3.87 seconds\n",
      "\u001B[1m40/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:29\u001B[0m 4s/step - accuracy: 0.9274 - loss: 0.2585Step 41/80 - Loss: 0.2472, Accuracy: 0.9195, Time: 4.12 seconds\n",
      "\u001B[1m41/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:26\u001B[0m 4s/step - accuracy: 0.9272 - loss: 0.2582Step 42/80 - Loss: 0.2450, Accuracy: 0.9214, Time: 3.91 seconds\n",
      "\u001B[1m42/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:22\u001B[0m 4s/step - accuracy: 0.9271 - loss: 0.2579Step 43/80 - Loss: 0.2494, Accuracy: 0.9163, Time: 3.85 seconds\n",
      "\u001B[1m43/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:18\u001B[0m 4s/step - accuracy: 0.9268 - loss: 0.2577Step 44/80 - Loss: 0.2481, Accuracy: 0.9159, Time: 3.72 seconds\n",
      "\u001B[1m44/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:15\u001B[0m 4s/step - accuracy: 0.9266 - loss: 0.2575Step 45/80 - Loss: 0.2538, Accuracy: 0.9133, Time: 3.72 seconds\n",
      "\u001B[1m45/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:11\u001B[0m 4s/step - accuracy: 0.9263 - loss: 0.2574Step 46/80 - Loss: 0.2528, Accuracy: 0.9152, Time: 3.82 seconds\n",
      "\u001B[1m46/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:07\u001B[0m 4s/step - accuracy: 0.9261 - loss: 0.2573Step 47/80 - Loss: 0.2504, Accuracy: 0.9170, Time: 3.65 seconds\n",
      "\u001B[1m47/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:03\u001B[0m 4s/step - accuracy: 0.9259 - loss: 0.2571Step 48/80 - Loss: 0.2518, Accuracy: 0.9167, Time: 3.83 seconds\n",
      "\u001B[1m48/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m2:00\u001B[0m 4s/step - accuracy: 0.9257 - loss: 0.2570Step 49/80 - Loss: 0.2496, Accuracy: 0.9184, Time: 3.74 seconds\n",
      "\u001B[1m49/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:56\u001B[0m 4s/step - accuracy: 0.9255 - loss: 0.2569Step 50/80 - Loss: 0.2487, Accuracy: 0.9200, Time: 3.75 seconds\n",
      "\u001B[1m50/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:52\u001B[0m 4s/step - accuracy: 0.9254 - loss: 0.2567Step 51/80 - Loss: 0.2494, Accuracy: 0.9176, Time: 3.68 seconds\n",
      "\u001B[1m51/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:48\u001B[0m 4s/step - accuracy: 0.9253 - loss: 0.2566Step 52/80 - Loss: 0.2505, Accuracy: 0.9173, Time: 3.68 seconds\n",
      "\u001B[1m52/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:44\u001B[0m 4s/step - accuracy: 0.9251 - loss: 0.2565Step 53/80 - Loss: 0.2524, Accuracy: 0.9170, Time: 3.69 seconds\n",
      "\u001B[1m53/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:41\u001B[0m 4s/step - accuracy: 0.9250 - loss: 0.2564Step 54/80 - Loss: 0.2538, Accuracy: 0.9148, Time: 3.68 seconds\n",
      "\u001B[1m54/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:37\u001B[0m 4s/step - accuracy: 0.9248 - loss: 0.2563Step 55/80 - Loss: 0.2536, Accuracy: 0.9164, Time: 3.81 seconds\n",
      "\u001B[1m55/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:33\u001B[0m 4s/step - accuracy: 0.9246 - loss: 0.2563Step 56/80 - Loss: 0.2521, Accuracy: 0.9179, Time: 3.76 seconds\n",
      "\u001B[1m56/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:29\u001B[0m 4s/step - accuracy: 0.9245 - loss: 0.2562Step 57/80 - Loss: 0.2509, Accuracy: 0.9193, Time: 3.67 seconds\n",
      "\u001B[1m57/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:26\u001B[0m 4s/step - accuracy: 0.9244 - loss: 0.2561Step 58/80 - Loss: 0.2528, Accuracy: 0.9172, Time: 3.68 seconds\n",
      "\u001B[1m58/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:22\u001B[0m 4s/step - accuracy: 0.9243 - loss: 0.2561Step 59/80 - Loss: 0.2519, Accuracy: 0.9186, Time: 3.78 seconds\n",
      "\u001B[1m59/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:18\u001B[0m 4s/step - accuracy: 0.9242 - loss: 0.2560Step 60/80 - Loss: 0.2503, Accuracy: 0.9200, Time: 3.69 seconds\n",
      "\u001B[1m60/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:14\u001B[0m 4s/step - accuracy: 0.9241 - loss: 0.2559Step 61/80 - Loss: 0.2488, Accuracy: 0.9213, Time: 3.66 seconds\n",
      "\u001B[1m61/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:11\u001B[0m 4s/step - accuracy: 0.9241 - loss: 0.2558Step 62/80 - Loss: 0.2485, Accuracy: 0.9210, Time: 3.70 seconds\n",
      "\u001B[1m62/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:07\u001B[0m 4s/step - accuracy: 0.9240 - loss: 0.2557Step 63/80 - Loss: 0.2487, Accuracy: 0.9190, Time: 3.82 seconds\n",
      "\u001B[1m63/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:03\u001B[0m 4s/step - accuracy: 0.9239 - loss: 0.2556Step 64/80 - Loss: 0.2481, Accuracy: 0.9187, Time: 3.81 seconds\n",
      "\u001B[1m64/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m59s\u001B[0m 4s/step - accuracy: 0.9239 - loss: 0.2554 Step 65/80 - Loss: 0.2464, Accuracy: 0.9200, Time: 3.75 seconds\n",
      "\u001B[1m65/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m56s\u001B[0m 4s/step - accuracy: 0.9238 - loss: 0.2553Step 66/80 - Loss: 0.2450, Accuracy: 0.9212, Time: 3.74 seconds\n",
      "\u001B[1m66/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m52s\u001B[0m 4s/step - accuracy: 0.9238 - loss: 0.2551Step 67/80 - Loss: 0.2438, Accuracy: 0.9224, Time: 3.65 seconds\n",
      "\u001B[1m67/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m48s\u001B[0m 4s/step - accuracy: 0.9237 - loss: 0.2550Step 68/80 - Loss: 0.2432, Accuracy: 0.9235, Time: 3.73 seconds\n",
      "\u001B[1m68/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m44s\u001B[0m 4s/step - accuracy: 0.9237 - loss: 0.2548Step 69/80 - Loss: 0.2428, Accuracy: 0.9246, Time: 3.66 seconds\n",
      "\u001B[1m69/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m41s\u001B[0m 4s/step - accuracy: 0.9237 - loss: 0.2546Step 70/80 - Loss: 0.2420, Accuracy: 0.9257, Time: 3.77 seconds\n",
      "\u001B[1m70/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m37s\u001B[0m 4s/step - accuracy: 0.9238 - loss: 0.2544Step 71/80 - Loss: 0.2454, Accuracy: 0.9239, Time: 3.68 seconds\n",
      "\u001B[1m71/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m33s\u001B[0m 4s/step - accuracy: 0.9238 - loss: 0.2543Step 72/80 - Loss: 0.2432, Accuracy: 0.9250, Time: 3.76 seconds\n",
      "\u001B[1m72/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m29s\u001B[0m 4s/step - accuracy: 0.9238 - loss: 0.2542Step 73/80 - Loss: 0.2438, Accuracy: 0.9247, Time: 3.65 seconds\n",
      "\u001B[1m73/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.9238 - loss: 0.2540Step 74/80 - Loss: 0.2421, Accuracy: 0.9257, Time: 3.73 seconds\n",
      "\u001B[1m74/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m22s\u001B[0m 4s/step - accuracy: 0.9238 - loss: 0.2539Step 75/80 - Loss: 0.2401, Accuracy: 0.9267, Time: 3.71 seconds\n",
      "\u001B[1m75/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m18s\u001B[0m 4s/step - accuracy: 0.9239 - loss: 0.2537Step 76/80 - Loss: 0.2395, Accuracy: 0.9276, Time: 3.81 seconds\n",
      "\u001B[1m76/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m14s\u001B[0m 4s/step - accuracy: 0.9239 - loss: 0.2535Step 77/80 - Loss: 0.2384, Accuracy: 0.9286, Time: 3.68 seconds\n",
      "\u001B[1m77/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.9240 - loss: 0.2533Step 78/80 - Loss: 0.2376, Accuracy: 0.9295, Time: 3.86 seconds\n",
      "\u001B[1m78/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 0.9241 - loss: 0.2531 Step 79/80 - Loss: 0.2360, Accuracy: 0.9304, Time: 3.66 seconds\n",
      "\u001B[1m79/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 0.9241 - loss: 0.2529Step 80/80 - Loss: 0.2367, Accuracy: 0.9300, Time: 3.63 seconds\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9242 - loss: 0.2527\n",
      "Epoch 5: saving model to ./Finetune_Checkpoints\\model_epoch_05_val_loss_0.22.keras\n",
      "--- Epoch 5 completed in 362.58 seconds ---\n",
      "\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m363s\u001B[0m 4s/step - accuracy: 0.9243 - loss: 0.2525 - val_accuracy: 0.9500 - val_loss: 0.2190 - learning_rate: 7.2900e-06\n",
      "\n",
      "--- Starting Epoch 6 ---\n",
      "Epoch 6/10\n",
      "Step 1/80 - Loss: 0.2003, Accuracy: 1.0000, Time: 7.08 seconds\n",
      "\u001B[1m 1/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m9:25\u001B[0m 7s/step - accuracy: 1.0000 - loss: 0.2003Step 2/80 - Loss: 0.3119, Accuracy: 0.9500, Time: 3.68 seconds\n",
      "\u001B[1m 2/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:47\u001B[0m 4s/step - accuracy: 0.9750 - loss: 0.2561Step 3/80 - Loss: 0.2479, Accuracy: 0.9667, Time: 3.69 seconds\n",
      "\u001B[1m 3/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:44\u001B[0m 4s/step - accuracy: 0.9722 - loss: 0.2534Step 4/80 - Loss: 0.2316, Accuracy: 0.9500, Time: 3.69 seconds\n",
      "\u001B[1m 4/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:40\u001B[0m 4s/step - accuracy: 0.9667 - loss: 0.2479Step 5/80 - Loss: 0.2133, Accuracy: 0.9600, Time: 3.66 seconds\n",
      "\u001B[1m 5/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:36\u001B[0m 4s/step - accuracy: 0.9653 - loss: 0.2410Step 6/80 - Loss: 0.1965, Accuracy: 0.9667, Time: 3.65 seconds\n",
      "\u001B[1m 6/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:32\u001B[0m 4s/step - accuracy: 0.9656 - loss: 0.2336Step 7/80 - Loss: 0.2547, Accuracy: 0.9429, Time: 3.70 seconds\n",
      "\u001B[1m 7/80\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:28\u001B[0m 4s/step - accuracy: 0.9623 - loss: 0.2366Step 8/80 - Loss: 0.2334, Accuracy: 0.9500, Time: 3.73 seconds\n",
      "\u001B[1m 8/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:25\u001B[0m 4s/step - accuracy: 0.9608 - loss: 0.2362Step 9/80 - Loss: 0.2328, Accuracy: 0.9556, Time: 3.65 seconds\n",
      "\u001B[1m 9/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:21\u001B[0m 4s/step - accuracy: 0.9602 - loss: 0.2358Step 10/80 - Loss: 0.2342, Accuracy: 0.9500, Time: 3.67 seconds\n",
      "\u001B[1m10/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:17\u001B[0m 4s/step - accuracy: 0.9592 - loss: 0.2357Step 11/80 - Loss: 0.2271, Accuracy: 0.9545, Time: 3.75 seconds\n",
      "\u001B[1m11/80\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:14\u001B[0m 4s/step - accuracy: 0.9588 - loss: 0.2349Step 12/80 - Loss: 0.2271, Accuracy: 0.9583, Time: 3.71 seconds\n",
      "\u001B[1m12/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:11\u001B[0m 4s/step - accuracy: 0.9587 - loss: 0.2342Step 13/80 - Loss: 0.2294, Accuracy: 0.9538, Time: 3.67 seconds\n",
      "\u001B[1m13/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:07\u001B[0m 4s/step - accuracy: 0.9583 - loss: 0.2339Step 14/80 - Loss: 0.2239, Accuracy: 0.9571, Time: 4.04 seconds\n",
      "\u001B[1m14/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:05\u001B[0m 4s/step - accuracy: 0.9583 - loss: 0.2331Step 15/80 - Loss: 0.2195, Accuracy: 0.9600, Time: 4.16 seconds\n",
      "\u001B[1m15/80\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:03\u001B[0m 4s/step - accuracy: 0.9584 - loss: 0.2322Step 16/80 - Loss: 0.2157, Accuracy: 0.9563, Time: 3.79 seconds\n",
      "\u001B[1m16/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:00\u001B[0m 4s/step - accuracy: 0.9582 - loss: 0.2312Step 17/80 - Loss: 0.2098, Accuracy: 0.9588, Time: 3.65 seconds\n",
      "\u001B[1m17/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:56\u001B[0m 4s/step - accuracy: 0.9583 - loss: 0.2299Step 18/80 - Loss: 0.2119, Accuracy: 0.9611, Time: 3.82 seconds\n",
      "\u001B[1m18/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:52\u001B[0m 4s/step - accuracy: 0.9584 - loss: 0.2289Step 19/80 - Loss: 0.2059, Accuracy: 0.9632, Time: 3.71 seconds\n",
      "\u001B[1m19/80\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:48\u001B[0m 4s/step - accuracy: 0.9587 - loss: 0.2277Step 20/80 - Loss: 0.2076, Accuracy: 0.9650, Time: 3.65 seconds\n",
      "\u001B[1m20/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:44\u001B[0m 4s/step - accuracy: 0.9590 - loss: 0.2267Step 21/80 - Loss: 0.2082, Accuracy: 0.9667, Time: 3.73 seconds\n",
      "\u001B[1m21/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:40\u001B[0m 4s/step - accuracy: 0.9594 - loss: 0.2258Step 22/80 - Loss: 0.2118, Accuracy: 0.9636, Time: 3.76 seconds\n",
      "\u001B[1m22/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:37\u001B[0m 4s/step - accuracy: 0.9596 - loss: 0.2252Step 23/80 - Loss: 0.2129, Accuracy: 0.9652, Time: 3.69 seconds\n",
      "\u001B[1m23/80\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:33\u001B[0m 4s/step - accuracy: 0.9598 - loss: 0.2247Step 24/80 - Loss: 0.2100, Accuracy: 0.9667, Time: 3.77 seconds\n",
      "\u001B[1m24/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:29\u001B[0m 4s/step - accuracy: 0.9601 - loss: 0.2241Step 25/80 - Loss: 0.2235, Accuracy: 0.9600, Time: 3.84 seconds\n",
      "\u001B[1m25/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:26\u001B[0m 4s/step - accuracy: 0.9601 - loss: 0.2240Step 26/80 - Loss: 0.2314, Accuracy: 0.9538, Time: 3.75 seconds\n",
      "\u001B[1m26/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:22\u001B[0m 4s/step - accuracy: 0.9598 - loss: 0.2243Step 27/80 - Loss: 0.2295, Accuracy: 0.9556, Time: 3.68 seconds\n",
      "\u001B[1m27/80\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:18\u001B[0m 4s/step - accuracy: 0.9597 - loss: 0.2245Step 28/80 - Loss: 0.2262, Accuracy: 0.9571, Time: 3.73 seconds\n",
      "\u001B[1m28/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:14\u001B[0m 4s/step - accuracy: 0.9596 - loss: 0.2246Step 29/80 - Loss: 0.2246, Accuracy: 0.9586, Time: 3.74 seconds\n",
      "\u001B[1m29/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:10\u001B[0m 4s/step - accuracy: 0.9596 - loss: 0.2246Step 30/80 - Loss: 0.2239, Accuracy: 0.9600, Time: 3.76 seconds\n",
      "\u001B[1m30/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:07\u001B[0m 4s/step - accuracy: 0.9596 - loss: 0.2245Step 31/80 - Loss: 0.2279, Accuracy: 0.9548, Time: 3.68 seconds\n",
      "\u001B[1m31/80\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m3:03\u001B[0m 4s/step - accuracy: 0.9594 - loss: 0.2247Step 32/80 - Loss: 0.2261, Accuracy: 0.9563, Time: 3.80 seconds\n",
      "\u001B[1m32/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:59\u001B[0m 4s/step - accuracy: 0.9593 - loss: 0.2247Step 33/80 - Loss: 0.2255, Accuracy: 0.9545, Time: 3.76 seconds\n",
      "\u001B[1m33/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:56\u001B[0m 4s/step - accuracy: 0.9592 - loss: 0.2247Step 34/80 - Loss: 0.2225, Accuracy: 0.9559, Time: 3.68 seconds\n",
      "\u001B[1m34/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:52\u001B[0m 4s/step - accuracy: 0.9591 - loss: 0.2247Step 35/80 - Loss: 0.2202, Accuracy: 0.9571, Time: 3.70 seconds\n",
      "\u001B[1m35/80\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m2:48\u001B[0m 4s/step - accuracy: 0.9590 - loss: 0.2245Step 36/80 - Loss: 0.2178, Accuracy: 0.9583, Time: 3.78 seconds\n",
      "\u001B[1m36/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:44\u001B[0m 4s/step - accuracy: 0.9590 - loss: 0.2243Step 37/80 - Loss: 0.2205, Accuracy: 0.9541, Time: 3.69 seconds\n",
      "\u001B[1m37/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:40\u001B[0m 4s/step - accuracy: 0.9589 - loss: 0.2242Step 38/80 - Loss: 0.2192, Accuracy: 0.9553, Time: 3.65 seconds\n",
      "\u001B[1m38/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:37\u001B[0m 4s/step - accuracy: 0.9588 - loss: 0.2241Step 39/80 - Loss: 0.2203, Accuracy: 0.9538, Time: 3.78 seconds\n",
      "\u001B[1m39/80\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m2:33\u001B[0m 4s/step - accuracy: 0.9587 - loss: 0.2240Step 40/80 - Loss: 0.2172, Accuracy: 0.9550, Time: 3.77 seconds\n",
      "\u001B[1m40/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:29\u001B[0m 4s/step - accuracy: 0.9586 - loss: 0.2238Step 41/80 - Loss: 0.2142, Accuracy: 0.9561, Time: 3.73 seconds\n",
      "\u001B[1m41/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:25\u001B[0m 4s/step - accuracy: 0.9585 - loss: 0.2236Step 42/80 - Loss: 0.2115, Accuracy: 0.9571, Time: 3.75 seconds\n",
      "\u001B[1m42/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:22\u001B[0m 4s/step - accuracy: 0.9585 - loss: 0.2233Step 43/80 - Loss: 0.2118, Accuracy: 0.9558, Time: 3.68 seconds\n",
      "\u001B[1m43/80\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m2:18\u001B[0m 4s/step - accuracy: 0.9584 - loss: 0.2231Step 44/80 - Loss: 0.2154, Accuracy: 0.9545, Time: 3.69 seconds\n",
      "\u001B[1m44/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:14\u001B[0m 4s/step - accuracy: 0.9583 - loss: 0.2229Step 45/80 - Loss: 0.2144, Accuracy: 0.9556, Time: 3.72 seconds\n",
      "\u001B[1m45/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:10\u001B[0m 4s/step - accuracy: 0.9583 - loss: 0.2227Step 46/80 - Loss: 0.2120, Accuracy: 0.9565, Time: 3.75 seconds\n",
      "\u001B[1m46/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:07\u001B[0m 4s/step - accuracy: 0.9582 - loss: 0.2225Step 47/80 - Loss: 0.2095, Accuracy: 0.9574, Time: 3.81 seconds\n",
      "\u001B[1m47/80\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m2:03\u001B[0m 4s/step - accuracy: 0.9582 - loss: 0.2222Step 48/80 - Loss: 0.2081, Accuracy: 0.9583, Time: 3.74 seconds\n",
      "\u001B[1m48/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:59\u001B[0m 4s/step - accuracy: 0.9582 - loss: 0.2219Step 49/80 - Loss: 0.2074, Accuracy: 0.9592, Time: 3.67 seconds\n",
      "\u001B[1m49/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:55\u001B[0m 4s/step - accuracy: 0.9582 - loss: 0.2216Step 50/80 - Loss: 0.2056, Accuracy: 0.9600, Time: 3.72 seconds\n",
      "\u001B[1m50/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:52\u001B[0m 4s/step - accuracy: 0.9583 - loss: 0.2213Step 51/80 - Loss: 0.2106, Accuracy: 0.9569, Time: 3.73 seconds\n",
      "\u001B[1m51/80\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m1:48\u001B[0m 4s/step - accuracy: 0.9582 - loss: 0.2211Step 52/80 - Loss: 0.2126, Accuracy: 0.9538, Time: 3.67 seconds\n",
      "\u001B[1m52/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:44\u001B[0m 4s/step - accuracy: 0.9582 - loss: 0.2209Step 53/80 - Loss: 0.2115, Accuracy: 0.9528, Time: 3.63 seconds\n",
      "\u001B[1m53/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:40\u001B[0m 4s/step - accuracy: 0.9580 - loss: 0.2207Step 54/80 - Loss: 0.2108, Accuracy: 0.9519, Time: 3.70 seconds\n",
      "\u001B[1m54/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:37\u001B[0m 4s/step - accuracy: 0.9579 - loss: 0.2205Step 55/80 - Loss: 0.2090, Accuracy: 0.9527, Time: 3.67 seconds\n",
      "\u001B[1m55/80\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m1:33\u001B[0m 4s/step - accuracy: 0.9578 - loss: 0.2203Step 56/80 - Loss: 0.2072, Accuracy: 0.9536, Time: 3.75 seconds\n",
      "\u001B[1m56/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:29\u001B[0m 4s/step - accuracy: 0.9578 - loss: 0.2201Step 57/80 - Loss: 0.2076, Accuracy: 0.9526, Time: 3.65 seconds\n",
      "\u001B[1m57/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:25\u001B[0m 4s/step - accuracy: 0.9577 - loss: 0.2199Step 58/80 - Loss: 0.2085, Accuracy: 0.9517, Time: 3.79 seconds\n",
      "\u001B[1m58/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:22\u001B[0m 4s/step - accuracy: 0.9576 - loss: 0.2197Step 59/80 - Loss: 0.2064, Accuracy: 0.9525, Time: 3.63 seconds\n",
      "\u001B[1m59/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m1:18\u001B[0m 4s/step - accuracy: 0.9575 - loss: 0.2195Step 60/80 - Loss: 0.2084, Accuracy: 0.9517, Time: 3.71 seconds\n",
      "\u001B[1m60/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:14\u001B[0m 4s/step - accuracy: 0.9574 - loss: 0.2193Step 61/80 - Loss: 0.2114, Accuracy: 0.9492, Time: 3.64 seconds\n",
      "\u001B[1m61/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:10\u001B[0m 4s/step - accuracy: 0.9573 - loss: 0.2191Step 62/80 - Loss: 0.2117, Accuracy: 0.9484, Time: 3.66 seconds\n",
      "\u001B[1m62/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:07\u001B[0m 4s/step - accuracy: 0.9571 - loss: 0.2190Step 63/80 - Loss: 0.2096, Accuracy: 0.9492, Time: 3.71 seconds\n",
      "\u001B[1m63/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m1:03\u001B[0m 4s/step - accuracy: 0.9570 - loss: 0.2189Step 64/80 - Loss: 0.2083, Accuracy: 0.9500, Time: 3.66 seconds\n",
      "\u001B[1m64/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m59s\u001B[0m 4s/step - accuracy: 0.9569 - loss: 0.2187 Step 65/80 - Loss: 0.2082, Accuracy: 0.9492, Time: 3.71 seconds\n",
      "\u001B[1m65/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m55s\u001B[0m 4s/step - accuracy: 0.9568 - loss: 0.2185Step 66/80 - Loss: 0.2067, Accuracy: 0.9500, Time: 3.68 seconds\n",
      "\u001B[1m66/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m52s\u001B[0m 4s/step - accuracy: 0.9567 - loss: 0.2184Step 67/80 - Loss: 0.2056, Accuracy: 0.9507, Time: 3.71 seconds\n",
      "\u001B[1m67/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m48s\u001B[0m 4s/step - accuracy: 0.9566 - loss: 0.2182Step 68/80 - Loss: 0.2060, Accuracy: 0.9500, Time: 3.75 seconds\n",
      "\u001B[1m68/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m44s\u001B[0m 4s/step - accuracy: 0.9565 - loss: 0.2180Step 69/80 - Loss: 0.2073, Accuracy: 0.9493, Time: 3.64 seconds\n",
      "\u001B[1m69/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m40s\u001B[0m 4s/step - accuracy: 0.9564 - loss: 0.2178Step 70/80 - Loss: 0.2104, Accuracy: 0.9471, Time: 3.72 seconds\n",
      "\u001B[1m70/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m37s\u001B[0m 4s/step - accuracy: 0.9562 - loss: 0.2177Step 71/80 - Loss: 0.2097, Accuracy: 0.9479, Time: 3.64 seconds\n",
      "\u001B[1m71/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m33s\u001B[0m 4s/step - accuracy: 0.9561 - loss: 0.2176Step 72/80 - Loss: 0.2078, Accuracy: 0.9486, Time: 3.78 seconds\n",
      "\u001B[1m72/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m29s\u001B[0m 4s/step - accuracy: 0.9560 - loss: 0.2175Step 73/80 - Loss: 0.2062, Accuracy: 0.9493, Time: 3.63 seconds\n",
      "\u001B[1m73/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.9559 - loss: 0.2173Step 74/80 - Loss: 0.2044, Accuracy: 0.9500, Time: 3.72 seconds\n",
      "\u001B[1m74/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m22s\u001B[0m 4s/step - accuracy: 0.9558 - loss: 0.2172Step 75/80 - Loss: 0.2045, Accuracy: 0.9493, Time: 3.69 seconds\n",
      "\u001B[1m75/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m18s\u001B[0m 4s/step - accuracy: 0.9558 - loss: 0.2170Step 76/80 - Loss: 0.2036, Accuracy: 0.9500, Time: 3.64 seconds\n",
      "\u001B[1m76/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m14s\u001B[0m 4s/step - accuracy: 0.9557 - loss: 0.2168Step 77/80 - Loss: 0.2027, Accuracy: 0.9506, Time: 3.71 seconds\n",
      "\u001B[1m77/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.9556 - loss: 0.2166Step 78/80 - Loss: 0.2022, Accuracy: 0.9513, Time: 3.69 seconds\n",
      "\u001B[1m78/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 0.9556 - loss: 0.2164 Step 79/80 - Loss: 0.2006, Accuracy: 0.9519, Time: 3.99 seconds\n",
      "\u001B[1m79/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 0.9555 - loss: 0.2162Step 80/80 - Loss: 0.1994, Accuracy: 0.9525, Time: 3.88 seconds\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9555 - loss: 0.2160\n",
      "Epoch 6: saving model to ./Finetune_Checkpoints\\model_epoch_06_val_loss_0.19.keras\n",
      "--- Epoch 6 completed in 362.11 seconds ---\n",
      "\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m362s\u001B[0m 4s/step - accuracy: 0.9554 - loss: 0.2158 - val_accuracy: 0.9450 - val_loss: 0.1883 - learning_rate: 6.5610e-06\n",
      "\n",
      "--- Starting Epoch 7 ---\n",
      "Epoch 7/10\n",
      "Step 1/80 - Loss: 0.0661, Accuracy: 1.0000, Time: 7.57 seconds\n",
      "\u001B[1m 1/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m10:04\u001B[0m 8s/step - accuracy: 1.0000 - loss: 0.0661Step 2/80 - Loss: 0.0857, Accuracy: 1.0000, Time: 3.63 seconds\n",
      "\n",
      "Early stopping triggered at batch 2: loss = 0.0857\n",
      "\u001B[1m 2/80\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m4:43\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0759 \n",
      "Epoch 7: saving model to ./Finetune_Checkpoints\\model_epoch_07_val_loss_0.19.keras\n",
      "--- Epoch 7 completed in 68.17 seconds ---\n",
      "\n",
      "\u001B[1m80/80\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m68s\u001B[0m 766ms/step - accuracy: 1.0000 - loss: 0.0855 - val_accuracy: 0.9450 - val_loss: 0.1943 - learning_rate: 5.9049e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25d5ad74290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6079134b65564429"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
