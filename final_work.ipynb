{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T16:38:05.678958Z",
     "start_time": "2025-01-10T16:38:05.524376Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:38:16.431283Z",
     "start_time": "2025-01-10T16:38:06.366948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = r'E:\\PosePerfect\\Model\\mobilenetV3_checkpoints\\model_epoch_07_val_loss_0.36.keras'\n",
    "cnn_lstm_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ],
   "id": "8634dcc82a26a287",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:40:16.362962Z",
     "start_time": "2025-01-10T16:40:16.324037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ],
   "id": "434a5911f4de025",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:40:18.392103Z",
     "start_time": "2025-01-10T16:40:18.362939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_video(frames, target_shape=(15, 224, 224, 3)):\n",
    "    # Resize frames and stack into a batch\n",
    "    processed_frames = [cv2.resize(frame, (224, 224)) for frame in frames]\n",
    "    processed_frames = np.array(processed_frames, dtype='float32')\n",
    "    processed_frames = preprocess_input(processed_frames)\n",
    "    return np.expand_dims(processed_frames, axis=0)"
   ],
   "id": "66084f52687e1623",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:40:19.687782Z",
     "start_time": "2025-01-10T16:40:19.668692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to predict activity from video frames\n",
    "def predict_activity(frames):\n",
    "    input_data = preprocess_video(frames)\n",
    "    predictions = cnn_lstm_model.predict(input_data)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return predicted_class[0]"
   ],
   "id": "66a41328972aa529",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:40:22.389633Z",
     "start_time": "2025-01-10T16:40:21.020015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bicep_curl_logic():\n",
    "    def calculate_angle(a, b, c):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        c = np.array(c)\n",
    "        \n",
    "        ba = a - b\n",
    "        bc = c - b\n",
    "        \n",
    "        mag_ba = math.sqrt(ba[0]**2 + ba[1]**2)\n",
    "        mag_bc = math.sqrt(bc[0]**2 + bc[1]**2)\n",
    "        \n",
    "        radians = math.acos(np.dot(ba, bc) / (mag_bc * mag_ba))\n",
    "        \n",
    "        angle = np.abs(radians * 180 / np.pi)\n",
    "        \n",
    "        if angle > 180:\n",
    "            angle = 360 - angle\n",
    "        \n",
    "        return angle\n",
    "\n",
    "    def draw_landmarks(image, landmarks, selected_landmarks, connections):\n",
    "        for idx in selected_landmarks:\n",
    "            lm = landmarks[idx]\n",
    "            h, w, _ = image.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            cv2.circle(image, (cx, cy), 5, (0, 255, 0), -1)\n",
    "    \n",
    "        for connection in connections:\n",
    "            start_idx, end_idx = connection\n",
    "            if start_idx in selected_landmarks and end_idx in selected_landmarks:\n",
    "                start_lm = landmarks[start_idx]\n",
    "                end_lm = landmarks[end_idx]\n",
    "    \n",
    "                start_coords = (int(start_lm.x * w), int(start_lm.y * h))\n",
    "                end_coords = (int(end_lm.x * w), int(end_lm.y * h))\n",
    "                cv2.line(image, start_coords, end_coords, (255, 0, 0), 2)\n",
    "                \n",
    "    selected_landmarks = [\n",
    "        mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_HIP.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_KNEE.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_ELBOW.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_WRIST.value,\n",
    "        mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
    "        mp_pose.PoseLandmark.LEFT_HIP.value,\n",
    "        mp_pose.PoseLandmark.LEFT_KNEE.value,\n",
    "        mp_pose.PoseLandmark.LEFT_ELBOW.value,\n",
    "        mp_pose.PoseLandmark.LEFT_WRIST.value,\n",
    "    ]\n",
    "    \n",
    "    connections = [\n",
    "        (mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_HIP.value),\n",
    "        (mp_pose.PoseLandmark.RIGHT_HIP.value, mp_pose.PoseLandmark.RIGHT_KNEE.value),\n",
    "        (mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_ELBOW.value),\n",
    "        (mp_pose.PoseLandmark.RIGHT_ELBOW.value, mp_pose.PoseLandmark.RIGHT_WRIST.value),\n",
    "        (mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_HIP.value),\n",
    "        (mp_pose.PoseLandmark.LEFT_HIP.value, mp_pose.PoseLandmark.LEFT_KNEE.value),\n",
    "        (mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_ELBOW.value),\n",
    "        (mp_pose.PoseLandmark.LEFT_ELBOW.value, mp_pose.PoseLandmark.LEFT_WRIST.value)\n",
    "    ]\n",
    "    \n",
    "    def calculate_progress(angle, min_angle, max_angle):\n",
    "        progress = 1 - (angle - min_angle) / (max_angle - min_angle)\n",
    "        progress = max(0, min(progress, 1))\n",
    "        return progress\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        counter = 0\n",
    "        stage = None\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            frame = cv2.flip(frame, 1)\n",
    "        \n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            \n",
    "            results = pose.process(image)\n",
    "        \n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "        \n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "        \n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        \n",
    "                left_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "                right_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "                \n",
    "                torso_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "    \n",
    "                min_angle = 10\n",
    "                max_angle = 175\n",
    "                \n",
    "                cv2.putText(image, f'{left_angle:.1f}', \n",
    "                            tuple(np.multiply(right_elbow, [640, 480]).astype(int)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "                progress = calculate_progress(left_angle, min_angle, max_angle)\n",
    "        \n",
    "                meter_x_start, meter_y_start = 10, 80\n",
    "                meter_width, meter_height = 20, 200\n",
    "                filled_height = int(progress * meter_height)\n",
    "        \n",
    "                cv2.rectangle(image, (meter_x_start, meter_y_start),\n",
    "                              (meter_x_start + meter_width, meter_y_start + meter_height), (200, 200, 200), -1)\n",
    "                cv2.rectangle(image, (meter_x_start, meter_y_start + meter_height - filled_height),\n",
    "                              (meter_x_start + meter_width, meter_y_start + meter_height), (0, 255, 0), -1)\n",
    "    \n",
    "                cv2.putText(image, f'{int(progress * 100)}%', (meter_x_start + 30, meter_y_start + meter_height),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "                cv2.putText(image, 'Count: ', (15, 12),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(counter), (10, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "                feedback = []\n",
    "                if abs(right_elbow[0] - right_shoulder[0]) > 0.1 or abs(left_elbow[0] - left_shoulder[0]) > 0.1:\n",
    "                    feedback.append(\"Hands too far apart\")\n",
    "                if left_angle > max_angle:\n",
    "                    feedback.append(\"You're going too low\")\n",
    "                if torso_angle < 170:\n",
    "                    feedback.append(\"Don't lean forward! Keep your back straight.\")\n",
    "                elif torso_angle > 190:\n",
    "                    feedback.append(\"Don't lean backward! Keep your back straight.\")\n",
    "        \n",
    "                    \n",
    "                for i, msg in enumerate(feedback):\n",
    "                    cv2.putText(image, msg, (400, 30 + i * 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "                if left_angle > max_angle and right_angle > max_angle:\n",
    "                    stage = \"down\"\n",
    "                if left_angle < min_angle and right_angle < min_angle and stage == \"down\":\n",
    "                    stage = \"up\"\n",
    "                    counter += 1\n",
    "                    print(\"Counter:\", counter)\n",
    "        \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            draw_landmarks(image, landmarks, selected_landmarks, connections)\n",
    "        \n",
    "            cv2.imshow('Biceps Curl', image)\n",
    "        \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ],
   "id": "bed436d2d2c9e9a2",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:40:23.359373Z",
     "start_time": "2025-01-10T16:40:23.144583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def squat_logic():\n",
    "    def calculate_angle_alt(shoulder, hip):\n",
    "        x1, y1 = shoulder\n",
    "        x2, y2 = hip\n",
    "    \n",
    "        vector = (x1 - x2, y1 - y2)\n",
    "    \n",
    "        vertical_vector = (0, -1)\n",
    "    \n",
    "        dot_product = vector[0] * vertical_vector[0] + vector[1] * vertical_vector[1]\n",
    "    \n",
    "        vector_magnitude = math.sqrt(vector[0]**2 + vector[1]**2)\n",
    "        vertical_magnitude = 1\n",
    "    \n",
    "        angle_rad = math.acos(dot_product / (vector_magnitude * vertical_magnitude))\n",
    "    \n",
    "        angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "        return angle_deg\n",
    "    \n",
    "    def draw_landmarks(image, landmarks, selected_landmarks, connections):\n",
    "        for idx in selected_landmarks:\n",
    "            lm = landmarks[idx]\n",
    "            h, w, _ = image.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            cv2.circle(image, (cx, cy), 5, (0, 255, 0), -1)\n",
    "    \n",
    "        for connection in connections:\n",
    "            start_idx, end_idx = connection\n",
    "            if start_idx in selected_landmarks and end_idx in selected_landmarks:\n",
    "                start_lm = landmarks[start_idx]\n",
    "                end_lm = landmarks[end_idx]\n",
    "    \n",
    "                start_coords = (int(start_lm.x * w), int(start_lm.y * h))\n",
    "                end_coords = (int(end_lm.x * w), int(end_lm.y * h))\n",
    "                cv2.line(image, start_coords, end_coords, (255, 0, 0), 2)\n",
    "                \n",
    "    selected_landmarks = [\n",
    "        mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_HIP.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_KNEE.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_ANKLE.value,\n",
    "        mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value,\n",
    "        # mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
    "        # mp_pose.PoseLandmark.LEFT_HIP.value,\n",
    "        # mp_pose.PoseLandmark.LEFT_KNEE.value,\n",
    "        # mp_pose.PoseLandmark.LEFT_ANKLE.value,\n",
    "        # mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value,\n",
    "    ]\n",
    "    \n",
    "    connections = [\n",
    "        (mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_HIP.value),\n",
    "        (mp_pose.PoseLandmark.RIGHT_HIP.value, mp_pose.PoseLandmark.RIGHT_KNEE.value),\n",
    "        (mp_pose.PoseLandmark.RIGHT_KNEE.value, mp_pose.PoseLandmark.RIGHT_ANKLE.value),\n",
    "        (mp_pose.PoseLandmark.RIGHT_ANKLE.value, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value),\n",
    "        # (mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_HIP.value),\n",
    "        # (mp_pose.PoseLandmark.LEFT_HIP.value, mp_pose.PoseLandmark.LEFT_KNEE.value),\n",
    "        # (mp_pose.PoseLandmark.LEFT_KNEE.value, mp_pose.PoseLandmark.LEFT_ANKLE.value),\n",
    "        # (mp_pose.PoseLandmark.LEFT_ANKLE.value, mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value)\n",
    "    ]\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        counter = 0\n",
    "        stage = None\n",
    "        up = True\n",
    "        down = False\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            frame = cv2.flip(frame, 1)\n",
    "        \n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = pose.process(image)\n",
    "        \n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "        \n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "                \n",
    "                shoulder_hip_vertical = calculate_angle_alt(right_shoulder, right_hip)\n",
    "                hip_knee_vertical = calculate_angle_alt(right_hip, right_knee)\n",
    "                knee_ankle_vertical = calculate_angle_alt(right_knee, right_ankle)\n",
    "                \n",
    "                cv2.putText(image, f'SH-HIP: {shoulder_hip_vertical:.1f}', \n",
    "                            tuple(np.multiply(right_hip, [640, 480]).astype(int)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, f'HIP-KNEE: {hip_knee_vertical:.1f}',\n",
    "                            tuple(np.multiply(right_knee, [640, 480]).astype(int)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, f'KNEE-ANKLE: {knee_ankle_vertical:.1f}',\n",
    "                            tuple(np.multiply(right_ankle, [640, 480]).astype(int)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                feedback = []\n",
    "                if shoulder_hip_vertical < 10:\n",
    "                    feedback.append(\"Bend forward\")\n",
    "                if shoulder_hip_vertical > 25:\n",
    "                    feedback.append(\"Bend backward\")\n",
    "                if 50 < hip_knee_vertical < 80:\n",
    "                    feedback.append(\"Lower your hips\")\n",
    "                if hip_knee_vertical > 95:\n",
    "                    feedback.append(\"Knees falling over toes\")\n",
    "                if knee_ankle_vertical > 30:\n",
    "                    feedback.append(\"Squats too deep\")\n",
    "                \n",
    "                for i, msg in enumerate(feedback):\n",
    "                    cv2.putText(image, msg, (10, 100 + i * 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "                if up:\n",
    "                    if hip_knee_vertical < 32:\n",
    "                        stage = \"stage1\"  # up\n",
    "                    elif stage == \"stage1\" and 35 < hip_knee_vertical < 65:\n",
    "                        stage = \"stage2\"  # middle\n",
    "                    elif stage == \"stage2\" and 75 < hip_knee_vertical < 95:\n",
    "                        stage = \"stage3\"  # down  \n",
    "                        down = True\n",
    "                        up = False\n",
    "                        \n",
    "                if down:\n",
    "                    if stage == \"stage3\" and 35 < hip_knee_vertical < 65:\n",
    "                        stage = \"stage2\"\n",
    "                    elif stage == \"stage2\" and hip_knee_vertical < 32:\n",
    "                        stage = \"stage1\"\n",
    "                        down = False\n",
    "                        up = True\n",
    "                        counter += 1     \n",
    "    \n",
    "                cv2.putText(image, 'Count: ', (15, 12),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(counter), (10, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            draw_landmarks(image, landmarks, selected_landmarks, connections)\n",
    "        \n",
    "            cv2.imshow('Squats', image)\n",
    "        \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ],
   "id": "55c56f7d25213d24",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:09:03.781777Z",
     "start_time": "2025-01-10T17:08:41.398719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    # buffers = []\n",
    "    buffer = []\n",
    "    buffer_size = 15 \n",
    "    activity_map = {0: \"Bicep Curls\", 1: \"Squats\"}\n",
    "    current_activity = None\n",
    "    sequence_count = 0\n",
    "    # i = 0\n",
    "\n",
    "    frame_rate = 4  # 5 FPS\n",
    "    frame_interval = 1 / frame_rate  # Interval between frames in seconds\n",
    "    last_time = time.time()\n",
    "\n",
    "    start_time = time.time()\n",
    "    wait_time = 7  # 15 seconds preparation time\n",
    "\n",
    "    try:\n",
    "         while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time < wait_time:\n",
    "                cv2.putText(frame, \"Activity: None\", (10, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                cv2.imshow('Activity Recognition', frame)\n",
    "\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "                \n",
    "            if elapsed_time < wait_time + 5: \n",
    "                cv2.putText(frame, \"Start\", (10, 90),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                cv2.imshow('Activity Recognition', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            current_time = time.time()\n",
    "            if current_time - last_time >= frame_interval:\n",
    "                last_time = current_time  \n",
    "\n",
    "                buffer.append(frame)\n",
    "                if len(buffer) > buffer_size:\n",
    "                    buffer.pop(0)\n",
    "\n",
    "                if len(buffer) == buffer_size:\n",
    "                    # sequence_count += 1\n",
    "                    # buffers.append(buffer.copy())\n",
    "                    # buffer.clear()\n",
    "                    # if sequence_count == 2: \n",
    "                        sequence_array = np.array(buffer)\n",
    "                        predicted_class = predict_activity(sequence_array)\n",
    "                        print(predicted_class)\n",
    "                        current_activity = activity_map.get(predicted_class, \"Detecting...\")\n",
    "                        print(current_activity)\n",
    "\n",
    "                        if current_activity == \"Bicep Curls\":\n",
    "                            bicep_curl_logic()\n",
    "                            break\n",
    "                        elif current_activity == \"Squats\":\n",
    "                            squat_logic()\n",
    "                            break\n",
    "                            \n",
    "                cv2.putText(frame, f\"Activity: {current_activity or 'Collecting...'}\", (10, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('Activity Recognition', frame)\n",
    " \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                 \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "6554c1a082b85848",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 627ms/step\n",
      "1\n",
      "Squats\n",
      "An error occurred: cannot access local variable 'landmarks' where it is not associated with a value\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:07:04.503761Z",
     "start_time": "2025-01-10T17:06:47.147587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# Initialize Mediapipe Pose module\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Function to calculate the angle between three points (using the law of cosines)\n",
    "def calculate_angle(a, b, c):\n",
    "    # a, b, c are (x, y) coordinates of three points\n",
    "    # Vector AB and BC\n",
    "    ab = [b[0] - a[0], b[1] - a[1]]\n",
    "    bc = [b[0] - c[0], b[1] - c[1]]\n",
    "    \n",
    "    # Dot product and magnitudes\n",
    "    dot_product = ab[0] * bc[0] + ab[1] * bc[1]\n",
    "    magnitude_ab = math.sqrt(ab[0] ** 2 + ab[1] ** 2)\n",
    "    magnitude_bc = math.sqrt(bc[0] ** 2 + bc[1] ** 2)\n",
    "    \n",
    "    # Calculate angle in radians\n",
    "    angle_rad = math.acos(dot_product / (magnitude_ab * magnitude_bc))\n",
    "    # Convert to degrees\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    return angle_deg\n",
    "\n",
    "# Function to classify the activity based on angles\n",
    "def classify_activity(frame, landmarks):\n",
    "    # Get the coordinates of the relevant body parts\n",
    "    shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]\n",
    "    elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y]\n",
    "    wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].y]\n",
    "    \n",
    "    hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "    knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "    ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y]\n",
    "    \n",
    "    # Check if the knee landmark exists\n",
    "    knee_detected = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].visibility > 0.5\n",
    "    \n",
    "    if knee_detected:\n",
    "        # Squat Logic (if knee is detected)\n",
    "        knee_angle = calculate_angle(hip, knee, ankle)\n",
    "        activity = \"Squatting\"\n",
    "        cv2.putText(frame, f'Knee Angle: {knee_angle:.1f}', \n",
    "                    (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        # Bicep Curl Logic (if knee is NOT detected)\n",
    "        elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "        activity = \"Bicep Curling\"\n",
    "        cv2.putText(frame, f'Elbow Angle: {elbow_angle:.1f}', \n",
    "                    (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return activity\n",
    "\n",
    "# Main program\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Flip the frame for better visualization\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # Process the frame to detect landmarks\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(image_rgb)\n",
    "\n",
    "            # If landmarks are found\n",
    "            if results.pose_landmarks:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # Classify activity based on landmarks\n",
    "                activity = classify_activity(frame, landmarks)\n",
    "                \n",
    "                if activity == \"Bicep Curling\":\n",
    "                    bicep_curl_logic(frame, pose, cap)\n",
    "                elif activity == 'Squatting':\n",
    "                    squat_logic(frame, pose, cap)\n",
    "\n",
    "                # Display the activity on the frame\n",
    "                cv2.putText(frame, f\"Activity: {activity}\", (10, 150),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Show the frame with the activity label\n",
    "            cv2.imshow('Activity Recognition', frame)\n",
    "\n",
    "            # Exit on pressing 'q'\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "9724e9aae7a99852",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "squat_logic() takes 0 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 98\u001B[0m\n\u001B[0;32m     95\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 98\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[31], line 81\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     79\u001B[0m     bicep_curl_logic(frame, pose, cap)\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m activity \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSquatting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 81\u001B[0m     \u001B[43msquat_logic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;66;03m# Display the activity on the frame\u001B[39;00m\n\u001B[0;32m     84\u001B[0m cv2\u001B[38;5;241m.\u001B[39mputText(frame, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mActivity: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mactivity\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, (\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m150\u001B[39m),\n\u001B[0;32m     85\u001B[0m             cv2\u001B[38;5;241m.\u001B[39mFONT_HERSHEY_SIMPLEX, \u001B[38;5;241m1\u001B[39m, (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m2\u001B[39m, cv2\u001B[38;5;241m.\u001B[39mLINE_AA)\n",
      "\u001B[1;31mTypeError\u001B[0m: squat_logic() takes 0 positional arguments but 3 were given"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:52:30.004593Z",
     "start_time": "2024-12-20T11:52:25.004648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "wait = 5\n",
    "\n",
    "while(1):\n",
    "    current_time = time.time()\n",
    "    if  int(current_time) - int(start_time)  == wait:\n",
    "        break\n",
    "        \n",
    "print(int(current_time)- int(start_time))"
   ],
   "id": "7a4ff0c3f339319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:04:26.676828Z",
     "start_time": "2024-12-20T12:04:25.155137Z"
    }
   },
   "cell_type": "code",
   "source": "print(time.time() )",
   "id": "f0c5b1f79a226671",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtime\u001B[49m\u001B[38;5;241m.\u001B[39mtime() )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'time' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:03:02.919126Z",
     "start_time": "2025-01-10T17:02:53.310114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "index = 0\n",
    "while True:\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    if not cap.isOpened():\n",
    "        break\n",
    "    print(f\"Camera index {index} is available.\")\n",
    "    index += 1\n",
    "    cap.release()\n"
   ],
   "id": "6686a36b2afb63d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera index 0 is available.\n",
      "Camera index 1 is available.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2679fe27425a2396"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
